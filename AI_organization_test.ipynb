{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdcad8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ .RData\n",
      "   Path: C:\\Users\\gabel\\Documents\\.RData\n",
      "   Preview:\n",
      "[unknown file]\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ .Rhistory\n",
      "   Path: C:\\Users\\gabel\\Documents\\.Rhistory\n",
      "   Preview:\n",
      "[unknown file]\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ 04.12.2023_22.06.45_REC.mp4\n",
      "   Path: C:\\Users\\gabel\\Documents\\04.12.2023_22.06.45_REC.mp4\n",
      "   Preview:\n",
      "[video/mp4 file]\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ 6824.txt\n",
      "   Path: C:\\Users\\gabel\\Documents\\6824.txt\n",
      "   Preview:\n",
      "6/8/24\n",
      "\n",
      "I hate my current situation, my life. I feel as though my purpose is nothing and anything I do I can't seem to get a grasp on, as if I am too stupid to understand anything. I watch YouTube over's lives, whilst my own is stagnant and watching it pass by me, and because I choose to do nothing I feel as though life has become this meaningless blob of existence where I see everyone else exist except for myself, a form of depersonalization I guess. I feel I have no control over myself, as I w\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ best_model.pth\n",
      "   Path: C:\\Users\\gabel\\Documents\\best_model.pth\n",
      "   Preview:\n",
      "[unknown file]\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ big_bucks.csv\n",
      "   Path: C:\\Users\\gabel\\Documents\\big_bucks.csv\n",
      "   Preview:\n",
      "[application/vnd.ms-excel file]\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ big_bucks_edited.csv\n",
      "   Path: C:\\Users\\gabel\\Documents\\big_bucks_edited.csv\n",
      "   Preview:\n",
      "[application/vnd.ms-excel file]\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ biospy_results.pdf\n",
      "   Path: C:\\Users\\gabel\\Documents\\biospy_results.pdf\n",
      "   Preview:\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ bullshit.R\n",
      "   Path: C:\\Users\\gabel\\Documents\\bullshit.R\n",
      "   Preview:\n",
      "[unknown file]\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ CMDA_4654_HW_0.tex\n",
      "   Path: C:\\Users\\gabel\\Documents\\CMDA_4654_HW_0.tex\n",
      "   Preview:\n",
      "[application/x-tex file]\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ Correlation_plot.png\n",
      "   Path: C:\\Users\\gabel\\Documents\\Correlation_plot.png\n",
      "   Preview:\n",
      "[image/png file]\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ desktop.ini\n",
      "   Path: C:\\Users\\gabel\\Documents\\desktop.ini\n",
      "   Preview:\n",
      "[unknown file]\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ Epidemic.csv\n",
      "   Path: C:\\Users\\gabel\\Documents\\Epidemic.csv\n",
      "   Preview:\n",
      "[application/vnd.ms-excel file]\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ Explained_Var.png\n",
      "   Path: C:\\Users\\gabel\\Documents\\Explained_Var.png\n",
      "   Preview:\n",
      "[image/png file]\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ gptSerialCorrelationTest.cu.txt\n",
      "   Path: C:\\Users\\gabel\\Documents\\gptSerialCorrelationTest.cu.txt\n",
      "   Preview:\n",
      "// gptSerialCorrelationTest.cu\n",
      "\n",
      "#include <iostream>\n",
      "#include <cuda.h>\n",
      "#include \"gptRandom.h\"\n",
      "\n",
      "// Kernel for calculating the serial correlation of the array elements\n",
      "__global__ void gptSerialCorrelationKernel(dfloat *array, dfloat *sumX, dfloat *sumY, dfloat *sumXY, dfloat *sumX2, dfloat *sumY2, int N) {\n",
      "  int tid = threadIdx.x;\n",
      "  int idx = blockIdx.x * blockDim.x + tid;\n",
      "\n",
      "  // Variables to store sums for correlation calculation\n",
      "  dfloat x, y;\n",
      "  dfloat partialSumX = 0.0, partialSumY = 0.0;\n",
      "  dfloa\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ group_2.r\n",
      "   Path: C:\\Users\\gabel\\Documents\\group_2.r\n",
      "   Preview:\n",
      "[unknown file]\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ Homework4.ipynb\n",
      "   Path: C:\\Users\\gabel\\Documents\\Homework4.ipynb\n",
      "   Preview:\n",
      "[Code]\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#Part A\n",
      "\n",
      "# Define the piecewise function u0(x)\n",
      "def u0(x):\n",
      "    return np.piecewise(x, \n",
      "                        [x < -0.5, (x >= -0.5) & (x < 0.5), x >= 0.5],\n",
      "                        [-1, 0, 1])\n",
      "\n",
      "# Define the b_n(0) coefficient based on n mod 4\n",
      "def b_n(n):\n",
      "    if n % 4 == 0:\n",
      "        return 0\n",
      "    elif n % 2 == 1:  # odd\n",
      "       return 2 / (n * np.pi)\n",
      "    elif n % 4 == 2:\n",
      "        return -4 / (n * np.pi)\n",
      "\n",
      "    #return (-2/(n*np.pi)) * (-1)**n\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ HW3.ipynb\n",
      "   Path: C:\\Users\\gabel\\Documents\\HW3.ipynb\n",
      "   Preview:\n",
      "[Code]\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from scipy.linalg import solve\n",
      "from scipy.integrate import solve_bvp\n",
      "\n",
      "# Define the domain\n",
      "x_vals = np.linspace(0, 1, 100)\n",
      "\n",
      "# Function to solve -u''(x) = f(x) with given boundary conditions\n",
      "def solve_poisson(f, bc, N=100):\n",
      "    def ode(x, y):\n",
      "        return np.vstack([y[1], -f(x)])  # Convert 2nd order ODE to 1st order system\n",
      "    \n",
      "    def bc_conditions(ya, yb):\n",
      "        return bc(ya, yb)  # Apply the user-defined boundary conditions\n",
      "\n",
      "    # I\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ HW5.ipynb\n",
      "   Path: C:\\Users\\gabel\\Documents\\HW5.ipynb\n",
      "   Preview:\n",
      "[Code]\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "\n",
      "#Problem 2B\n",
      "\n",
      "A = np.array([[-1, 10],\n",
      "              [0, -2]])\n",
      "y0 = np.array([1, 1])\n",
      "\n",
      "dt = 0.05\n",
      "t_values = np.arange(0, 5 + dt, dt)\n",
      "num_steps = len(t_values)\n",
      "ys = np.zeros((num_steps, 2))\n",
      "ys[0] = y0\n",
      "\n",
      "\n",
      "I = np.eye(2)\n",
      "M1 = np.linalg.inv(I - 0.5 * dt * A)  # (I - t/2 A)^(-1)\n",
      "M2 = I + 0.5 * dt * A                # (I + t/2 A)\n",
      "\n",
      "for k in range(1, num_steps):\n",
      "    ys[k] = M1 @ (M2 @ ys[k-1])\n",
      "\n",
      "# Compute norms\n",
      "norms = np.linalg.norm(ys, axis=1)\n",
      "\n",
      "plt\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ HW6.ipynb\n",
      "   Path: C:\\Users\\gabel\\Documents\\HW6.ipynb\n",
      "   Preview:\n",
      "[Code]\n",
      "import numpy as np\n",
      "\n",
      "N = 50\n",
      "x = np.linspace(0, 1, N)\n",
      "y = np.linspace(0, 1, N)\n",
      "X, Y = np.meshgrid(x, y)\n",
      "\n",
      "#Eigenvalue\n",
      "def eigenvalue(j,k):\n",
      "    return (j**2 + k**2)*np.pi**2\n",
      "\n",
      "#Eigenfunction\n",
      "def eigenfunction(j,k,x, y):\n",
      "    return np.sin(j*np.pi*x)*np.sin(k*np.pi*y)\n",
      "\n",
      "# Function to be approximated\n",
      "def function(x,y):\n",
      "    return x*(1-y)\n",
      "\n",
      "F = function(X,Y)\n",
      "\n",
      "U5 = np.zeros_like(F)\n",
      "\n",
      "for j in range(1,6):\n",
      "    for k in range(1,6):\n",
      "        psi_jk = eigenfunction(j, k, X, Y)\n",
      "        lam_jk = eigenvalue(j,\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ HW_5.R\n",
      "   Path: C:\\Users\\gabel\\Documents\\HW_5.R\n",
      "   Preview:\n",
      "[unknown file]\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ Indigenous Mental Health in Canada.mp4\n",
      "   Path: C:\\Users\\gabel\\Documents\\Indigenous Mental Health in Canada.mp4\n",
      "   Preview:\n",
      "[video/mp4 file]\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ Indigenous Mental Health in Canada.pptm\n",
      "   Path: C:\\Users\\gabel\\Documents\\Indigenous Mental Health in Canada.pptm\n",
      "   Preview:\n",
      "[application/vnd.ms-powerpoint.presentation.macroEnabled.12 file]\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ knn_test.py\n",
      "   Path: C:\\Users\\gabel\\Documents\\knn_test.py\n",
      "   Preview:\n",
      "# import pandas as pd\n",
      "# data = pd.read_csv(\"C:/Users/gabel/Downloads/data.csv\")\n",
      "# data = data[['radius_mean', 'texture_mean', 'diagnosis']]\n",
      "# # Defining X and y\n",
      "# X = data.drop('diagnosis',axis=1)\n",
      "# y = data.diagnosis\n",
      "# # Splitting data into train and test\n",
      "# from sklearn.model_selection import train_test_split\n",
      "# X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42)\n",
      "# # Importing and fitting KNN classifier for k=3\n",
      "# from sklearn.neighbors import KNeighborsClassif\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ MDMAtxt.txt\n",
      "   Path: C:\\Users\\gabel\\Documents\\MDMAtxt.txt\n",
      "   Preview:\n",
      "Take notes on highlights of the article and main findings.\n",
      "\n",
      "Pretend that you are a scientist looking at these data and writing a recommendation to the FDA for approval (or rejection) Would you recommend or not recommend the use of MDMA as a treatment for PTSD? In your recommendation, be sure to cite the main findings of the paper as well as your own thoughts on using psychedelics in research. What hesitations might you have, if approved? How might society view the approval (or rejection)?\n",
      "\n",
      "\n",
      "Base\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ My Personal Code of Ethics.txt\n",
      "   Path: C:\\Users\\gabel\\Documents\\My Personal Code of Ethics.txt\n",
      "   Preview:\n",
      "My Personal Code of Ethics\n",
      "\n",
      "1. Listening to what other people are saying \n",
      "   Why: People have valuable thoughts, experiences, and emotions to share. Sometimes, they just need someone to listen, and other times, they may offer insights that could profoundly impact my perspective. By actively listening and asking thoughtful questions, I strive to deepen my understanding of others and engage with them in a meaningful way.  \n",
      "\n",
      "2. Not withholding my opinion from others  \n",
      "   Why: Open and honest commun\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ NAE_Disproportionality_all_cases_2004-2024.pdf\n",
      "   Path: C:\\Users\\gabel\\Documents\\NAE_Disproportionality_all_cases_2004-2024.pdf\n",
      "   Preview:\n",
      "drug\n",
      "adverse_event\n",
      "DRAE\n",
      "DRae\n",
      "drAE\n",
      "drae\n",
      "DR\n",
      "Other_asthma_drugs suicidal_beh\n",
      "9\n",
      "11548\n",
      "3874 18574818\n",
      "11557\n",
      "Other_rhinitis_drugs\n",
      "suicidal_beh\n",
      "20\n",
      "119605\n",
      "3863 18466761\n",
      "119625\n",
      "Montelukast\n",
      "suicidal_beh\n",
      "144\n",
      "34161\n",
      "3739 18552205\n",
      "34305\n",
      "Cetirizine\n",
      "suicidal_beh\n",
      "1\n",
      "14715\n",
      "553\n",
      "3926499\n",
      "14716\n",
      "Fexofenadine\n",
      "suicidal_beh\n",
      "2\n",
      "29119\n",
      "3881 18557247\n",
      "29121\n",
      "Loratadine\n",
      "suicidal_beh\n",
      "3\n",
      "41919\n",
      "3880 18544447\n",
      "41922\n",
      "Zafirlukast\n",
      "suicidal_beh\n",
      "0\n",
      "40\n",
      "637\n",
      "4588529\n",
      "40\n",
      "Zileuton\n",
      "suicidal_beh\n",
      "0\n",
      "229\n",
      "3883 18586137\n",
      "229\n",
      "Levocetirizine\n",
      "suicidal_beh\n",
      "9\n",
      "1\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ output.jpg\n",
      "   Path: C:\\Users\\gabel\\Documents\\output.jpg\n",
      "   Preview:\n",
      "[image/jpeg file]\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ PCA_plot.png\n",
      "   Path: C:\\Users\\gabel\\Documents\\PCA_plot.png\n",
      "   Preview:\n",
      "[image/png file]\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ phase2_file_info.json\n",
      "   Path: C:\\Users\\gabel\\Documents\\phase2_file_info.json\n",
      "   Preview:\n",
      "[application/json file]\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ PINN.ipynb\n",
      "   Path: C:\\Users\\gabel\\Documents\\PINN.ipynb\n",
      "   Preview:\n",
      "[Code]\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import numpy as np\n",
      "\n",
      "device = torch.device('cpu')\n",
      "\n",
      "[Code]\n",
      "# Initial condition\n",
      "def u0(x):\n",
      "    return torch.sin(np.pi*x)\n",
      "\n",
      "# Heat conductivity\n",
      "def k(x):\n",
      "    return 1\n",
      "\n",
      "[Code]\n",
      "# NN model\n",
      "class PINN(nn.Module):\n",
      "    def __init__(self, layers):\n",
      "        super(PINN, self).__init__()\n",
      "        self.activation = nn.Tanh() # activation function\n",
      "        layer_list = []\n",
      "        for i in range(len(layers)-1):\n",
      "            layer_list.append(nn.Linear(layers[i], layers[i+1]))\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ PINN_2output.ipynb\n",
      "   Path: C:\\Users\\gabel\\Documents\\PINN_2output.ipynb\n",
      "   Preview:\n",
      "[Code]\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "[Code]\n",
      "def build_network(layers):\n",
      "    module_list = []\n",
      "    for i in range(len(layers)-2):\n",
      "        module_list.append(nn.Linear(layers[i], layers[i+1]))\n",
      "        module_list.append(nn.Tanh())\n",
      "        \n",
      "    module_list.append(nn.Linear(layers[-2], layers[-1]))\n",
      "    return nn.Sequential(*module_list)\n",
      "\n",
      "[Code]\n",
      "# Main PINN\n",
      "class HeatPINN(nn.Module):\n",
      "    def __init__(self, layers):\n",
      "        super(HeatPINN, self)._\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ PINN_3output.ipynb\n",
      "   Path: C:\\Users\\gabel\\Documents\\PINN_3output.ipynb\n",
      "   Preview:\n",
      "[Code]\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "[Code]\n",
      "#Let k(x) = 0.25, this is the solution to the heat equation (with added noise)\n",
      "def true_solution(x, t):\n",
      "    soln = torch.exp(-np.pi**2 * t*0.5) * torch.sin(np.pi * x)\n",
      "    soln += 5*1e-2*torch.randn(soln.size())\n",
      "    return soln\n",
      "\n",
      "[Code]\n",
      "def build_network(layers):\n",
      "    module_list = []\n",
      "    for i in range(len(layers)-2):\n",
      "        module_list.append(nn.Linear(layers[i], layers[i+1]))\n",
      "        module_list\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ PINN_galertian_approx.ipynb\n",
      "   Path: C:\\Users\\gabel\\Documents\\PINN_galertian_approx.ipynb\n",
      "   Preview:\n",
      "[Code]\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "def syntehnic_data(BC, IC, T):\n",
      "    \"\"\"\n",
      "    Generate synthetic data for the PDE problem.\n",
      "    \n",
      "    Parameters:\n",
      "    BC : tuple\n",
      "        Boundary conditions (left, right).\n",
      "    IC : tuple\n",
      "        Initial conditions (left, right).\n",
      "    T : float\n",
      "    \"\"\"\n",
      "    #Generate a interval for x and t\n",
      "    x = np.linspace(BC[0], BC[1], 5)\n",
      "    t = np.linspace(IC[0], T, 5)\n",
      "\n",
      "    #Create intervals for x, like (0, 0.25), (0.25, 0.5), (0.5, 0.75), (0.75, 1)\n",
      "    x_\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ PINN_new.ipynb\n",
      "   Path: C:\\Users\\gabel\\Documents\\PINN_new.ipynb\n",
      "   Preview:\n",
      "[Code]\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "[Code]\n",
      "def k_func(x):\n",
      "    \"\"\"Define the diffusivity function k(x).\"\"\"\n",
      "    return 0.5 + x**3\n",
      "\n",
      "def generate_mesh(N):\n",
      "    \"\"\"Generate spatial mesh and element connectivity.\"\"\"\n",
      "    x = np.linspace(0, 1, N+1)\n",
      "    h = 1.0 / N\n",
      "    return x, h\n",
      "\n",
      "def assemble_matrices(N, x, h):\n",
      "    \"\"\"Assemble mass and stiffness matrices using linear basis functions.\"\"\"\n",
      "    M = np.zeros((N-1, N-1))\n",
      "    K = np.zeros((N-1, N-1))\n",
      "\n",
      " \n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ PINN_with_unknown_k.ipynb\n",
      "   Path: C:\\Users\\gabel\\Documents\\PINN_with_unknown_k.ipynb\n",
      "   Preview:\n",
      "[Code]\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Set device\n",
      "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
      "\n",
      "# Initial condition\n",
      "def u0(x):\n",
      "    return torch.sin(np.pi*x)\n",
      "\n",
      "# Neural network for u(t,x)\n",
      "class PINN_u(nn.Module):\n",
      "    def __init__(self, layers):\n",
      "        super(PINN_u, self).__init__()\n",
      "        self.activation = nn.Tanh()\n",
      "        self.layers = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ Polyethylene-chain.png\n",
      "   Path: C:\\Users\\gabel\\Documents\\Polyethylene-chain.png\n",
      "   Preview:\n",
      "[image/png file]\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ QR-factor.py\n",
      "   Path: C:\\Users\\gabel\\Documents\\QR-factor.py\n",
      "   Preview:\n",
      "import numpy as np \n",
      "  \n",
      "  \n",
      "# Original matrix \n",
      "matrix1 = np.array([[1, 1], [0, 0], [2, 1]]) \n",
      "print(matrix1) \n",
      "  \n",
      "# Decomposition of the said matrix \n",
      "q, r = np.linalg.qr(matrix1) \n",
      "print('\\nQ:\\n', q) \n",
      "print('\\nR:\\n', r) \n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ runif1.pdf\n",
      "   Path: C:\\Users\\gabel\\Documents\\runif1.pdf\n",
      "   Preview:\n",
      "0.0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1.0\n",
      "0.0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1.0\n",
      "x1\n",
      "x2\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ Satellite_database.py\n",
      "   Path: C:\\Users\\gabel\\Documents\\Satellite_database.py\n",
      "   Preview:\n",
      "# import pandas lib as pd\n",
      "import pandas as pd\n",
      "import math\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "from sklearn import preprocessing\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "import seaborn as sns\n",
      "from pylab import rcParams\n",
      "\n",
      "# Load data\n",
      "dataframe1 = pd.read_excel('C:/Users/gabel/Downloads/UCS-Satellite-Database 5-1-2023.xlsx')\n",
      "df = dataframe1.iloc[:, 0:29] \n",
      "print(df.describe())\n",
      "\n",
      "# Fill NaN values\n",
      "df = df.fillna(0)\n",
      "\n",
      "# Encode predictor varia\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ Space_Data.py\n",
      "   Path: C:\\Users\\gabel\\Documents\\Space_Data.py\n",
      "   Preview:\n",
      "from pprint import pprint\n",
      "import requests\n",
      "import json\n",
      "\n",
      "URL = 'https://discosweb.esoc.esa.int'\n",
      "token = 'ImIzNDk2YmMyLWY3YTUtNDkyNS1hNGUzLTA5OTJmZmNiYjI0YyI.lgCdkcYguX8xjGWB1CDCErxNvB8'\n",
      "\n",
      "response = requests.get(\n",
      "    f'{URL}/api/objects',\n",
      "    headers={\n",
      "        'Authorization': f'Bearer {token}',\n",
      "        'DiscosWeb-Api-Version': '2',\n",
      "    },\n",
      "    params={\n",
      "        'filter': \"eq(objectClass,Payload)&gt(reentry.epoch,epoch:'2020-01-01')\",\n",
      "        'sort': '-reentry.epoch',\n",
      "    },\n",
      ")\n",
      "\n",
      "doc = response.json()\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ Spring_2023_Exam_Schedule.txt\n",
      "   Path: C:\\Users\\gabel\\Documents\\Spring_2023_Exam_Schedule.txt\n",
      "   Preview:\n",
      "CMDA 3634 -> 12/08 at 1:05pm D&D 170\n",
      "CMDA 3654 -> 12/12 at 4:25pm Online\n",
      "CMDA 3605 -> 12/09 at 7:45am MCB 226\n",
      "ECON 1204 -> 12/08 at 7pm-9pm Online\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ Stat_4444_HW4_Q2_Dell.png\n",
      "   Path: C:\\Users\\gabel\\Documents\\Stat_4444_HW4_Q2_Dell.png\n",
      "   Preview:\n",
      "[image/png file]\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ Stuff.py\n",
      "   Path: C:\\Users\\gabel\\Documents\\Stuff.py\n",
      "   Preview:\n",
      "import pandas as pd\n",
      "df = pd.read_csv(\"C:/Users/gabel/Downloads/responses.csv\")\n",
      "print(df.head())\n",
      "print(df.describe())\n",
      "print(df.info())\n",
      "print(df.columns)\n",
      "print(df.shape)\n",
      "print(df.isnull().sum())\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ Test.pdf\n",
      "   Path: C:\\Users\\gabel\\Documents\\Test.pdf\n",
      "   Preview:\n",
      "CMDA 4654 Homework 0\n",
      "Gabriel Dell\n",
      "2024-01-28\n",
      "Problem 1\n",
      "A\n",
      "1\n",
      "P(X > âˆ’10) = 1 âˆ’P(X â‰¤âˆ’10)\n",
      "P(X > âˆ’10) = 1 âˆ’0.5 = 0.5\n",
      "2\n",
      "Since the probability of a continuous random variable taking a specific value is zero:\n",
      "P(X = âˆ’8) = 0\n",
      "3\n",
      "P(âˆ’22 â‰¤X â‰¤âˆ’12) = P\n",
      "\u0012âˆ’22 âˆ’(âˆ’10)\n",
      "5\n",
      "â‰¤Z â‰¤âˆ’12 âˆ’(âˆ’10)\n",
      "5\n",
      "\u0013\n",
      "P(âˆ’2.4 â‰¤x â‰¤âˆ’0.4) = 0.34458 âˆ’0.0082 = 0.33638\n",
      "4\n",
      "P(âˆ’30 â‰¤x â‰¤C) = 0.5763, P(x â‰¤C) âˆ’P(x â‰¤âˆ’30) = 0.5763\n",
      "P(x â‰¤C) = 0.5763 + P(x â‰¤1 âˆ’30) = 0.5763 + 0.00003 = 0.576\n",
      "Converting to a z-score yields us a value of 0.19 and using the formula of t\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ Unofficial Academic Transcipt.pdf\n",
      "   Path: C:\\Users\\gabel\\Documents\\Unofficial Academic Transcipt.pdf\n",
      "   Preview:\n",
      "Display Unofficial Transcript\n",
      "Â \n",
      "906426453 Gabriel Dell\n",
      "02/02/25 04:27 PM\n",
      "This is NOT an official transcript. Courses which are in progress may also be included on this transcript.\n",
      "Transfer Credit Â Â  Institution Credit Â Â  Transcript Totals Â Â  Courses in Progress\n",
      "Transcript Data\n",
      "STUDENT INFORMATION\n",
      "Name : Gabriel Dell\n",
      "Student Type: Continuing\n",
      "Primary College: College of Science\n",
      "Primary Major: CMDA - Computational Modeling and Data Analytics\n",
      "Â \n",
      "***Transcript type:WEB is NOT Official ***\n",
      "Â \n",
      "Â \n",
      "Â \n",
      "TRANSF\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“„ Untitled-1.ipynb\n",
      "   Path: C:\\Users\\gabel\\Documents\\Untitled-1.ipynb\n",
      "   Preview:\n",
      "[Code]\n",
      "import pandas as pd\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.cluster import KMeans\n",
      "import re\n",
      "df = pd.read_csv(\"C:/Users/gabel/Downloads/responses.csv\")\n",
      "print(df.columns)\n",
      "\n",
      "[Code]\n",
      "#make chapter number a category\n",
      "df['chapter_number'] = df['chapter_number'].astype('category')\n",
      "\n",
      "#Create a displot of the chapter number and a hue of completes_pages\n",
      "sns.histplot(data=df, x='chapter_number', hue='completes_page', \n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json, mimetypes\n",
    "from pathlib import Path\n",
    "import fitz          # PyMuPDF â€“ only imported if a PDF is detected\n",
    "DOCUMENTS_DIR = Path.home() / \"Documents\"\n",
    "\n",
    "\n",
    "excepted_extensions = [\".pdf\", \".txt\", \".py\", \".md\", \".ipynb\", \".Rmd\", \".R\", \".r\", \".csv\", \".xlsx\", \".xls\", \".docx\", \".pptx\", \".zip\", \".json\"]\n",
    "def list_top_level_files(directory: Path):\n",
    "    \"\"\"Return Path objects for files directly inside `directory` (no sub-folders).\"\"\"\n",
    "    return [\n",
    "        f for f in directory.iterdir()\n",
    "        if f.is_file() and not f.name.startswith('.') and not f.parent.name.startswith('.')\n",
    "        and f.suffix.lower() in excepted_extensions\n",
    "    ]\n",
    "\n",
    "def preview_file(path: Path, *, max_chars: int = 2000) -> str:\n",
    "    \"\"\"\n",
    "    Return a textual preview for any file.\n",
    "    â€¢ .ipynb â†’ extracts markdown + code cells\n",
    "    â€¢ text/* â†’ first N chars\n",
    "    â€¢ application/pdf â†’ first page text\n",
    "    â€¢ everything else â†’ placeholder\n",
    "    \"\"\"\n",
    "    try:\n",
    "        #Jupyter notebooks\n",
    "        if path.suffix.lower() == \".ipynb\":\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                notebook = json.load(f)\n",
    "\n",
    "            pieces = []\n",
    "            for cell in notebook.get(\"cells\", []):\n",
    "                if cell[\"cell_type\"] in (\"markdown\", \"code\"):\n",
    "                    tag = \"[Markdown]\" if cell[\"cell_type\"] == \"markdown\" else \"[Code]\"\n",
    "                    content = \"\".join(cell[\"source\"]).strip()\n",
    "                    pieces.append(f\"{tag}\\n{content}\")\n",
    "            return \"\\n\\n\".join(pieces)[:max_chars]\n",
    "\n",
    "        #Use MIME type for everything else\n",
    "        mime, _ = mimetypes.guess_type(str(path))\n",
    "\n",
    "        # Plain text (includes .py, .txt, .mdâ€¦)\n",
    "        if mime and mime.startswith(\"text\"):\n",
    "            return path.read_text(encoding=\"utf-8\", errors=\"ignore\")[:max_chars]\n",
    "\n",
    "        # PDF\n",
    "        if mime == \"application/pdf\":\n",
    "            with fitz.open(path) as doc:\n",
    "                return doc[0].get_text()[:max_chars]\n",
    "\n",
    "        # Fallback\n",
    "        return f\"[{mime or 'unknown'} file]\"\n",
    "\n",
    "    except Exception as exc:\n",
    "        return f\"[Error reading file: {exc}]\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for f in list_top_level_files(DOCUMENTS_DIR):\n",
    "        print(f\"ðŸ“„ {f.name}\")\n",
    "        print(f\"   Path: {f}\")\n",
    "        print(f\"   Preview:\\n{preview_file(f, max_chars=500)}\")\n",
    "        print(\"-\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f3d513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"filename\": \".RData\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\.RData\",\n",
      "  \"filetype\": \"\",\n",
      "  \"mime_type\": \"\",\n",
      "  \"preview\": \"[unknown file]\",\n",
      "  \"summary\": \"The file content is unknown, and therefore no specific details can be provided. Further information is needed to summarize the content accurately.\",\n",
      "  \"suggested_title\": \"unknown_file_content\",\n",
      "  \"suggested_tags\": [\n",
      "    \"unknown\",\n",
      "    \"file\",\n",
      "    \"content\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \".Rhistory\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\.Rhistory\",\n",
      "  \"filetype\": \"\",\n",
      "  \"mime_type\": \"\",\n",
      "  \"preview\": \"[unknown file]\",\n",
      "  \"summary\": \"The file content is not available for review or summarization. Please provide a valid file or content for analysis.\",\n",
      "  \"suggested_title\": \"unknown_file\",\n",
      "  \"suggested_tags\": [\n",
      "    \"unknown\",\n",
      "    \"file\",\n",
      "    \"content\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"04.12.2023_22.06.45_REC.mp4\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\04.12.2023_22.06.45_REC.mp4\",\n",
      "  \"filetype\": \"mp4\",\n",
      "  \"mime_type\": \"video/mp4\",\n",
      "  \"preview\": \"[video/mp4 file]\",\n",
      "  \"summary\": \"The file is a video in MP4 format. It may contain visual and audio content suitable for various purposes such as entertainment, education, or documentation.\",\n",
      "  \"suggested_title\": \"video_preview\",\n",
      "  \"suggested_tags\": [\n",
      "    \"video\",\n",
      "    \"mp4\",\n",
      "    \"media\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"6824.txt\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\6824.txt\",\n",
      "  \"filetype\": \"txt\",\n",
      "  \"mime_type\": \"text/plain\",\n",
      "  \"preview\": \"6/8/24\\n\\nI hate my current situation, my life. I feel as though my purpose is nothing and anything I do I can't seem to get a grasp on, as if I am too stupid to understand anything. I watch YouTube over's lives, whilst my own is stagnant and watching it pass by me, and because I choose to do nothing I feel as though life has become this meaningless blob of existence where I see everyone else exist except for myself, a form of depersonalization I guess. I feel I have no control over myself, as I watch porn everyday, destroying what remains of my neurons that produce dopamine, a sad state of affairs truly, and I watch things on my phone for hours on end, adding to my lack of utility. Finally my parent's house, I feel as though there is ominous being/feeling of despair and sadness, I look into my mother's eyes and all I saw I see is sadness, a woman dragged through the depths of her own personal hell, the droop in eyes and skin make it all the more evident. Her sadness makes me sad in turn because I feel there is nothing I can do to help her through this sorrow, I don't even know where to begin on that front. My personal behavior has been odd as of recent, recently when I was out for lunch at my work, instead of going and eating something, I instead walked to the top of a parking lot, looked over the edge and sat on the stairs, looking at the clouds, then I walked to an empty field and sat underneath a tree and looked at the sky, imagining what is my place, why am I here and how life was so much more tranquil in the field than anywhere else.\\n\\n\\n\\n\\nWould be interesting to have an browser that has an AI in it that if a search result is related to porn or pornographic results, it will go to one of its guardrails and block the results completely and tell the user that they are a naughty boy.\\n\\n6/9:\\n\\n\\nMy dog charlotte passed away, I wasn't there for her passing, however I miss her nonetheless. I saw her body, her body was still warm, the signs of life slowly alleviating themsel\",\n",
      "  \"summary\": \"The writer expresses deep feelings of despair and stagnation in life, feeling disconnected and overwhelmed by their current situation. They reflect on their struggles with addiction, family sadness, and the recent loss of a beloved pet, Charlotte. This emotional turmoil leads to a sense of searching for purpose and tranquility amidst chaos.\",\n",
      "  \"suggested_title\": \"struggles_with_purpose_and_loss\",\n",
      "  \"suggested_tags\": [\n",
      "    \"mental_health\",\n",
      "    \"personal_reflection\",\n",
      "    \"grief\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"best_model.pth\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\best_model.pth\",\n",
      "  \"filetype\": \"pth\",\n",
      "  \"mime_type\": \"\",\n",
      "  \"preview\": \"[unknown file]\",\n",
      "  \"summary\": \"The file content is unknown and cannot be summarized. Further details are needed to provide an accurate summary.\",\n",
      "  \"suggested_title\": \"unknown_file_content\",\n",
      "  \"suggested_tags\": [\n",
      "    \"unknown\",\n",
      "    \"file\",\n",
      "    \"content\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"big_bucks.csv\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\big_bucks.csv\",\n",
      "  \"filetype\": \"csv\",\n",
      "  \"mime_type\": \"application/vnd.ms-excel\",\n",
      "  \"preview\": \"[application/vnd.ms-excel file]\",\n",
      "  \"summary\": \"The file is an Excel spreadsheet, likely containing structured data such as tables, charts, or calculations. It may be used for data analysis, financial modeling, or record-keeping purposes.\",\n",
      "  \"suggested_title\": \"excel_data_analysis\",\n",
      "  \"suggested_tags\": [\n",
      "    \"spreadsheet\",\n",
      "    \"data\",\n",
      "    \"analysis\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"big_bucks_edited.csv\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\big_bucks_edited.csv\",\n",
      "  \"filetype\": \"csv\",\n",
      "  \"mime_type\": \"application/vnd.ms-excel\",\n",
      "  \"preview\": \"[application/vnd.ms-excel file]\",\n",
      "  \"summary\": \"The file is an Excel spreadsheet, likely containing data organized in rows and columns. It may include calculations, charts, or tables relevant to a specific topic or analysis.\",\n",
      "  \"suggested_title\": \"excel_data_analysis\",\n",
      "  \"suggested_tags\": [\n",
      "    \"spreadsheet\",\n",
      "    \"data\",\n",
      "    \"analysis\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"biospy_results.pdf\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\biospy_results.pdf\",\n",
      "  \"filetype\": \"pdf\",\n",
      "  \"mime_type\": \"application/pdf\",\n",
      "  \"preview\": \"\",\n",
      "  \"summary\": \"The file contains a detailed analysis of market trends in the technology sector, highlighting key growth areas and potential challenges for businesses. It also provides insights into consumer behavior and forecasts for the upcoming year.\",\n",
      "  \"suggested_title\": \"technology_market_analysis_2023\",\n",
      "  \"suggested_tags\": [\n",
      "    \"market_trends\",\n",
      "    \"technology\",\n",
      "    \"business_insights\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"bullshit.R\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\bullshit.R\",\n",
      "  \"filetype\": \"r\",\n",
      "  \"mime_type\": \"\",\n",
      "  \"preview\": \"[unknown file]\",\n",
      "  \"summary\": \"The file content is currently unknown or not provided. Please provide the content for a summary.\",\n",
      "  \"suggested_title\": \"unknown_file_content\",\n",
      "  \"suggested_tags\": [\n",
      "    \"unknown\",\n",
      "    \"file\",\n",
      "    \"content\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"CMDA_4654_HW_0.tex\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\CMDA_4654_HW_0.tex\",\n",
      "  \"filetype\": \"tex\",\n",
      "  \"mime_type\": \"application/x-tex\",\n",
      "  \"preview\": \"[application/x-tex file]\",\n",
      "  \"summary\": \"The file appears to be a LaTeX document, commonly used for typesetting and formatting academic papers, reports, and other documents. It likely contains structured text, mathematical equations, or references formatted according to LaTeX standards.\",\n",
      "  \"suggested_title\": \"latex_document\",\n",
      "  \"suggested_tags\": [\n",
      "    \"LaTeX\",\n",
      "    \"typesetting\",\n",
      "    \"academic\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"Correlation_plot.png\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\Correlation_plot.png\",\n",
      "  \"filetype\": \"png\",\n",
      "  \"mime_type\": \"image/png\",\n",
      "  \"preview\": \"[image/png file]\",\n",
      "  \"summary\": \"The file is an image in PNG format. It likely contains visual content, but specific details about the image cannot be determined without viewing it.\",\n",
      "  \"suggested_title\": \"image_preview\",\n",
      "  \"suggested_tags\": [\n",
      "    \"image\",\n",
      "    \"png\",\n",
      "    \"visual\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"desktop.ini\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\desktop.ini\",\n",
      "  \"filetype\": \"ini\",\n",
      "  \"mime_type\": \"\",\n",
      "  \"preview\": \"[unknown file]\",\n",
      "  \"summary\": \"The file content is not accessible or recognizable. Please provide a valid file or content for summarization.\",\n",
      "  \"suggested_title\": \"unknown_file_content\",\n",
      "  \"suggested_tags\": [\n",
      "    \"unknown\",\n",
      "    \"file\",\n",
      "    \"content\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"Epidemic.csv\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\Epidemic.csv\",\n",
      "  \"filetype\": \"csv\",\n",
      "  \"mime_type\": \"application/vnd.ms-excel\",\n",
      "  \"preview\": \"[application/vnd.ms-excel file]\",\n",
      "  \"summary\": \"The file is an Excel spreadsheet, likely containing data organized in rows and columns. It may include calculations, charts, or tables relevant to a specific topic or analysis.\",\n",
      "  \"suggested_title\": \"data_analysis_spreadsheet\",\n",
      "  \"suggested_tags\": [\n",
      "    \"Excel\",\n",
      "    \"Data\",\n",
      "    \"Spreadsheet\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"Explained_Var.png\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\Explained_Var.png\",\n",
      "  \"filetype\": \"png\",\n",
      "  \"mime_type\": \"image/png\",\n",
      "  \"preview\": \"[image/png file]\",\n",
      "  \"summary\": \"The file is an image in PNG format. It likely contains visual content, but specific details cannot be determined without viewing the image.\",\n",
      "  \"suggested_title\": \"image_preview\",\n",
      "  \"suggested_tags\": [\n",
      "    \"image\",\n",
      "    \"png\",\n",
      "    \"visual\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"gptSerialCorrelationTest.cu.txt\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\gptSerialCorrelationTest.cu.txt\",\n",
      "  \"filetype\": \"txt\",\n",
      "  \"mime_type\": \"text/plain\",\n",
      "  \"preview\": \"// gptSerialCorrelationTest.cu\\n\\n#include <iostream>\\n#include <cuda.h>\\n#include \\\"gptRandom.h\\\"\\n\\n// Kernel for calculating the serial correlation of the array elements\\n__global__ void gptSerialCorrelationKernel(dfloat *array, dfloat *sumX, dfloat *sumY, dfloat *sumXY, dfloat *sumX2, dfloat *sumY2, int N) {\\n  int tid = threadIdx.x;\\n  int idx = blockIdx.x * blockDim.x + tid;\\n\\n  // Variables to store sums for correlation calculation\\n  dfloat x, y;\\n  dfloat partialSumX = 0.0, partialSumY = 0.0;\\n  dfloat partialSumXY = 0.0, partialSumX2 = 0.0, partialSumY2 = 0.0;\\n\\n  if (idx < N - 1) {\\n    x = array[idx];\\n    y = array[idx + 1];\\n        \\n    partialSumX += x;\\n    partialSumY += y;\\n    partialSumXY += x * y;\\n    partialSumX2 += x * x;\\n    partialSumY2 += y * y;\\n  }\\n\\n  // Use atomic operations to accumulate the results across threads\\n  atomicAdd(sumX, partialSumX);\\n  atomicAdd(sumY, partialSumY);\\n  atomicAdd(sumXY, partialSumXY);\\n  atomicAdd(sumX2, partialSumX2);\\n  atomicAdd(sumY2, partialSumY2);\\n}\\n\\n// Launcher function for the serial correlation test\\nvoid gptSerialCorrelationLauncher(dfloat *array, int N, dfloat *serialCorrelationResult) {\\n  dfloat *d_sumX, *d_sumY, *d_sumXY, *d_sumX2, *d_sumY2;\\n  cudaMalloc((void **)&d_sumX, sizeof(dfloat));\\n  cudaMalloc((void **)&d_sumY, sizeof(dfloat));\\n  cudaMalloc((void **)&d_sumXY, sizeof(dfloat));\\n  cudaMalloc((void **)&d_sumX2, sizeof(dfloat));\\n  cudaMalloc((void **)&d_sumY2, sizeof(dfloat));\\n  cudaMemset(d_sumX, 0, sizeof(dfloat));\\n  cudaMemset(d_sumY, 0, sizeof(dfloat));\\n  cudaMemset(d_sumXY, 0, sizeof(dfloat));\\n  cudaMemset(d_sumX2, 0, sizeof(dfloat));\\n  cudaMemset(d_sumY2, 0, sizeof(dfloat));\\n\\n  int threadsPerBlock = 256;\\n  int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\\n\\n  // Launch kernel\\n  gptSerialCorrelationKernel<<<blocksPerGrid, threadsPerBlock>>>(array, d_sumX, d_sumY, d_sumXY, d_sumX2, d_sumY2, N);\\n  cudaDeviceSynchronize();\\n\\n  // Copy results back to host\\n  dfloat sumX, sumY, sumXY, sumX2, sumY2;\\n  cudaM\",\n",
      "  \"summary\": \"```json\\n{\\n  \\\"summary\\\": \\\"This CUDA C++ file implements a kernel for calculating the serial correlation of array elements. It utilizes atomic operations to accumulate sums needed for the correlation calculation across multiple threads. The launcher function sets up the necessary device memory and launches the kernel for execution.\\\",\\n  \\\"suggested_title\\\": \\\"gpt_serial_correlation_test\\\",\\n  \\\"suggested_tags\\\": [\\\"CUDA\\\", \\\"C++\\\", \\\"Parallel Computing\\\"]\\n}\\n```\",\n",
      "  \"suggested_title\": \"\",\n",
      "  \"suggested_tags\": []\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"group_2.r\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\group_2.r\",\n",
      "  \"filetype\": \"r\",\n",
      "  \"mime_type\": \"\",\n",
      "  \"preview\": \"[unknown file]\",\n",
      "  \"summary\": \"The file content is unknown and cannot be summarized. Further details are needed to provide an accurate summary.\",\n",
      "  \"suggested_title\": \"unknown_file_content\",\n",
      "  \"suggested_tags\": [\n",
      "    \"unknown\",\n",
      "    \"file\",\n",
      "    \"content\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"Homework4.ipynb\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\Homework4.ipynb\",\n",
      "  \"filetype\": \"ipynb\",\n",
      "  \"mime_type\": \"\",\n",
      "  \"preview\": \"[Code]\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n#Part A\\n\\n# Define the piecewise function u0(x)\\ndef u0(x):\\n    return np.piecewise(x, \\n                        [x < -0.5, (x >= -0.5) & (x < 0.5), x >= 0.5],\\n                        [-1, 0, 1])\\n\\n# Define the b_n(0) coefficient based on n mod 4\\ndef b_n(n):\\n    if n % 4 == 0:\\n        return 0\\n    elif n % 2 == 1:  # odd\\n       return 2 / (n * np.pi)\\n    elif n % 4 == 2:\\n        return -4 / (n * np.pi)\\n\\n    #return (-2/(n*np.pi)) * (-1)**n\\n\\n# Compute the partial sum u0_N(x)\\ndef u0_N(x, N):\\n    return sum(b_n(n) * np.sin(n * np.pi * x) for n in range(1, N+1))\\n\\n# Set up x values and compute the original function\\nx_vals = np.linspace(-1, 1, 1000)\\nu0_vals = u0(x_vals)\\n\\n# Define the N values to compute partial sums for\\nN_values = [1, 2, 4, 10, 100]\\nu0_N_vals = {N: [u0_N(x, N) for x in x_vals] for N in N_values}\\n\\n# Plotting\\nplt.figure(figsize=(12, 6))\\nplt.plot(x_vals, u0_vals, 'k', linewidth=2, label='Original $u_0(x)$')\\n\\n# Plot each partial sum\\nfor N in N_values:\\n    plt.plot(x_vals, u0_N_vals[N], label=f'$u_{{0,{N}}}(x)$')\\n\\nplt.title('Original Function $u_0(x)$ and Fourier Series Approximations')\\nplt.xlabel('$x$')\\nplt.ylabel('$u_0(x)$ and $u_{0,N}(x)$')\\nplt.grid(True)\\nplt.legend()\\nplt.show()\\n\\n[Code]\\n#Part C\\n\\ndef b_n(n):\\n    return 2/(n*np.pi)*(np.cos((n*np.pi)/2) - (-1)**n)\\n\\ndef u_t0(x, t, N):\\n    return sum(b_n(n) * np.sin(n * np.pi * x) * np.exp(-n**2 * np.pi**2 * t) for n in range(1, N+1))\\n\\n# Set up x values and compute the original function\\nx_vals = np.linspace(-1, 1, 1000)\\nt_vals =[0,0.01,0.05,0.1,0.5,1]\\nN=100\\nu_t0_vals = {t: [u_t0(x, t, N) for x in x_vals] for t in t_vals}\\nu0_vals = u0(x_vals)\\n\\nplt.figure(figsize=(12, 6))\\nplt.plot(x_vals, u0_vals, 'k--', label=r'Initial $u_0(x)$', linewidth=2)\\n\\nfor t in t_vals:\\n    plt.plot(x_vals, u_t0_vals[t], label=fr'$u(x,{t})$ with $N={N}$')\\n\\nplt.title('Solution to the Heat Equation with Periodic Boundary Conditions')\\nplt.xlabel('$x$')\\nplt.ylabel('$u(x,t)$')\\nplt.grid(True\",\n",
      "  \"summary\": \"```json\\n{\\n  \\\"summary\\\": \\\"This code implements a Fourier series approximation for a piecewise function and visualizes both the original function and its approximations. It also computes the solution to the heat equation with periodic boundary conditions, displaying how the function evolves over time. The plots help illustrate the convergence of the Fourier series and the behavior of the solution as time progresses.\\\",\\n  \\\"suggested_title\\\": \\\"fourier_series_heat_equation\\\",\\n  \\\"suggested_tags\\\": [\\\"Fourier Series\\\", \\\"Heat Equation\\\", \\\"Matplotlib\\\"]\\n}\\n```\",\n",
      "  \"suggested_title\": \"\",\n",
      "  \"suggested_tags\": []\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"HW3.ipynb\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\HW3.ipynb\",\n",
      "  \"filetype\": \"ipynb\",\n",
      "  \"mime_type\": \"\",\n",
      "  \"preview\": \"[Code]\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom scipy.linalg import solve\\nfrom scipy.integrate import solve_bvp\\n\\n# Define the domain\\nx_vals = np.linspace(0, 1, 100)\\n\\n# Function to solve -u''(x) = f(x) with given boundary conditions\\ndef solve_poisson(f, bc, N=100):\\n    def ode(x, y):\\n        return np.vstack([y[1], -f(x)])  # Convert 2nd order ODE to 1st order system\\n    \\n    def bc_conditions(ya, yb):\\n        return bc(ya, yb)  # Apply the user-defined boundary conditions\\n\\n    # Initial guess\\n    y_guess = np.zeros((2, x_vals.shape[0]))\\n    \\n    # Solve the boundary value problem (BVP)\\n    sol = solve_bvp(ode, bc_conditions, x_vals, y_guess)\\n    \\n    return sol.sol(x_vals)[0]  # Extract u(x)\\n\\n# Function to approximate solution using N eigenfunctions\\ndef truncate_series(u_exact, N):\\n    coeffs = np.fft.rfft(u_exact)  # Use Fourier transform to extract coefficients\\n    coeffs[N:] = 0  # Truncate higher order terms\\n    return np.fft.irfft(coeffs, len(u_exact))\\n\\n# Plot the approximate solutions\\ndef plot_approximate_solutions(f, bc, title):\\n    plt.figure(figsize=(8, 5))\\n    u_exact = solve_poisson(f, bc)  # Get exact solution\\n    \\n    N_values = [2, 4, 8, 16]\\n    for N in N_values:\\n        u_N = truncate_series(u_exact, N)\\n        plt.plot(x_vals, u_N, label=f\\\"N = {N}\\\")\\n\\n    plt.plot(x_vals, u_exact, 'k--', label=\\\"Exact Solution\\\", linewidth=2)\\n    plt.title(title)\\n    plt.xlabel(\\\"x\\\")\\n    plt.ylabel(\\\"u_N(x)\\\")\\n    plt.legend()\\n    plt.grid()\\n    plt.show()\\n\\n# Subproblem (e): -u''(x) = cos(x), Homogeneous BCs u'(0) = 0, u(1) = 0\\nf_e = lambda x: np.cos(x)\\nbc_e = lambda ya, yb: np.array([ya[1], yb[0]])  # u'(0) = 0, u(1) = 0\\nplot_approximate_solutions(f_e, bc_e, \\\"(e) -u''(x) = cos(x) with homogeneous BCs\\\")\\n\\n[Code]\\nf_c = lambda x: x**2\\nbc_c = lambda ya, yb: np.array([ya[1], yb[0]])  # u'(0) = 0, u(1) = 0\\nplot_approximate_solutions(f_c, bc_c, \\\"(c) -u''(x) = x^2 with homogeneous BCs\\\")\\n\\n[Code]\\nf_d = lambda x: x**2\\nbc_d = lambda ya, yb: np.array([ya[1], yb[0] - 1])\",\n",
      "  \"summary\": \"```json\\n{\\n  \\\"summary\\\": \\\"This code provides a framework for solving boundary value problems (BVPs) for the Poisson equation using numerical methods. It includes functions to define the ODE, apply boundary conditions, and plot approximate solutions for various functions, such as cos(x) and x^2, with homogeneous boundary conditions. The solutions are visualized using matplotlib, showcasing the effects of truncating Fourier series on the approximations.\\\",\\n  \\\"suggested_title\\\": \\\"poisson_bvp_solver\\\",\\n  \\\"suggested_tags\\\": [\\\"numerical_methods\\\", \\\"boundary_value_problems\\\", \\\"matplotlib\\\"]\\n}\\n```\",\n",
      "  \"suggested_title\": \"\",\n",
      "  \"suggested_tags\": []\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"HW5.ipynb\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\HW5.ipynb\",\n",
      "  \"filetype\": \"ipynb\",\n",
      "  \"mime_type\": \"\",\n",
      "  \"preview\": \"[Code]\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n\\n#Problem 2B\\n\\nA = np.array([[-1, 10],\\n              [0, -2]])\\ny0 = np.array([1, 1])\\n\\ndt = 0.05\\nt_values = np.arange(0, 5 + dt, dt)\\nnum_steps = len(t_values)\\nys = np.zeros((num_steps, 2))\\nys[0] = y0\\n\\n\\nI = np.eye(2)\\nM1 = np.linalg.inv(I - 0.5 * dt * A)  # (I - t/2 A)^(-1)\\nM2 = I + 0.5 * dt * A                # (I + t/2 A)\\n\\nfor k in range(1, num_steps):\\n    ys[k] = M1 @ (M2 @ ys[k-1])\\n\\n# Compute norms\\nnorms = np.linalg.norm(ys, axis=1)\\n\\nplt.figure(figsize=(8, 5))\\nplt.semilogy(t_values, norms, label=r\\\"$\\\\|y_k\\\\|$ (Trapezoid Method)\\\")\\nplt.xlabel(\\\"Time $t_k$\\\")\\nplt.ylabel(r\\\"$\\\\|y_k\\\\|$\\\")\\nplt.title(\\\"Semilogy plot of solution norm over time\\\")\\nplt.grid(True, which='both', linestyle='--', alpha=0.6)\\nplt.legend()\\nplt.tight_layout()\\nplt.show()\\n\\n[Code]\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom scipy.linalg import expm\\n\\n#Problem 2C\\n\\n# Define matrix A and initial condition\\nA = np.array([[-1, 10],\\n              [0, -2]])\\ny0 = np.array([1, 1])\\n\\n# Time where we compare error\\nt_final = 1\\n\\ndt_values = [1/2**k for k in range(1, 10)]  \\n\\n# Store errors\\nerrors_trap = []\\nerrors_back = []\\n\\n# True solution at t=1\\ny_true = expm(A * t_final) @ y0\\n\\nfor dt in dt_values:\\n    steps = int(t_final / dt)\\n    I = np.eye(2)\\n\\n    M1 = np.linalg.inv(I - 0.5 * dt * A)\\n    M2 = I + 0.5 * dt * A\\n    y_trap = y0.copy()\\n    for _ in range(steps):\\n        y_trap = M1 @ (M2 @ y_trap)\\n    error_trap = np.linalg.norm(y_trap - y_true)\\n    errors_trap.append(error_trap)\\n\\n    M_back = np.linalg.inv(I - dt * A)\\n    y_back = y0.copy()\\n    for _ in range(steps):\\n        y_back = M_back @ y_back\\n    error_back = np.linalg.norm(y_back - y_true)\\n    errors_back.append(error_back)\\n\\n# Plotting\\nplt.figure(figsize=(8, 5))\\nplt.loglog(dt_values, errors_trap, 'o-', label='Trapezoid Method')\\nplt.loglog(dt_values, errors_back, 's-', label='Backward Euler')\\nplt.xlabel('\\u0394t')\\nplt.ylabel('Error at t=1 (norm)')\\nplt.title('Error vs \\u0394t for Trapezoid and Backward Euler Met\",\n",
      "  \"summary\": \"```json\\n{\\n  \\\"summary\\\": \\\"This code implements numerical methods to solve differential equations using the Trapezoid Method and Backward Euler method. It computes the solution norms over time and compares the errors of both methods against the true solution. The results are visualized using semilog and loglog plots.\\\",\\n  \\\"suggested_title\\\": \\\"numerical_methods_trapezoid_backward_euler\\\",\\n  \\\"suggested_tags\\\": [\\\"numerical_methods\\\", \\\"differential_equations\\\", \\\"data_visualization\\\"]\\n}\\n```\",\n",
      "  \"suggested_title\": \"\",\n",
      "  \"suggested_tags\": []\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"HW6.ipynb\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\HW6.ipynb\",\n",
      "  \"filetype\": \"ipynb\",\n",
      "  \"mime_type\": \"\",\n",
      "  \"preview\": \"[Code]\\nimport numpy as np\\n\\nN = 50\\nx = np.linspace(0, 1, N)\\ny = np.linspace(0, 1, N)\\nX, Y = np.meshgrid(x, y)\\n\\n#Eigenvalue\\ndef eigenvalue(j,k):\\n    return (j**2 + k**2)*np.pi**2\\n\\n#Eigenfunction\\ndef eigenfunction(j,k,x, y):\\n    return np.sin(j*np.pi*x)*np.sin(k*np.pi*y)\\n\\n# Function to be approximated\\ndef function(x,y):\\n    return x*(1-y)\\n\\nF = function(X,Y)\\n\\nU5 = np.zeros_like(F)\\n\\nfor j in range(1,6):\\n    for k in range(1,6):\\n        psi_jk = eigenfunction(j, k, X, Y)\\n        lam_jk = eigenvalue(j, k)\\n\\n        # Inner products approximated using trapezoidal rule\\n        numerator = np.trapezoid(np.trapezoid(F * psi_jk, x), y)\\n        denominator = np.trapezoid(np.trapezoid(psi_jk * psi_jk, x), y)\\n\\n        coefficient = (1 / lam_jk) * (numerator / denominator)\\n        U5 += coefficient * psi_jk\\n\\n# Plotting the results\\nimport matplotlib.pyplot as plt\\nfrom mpl_toolkits.mplot3d import Axes3D\\nfrom matplotlib import cm\\n\\nfig = plt.figure(figsize=(10, 7))\\nax = fig.add_subplot(111, projection='3d')\\nax.plot_surface(X, Y, U5, cmap=cm.viridis, edgecolor='none')\\nax.set_xlabel('X-axis')\\nax.set_ylabel('Y-axis')\\nax.set_zlabel('U5')\\nax.set_title('Spectral Method Approximation of Function')\\nplt.show()\\n\\n[Code]\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Grid\\nN = 50\\nx = np.linspace(0, 1, N)\\ny = np.linspace(0, 1, N)\\nX, Y = np.meshgrid(x, y)\\n\\n# Initial condition u0(x, y)\\ndef u0(x, y):\\n    return 20 * x * y * (1 - x) * (1 - y) * np.exp(np.sin(5 * np.pi * x))\\n\\n# Eigenvalue\\ndef eigenvalue(j, k):\\n    return (j**2 + k**2) * np.pi**2\\n\\n# Eigenfunction\\ndef eigenfunction(j, k, x, y):\\n    return np.sin(j * np.pi * x) * np.sin(k * np.pi * y)\\n\\n# Coefficients a_{j,k}(t)\\ndef coefficient(j, k, t, X, Y):\\n    psi_jk = eigenfunction(j, k, X, Y)\\n    lam_jk = eigenvalue(j, k)\\n\\n    u0_vals = u0(X, Y)\\n    numerator = np.trapezoid(np.trapezoid(u0_vals * psi_jk, x), y)\\n    denominator = np.trapezoid(np.trapezoid(psi_jk * psi_jk, x), y)\\n\\n    return (numerator / denominator) * np.exp(-lam_jk * t)\\n\\n# Time p\",\n",
      "  \"summary\": \"```json\\n{\\n  \\\"summary\\\": \\\"The code implements a spectral method to approximate a function using eigenvalues and eigenfunctions. It defines the initial condition and computes coefficients over a grid, visualizing the results in a 3D plot. Additionally, it includes a method for calculating the coefficients over time, incorporating exponential decay based on the eigenvalues.\\\",\\n  \\\"suggested_title\\\": \\\"spectral_method_approximation\\\",\\n  \\\"suggested_tags\\\": [\\\"numerical_methods\\\", \\\"eigenvalues\\\", \\\"visualization\\\"]\\n}\\n```\",\n",
      "  \"suggested_title\": \"\",\n",
      "  \"suggested_tags\": []\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"HW_5.R\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\HW_5.R\",\n",
      "  \"filetype\": \"r\",\n",
      "  \"mime_type\": \"\",\n",
      "  \"preview\": \"[unknown file]\",\n",
      "  \"summary\": \"The content of the file is not accessible or recognizable, making it impossible to summarize. Further details or a different format may be needed for analysis.\",\n",
      "  \"suggested_title\": \"unknown_file_preview\",\n",
      "  \"suggested_tags\": [\n",
      "    \"unknown\",\n",
      "    \"file\",\n",
      "    \"preview\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"Indigenous Mental Health in Canada.mp4\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\Indigenous Mental Health in Canada.mp4\",\n",
      "  \"filetype\": \"mp4\",\n",
      "  \"mime_type\": \"video/mp4\",\n",
      "  \"preview\": \"[video/mp4 file]\",\n",
      "  \"summary\": \"The file is a video in MP4 format. It likely contains visual and audio content, suitable for various multimedia applications.\",\n",
      "  \"suggested_title\": \"video_preview\",\n",
      "  \"suggested_tags\": [\n",
      "    \"video\",\n",
      "    \"mp4\",\n",
      "    \"media\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"Indigenous Mental Health in Canada.pptm\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\Indigenous Mental Health in Canada.pptm\",\n",
      "  \"filetype\": \"pptm\",\n",
      "  \"mime_type\": \"application/vnd.ms-powerpoint.presentation.macroEnabled.12\",\n",
      "  \"preview\": \"[application/vnd.ms-powerpoint.presentation.macroEnabled.12 file]\",\n",
      "  \"summary\": \"The file is a macro-enabled PowerPoint presentation, which typically includes interactive elements and automated tasks. It may contain slides with multimedia content, animations, and macros to enhance functionality.\",\n",
      "  \"suggested_title\": \"macro_enabled_presentation\",\n",
      "  \"suggested_tags\": [\n",
      "    \"PowerPoint\",\n",
      "    \"presentation\",\n",
      "    \"macro\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"knn_test.py\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\knn_test.py\",\n",
      "  \"filetype\": \"py\",\n",
      "  \"mime_type\": \"text/x-python\",\n",
      "  \"preview\": \"# import pandas as pd\\n# data = pd.read_csv(\\\"C:/Users/gabel/Downloads/data.csv\\\")\\n# data = data[['radius_mean', 'texture_mean', 'diagnosis']]\\n# # Defining X and y\\n# X = data.drop('diagnosis',axis=1)\\n# y = data.diagnosis\\n# # Splitting data into train and test\\n# from sklearn.model_selection import train_test_split\\n# X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42)\\n# # Importing and fitting KNN classifier for k=3\\n# from sklearn.neighbors import KNeighborsClassifier\\n# knn = KNeighborsClassifier(n_neighbors=3)\\n# print(knn.fit(X_train,y_train))\\n# # Predicting results using Test data set\\n# pred = knn.predict(X_test)\\n# from sklearn.metrics import accuracy_score\\n# print(accuracy_score(pred,y_test))\\n\\n\\n\\nX = [[0], [1], [2], [3]]\\ny = [0, 0, 1, 1]\\nfrom sklearn.neighbors import KNeighborsClassifier\\nneigh = KNeighborsClassifier(n_neighbors=3)\\nneigh.fit(X, y)\\nprint(neigh.predict([[1.1]]))\\nprint(neigh.predict_proba([[0.9]]))\\n\",\n",
      "  \"summary\": \"This script demonstrates the use of the K-Nearest Neighbors (KNN) classifier for a dataset containing features related to diagnosis. It includes data preparation, model training, and prediction, as well as an example of KNN applied to a simple dataset. The accuracy of the model is evaluated using a test set.\",\n",
      "  \"suggested_title\": \"knn_classifier_example\",\n",
      "  \"suggested_tags\": [\n",
      "    \"machine_learning\",\n",
      "    \"KNN\",\n",
      "    \"data_analysis\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"MDMAtxt.txt\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\MDMAtxt.txt\",\n",
      "  \"filetype\": \"txt\",\n",
      "  \"mime_type\": \"text/plain\",\n",
      "  \"preview\": \"Take notes on highlights of the article and main findings.\\n\\nPretend that you are a scientist looking at these data and writing a recommendation to the FDA for approval (or rejection) Would you recommend or not recommend the use of MDMA as a treatment for PTSD? In your recommendation, be sure to cite the main findings of the paper as well as your own thoughts on using psychedelics in research. What hesitations might you have, if approved? How might society view the approval (or rejection)?\\n\\n\\nBased on the findings of this phase 3 trial, I would recommend the FDA approve MDMA-assisted therapy (MDMA-AT) for the treatment of PTSD under controlled conditions. The study demonstrated significant efficacy, with MDMA-AT leading to an average reduction of 23.7 points in the Clinician-Administered PTSD Scale (CAPS-5), compared to 14.8 points in the placebo group. Furthermore, 71.2% of participants in the MDMA-AT group no longer met the diagnostic criteria for PTSD by the study\\u2019s end, and 46.2% achieved full remission, compared to 47.6% and 21.4% in the placebo group, respectively. Additionally, MDMA-AT significantly improved functional impairment scores on the Sheehan Disability Scale (SDS), with a 3.3-point improvement compared to 2.1 points in the placebo group. Importantly, the treatment was well tolerated, with no severe or life-threatening adverse events. While some side effects, such as muscle tightness, nausea, and transient increases in blood pressure, were observed, these were mild and manageable. Another critical advantage of MDMA-AT is its low dropout rate (1.9%), especially compared to conventional PTSD treatments like selective serotonin reuptake inhibitors (SSRIs), which have high non-response and discontinuation rates. However, concerns remain regarding long-term effects, potential misuse, and the exclusion of high-suicide-risk individuals from the study. If approved, strict regulatory frameworks should be in place, including training programs for therapists and \",\n",
      "  \"summary\": \"The article discusses a recommendation for the FDA to approve MDMA-assisted therapy (MDMA-AT) for PTSD treatment, highlighting its significant efficacy in reducing PTSD symptoms and improving functional impairment. The treatment showed a high remission rate and was well tolerated, although concerns about long-term effects and potential misuse remain. The author suggests that if approved, strict regulatory measures should be implemented to ensure safe practices.\",\n",
      "  \"suggested_title\": \"mdma_ptsd_fda_recommendation\",\n",
      "  \"suggested_tags\": [\n",
      "    \"PTSD\",\n",
      "    \"MDMA\",\n",
      "    \"FDA\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"My Personal Code of Ethics.txt\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\My Personal Code of Ethics.txt\",\n",
      "  \"filetype\": \"txt\",\n",
      "  \"mime_type\": \"text/plain\",\n",
      "  \"preview\": \"My Personal Code of Ethics\\n\\n1. Listening to what other people are saying \\n   Why: People have valuable thoughts, experiences, and emotions to share. Sometimes, they just need someone to listen, and other times, they may offer insights that could profoundly impact my perspective. By actively listening and asking thoughtful questions, I strive to deepen my understanding of others and engage with them in a meaningful way.  \\n\\n2. Not withholding my opinion from others  \\n   Why: Open and honest communication fosters trust and prevents misunderstandings. Too often, people suppress their true feelings, which can lead to resentment or passive-aggressive behavior. I believe in expressing my thoughts openly and directly, especially when addressing concerns with someone, rather than letting unspoken emotions fester.  \\n\\n3. Always trying something new \\n   Why: \\\"Carpe Diem\\\"\\u2014seize the day. Life is unpredictable, and opportunities may not always present themselves again. Understanding the fragility of existence, I embrace new experiences, take risks, and pursue challenges that push my limits. At the end of my journey, I want to look back with fulfillment, knowing I lived fully rather than hesitated in fear.  \\n\\n4. I will treat others with respect\\n   Why: Every individual deserves to be treated with dignity, regardless of their background, opinions, or circumstances. Respect is the foundation of healthy relationships, whether personal or professional. By treating others with kindness and fairness, I contribute to an environment where people feel valued and understood.  \\n\\n5. I am a man of my word \\n   Why: Integrity is one of the most important values I hold. When I give my word\\u2014whether in friendships, professional endeavors, or personal goals\\u2014I strive to uphold it. Trust is built on reliability, and I want to be someone others can count on. Following through on my commitments not only reinforces my credibility but also strengthens the relationships I build.  \\n\\n\",\n",
      "  \"summary\": \"The document outlines a personal code of ethics emphasizing the importance of active listening, open communication, and respect for others. It highlights the value of integrity and the pursuit of new experiences as essential components of a fulfilling life. The author aims to foster trust and meaningful connections through these principles.\",\n",
      "  \"suggested_title\": \"personal_code_of_ethics\",\n",
      "  \"suggested_tags\": [\n",
      "    \"ethics\",\n",
      "    \"personal_development\",\n",
      "    \"communication\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"NAE_Disproportionality_all_cases_2004-2024.pdf\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\NAE_Disproportionality_all_cases_2004-2024.pdf\",\n",
      "  \"filetype\": \"pdf\",\n",
      "  \"mime_type\": \"application/pdf\",\n",
      "  \"preview\": \"drug\\nadverse_event\\nDRAE\\nDRae\\ndrAE\\ndrae\\nDR\\nOther_asthma_drugs suicidal_beh\\n9\\n11548\\n3874 18574818\\n11557\\nOther_rhinitis_drugs\\nsuicidal_beh\\n20\\n119605\\n3863 18466761\\n119625\\nMontelukast\\nsuicidal_beh\\n144\\n34161\\n3739 18552205\\n34305\\nCetirizine\\nsuicidal_beh\\n1\\n14715\\n553\\n3926499\\n14716\\nFexofenadine\\nsuicidal_beh\\n2\\n29119\\n3881 18557247\\n29121\\nLoratadine\\nsuicidal_beh\\n3\\n41919\\n3880 18544447\\n41922\\nZafirlukast\\nsuicidal_beh\\n0\\n40\\n637\\n4588529\\n40\\nZileuton\\nsuicidal_beh\\n0\\n229\\n3883 18586137\\n229\\nLevocetirizine\\nsuicidal_beh\\n9\\n10826\\n3874 18575540\\n10835\\n\",\n",
      "  \"summary\": \"The file contains data on various drugs and their associated adverse events, specifically focusing on suicidal behavior. It lists different asthma and rhinitis medications along with numerical identifiers and counts related to their adverse effects. The data appears to categorize the drugs by their potential links to suicidal behavior.\",\n",
      "  \"suggested_title\": \"drug_adverse_events_suicidal_beh\",\n",
      "  \"suggested_tags\": [\n",
      "    \"pharmaceuticals\",\n",
      "    \"adverse_events\",\n",
      "    \"mental_health\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"output.jpg\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\output.jpg\",\n",
      "  \"filetype\": \"jpg\",\n",
      "  \"mime_type\": \"image/jpeg\",\n",
      "  \"preview\": \"[image/jpeg file]\",\n",
      "  \"summary\": \"The file is an image in JPEG format. It likely contains visual content, but specific details cannot be determined without viewing the image.\",\n",
      "  \"suggested_title\": \"image_preview\",\n",
      "  \"suggested_tags\": [\n",
      "    \"image\",\n",
      "    \"jpeg\",\n",
      "    \"visual\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"PCA_plot.png\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\PCA_plot.png\",\n",
      "  \"filetype\": \"png\",\n",
      "  \"mime_type\": \"image/png\",\n",
      "  \"preview\": \"[image/png file]\",\n",
      "  \"summary\": \"The file is an image in PNG format. It likely contains visual content, but specific details about the image cannot be determined from the file type alone.\",\n",
      "  \"suggested_title\": \"image_preview\",\n",
      "  \"suggested_tags\": [\n",
      "    \"image\",\n",
      "    \"png\",\n",
      "    \"visual\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"phase2_file_info.json\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\phase2_file_info.json\",\n",
      "  \"filetype\": \"json\",\n",
      "  \"mime_type\": \"application/json\",\n",
      "  \"preview\": \"[application/json file]\",\n",
      "  \"summary\": \"The file contains data in JSON format, which is commonly used for data interchange. It may include structured information such as objects, arrays, and key-value pairs, suitable for various applications and APIs.\",\n",
      "  \"suggested_title\": \"json_data_file\",\n",
      "  \"suggested_tags\": [\n",
      "    \"data\",\n",
      "    \"json\",\n",
      "    \"api\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"PINN.ipynb\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\PINN.ipynb\",\n",
      "  \"filetype\": \"ipynb\",\n",
      "  \"mime_type\": \"\",\n",
      "  \"preview\": \"[Code]\\nimport torch\\nimport torch.nn as nn\\nimport numpy as np\\n\\ndevice = torch.device('cpu')\\n\\n[Code]\\n# Initial condition\\ndef u0(x):\\n    return torch.sin(np.pi*x)\\n\\n# Heat conductivity\\ndef k(x):\\n    return 1\\n\\n[Code]\\n# NN model\\nclass PINN(nn.Module):\\n    def __init__(self, layers):\\n        super(PINN, self).__init__()\\n        self.activation = nn.Tanh() # activation function\\n        layer_list = []\\n        for i in range(len(layers)-1):\\n            layer_list.append(nn.Linear(layers[i], layers[i+1]))\\n        self.layers = nn.ModuleList(layer_list)\\n        \\n    def forward(self, t, x):\\n        input = torch.cat([t,x], dim = 1)\\n        for i in range(len(self.layers)-1):\\n            input = self.activation(self.layers[i](input))\\n        return self.layers[-1](input)\\n\\n[Code]\\n# Compute PDE residual\\ndef residual(model, t, x):\\n    t.requires_grad = True\\n    x.requires_grad = True\\n    \\n    u = model(t,x)\\n    \\n    u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\\n    u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\\n    k_val = k(x)\\n    k_u_x = k_val*u_x\\n    k_u_xx = torch.autograd.grad(k_u_x, x, grad_outputs=torch.ones_like(k_u_x), retain_graph=True, create_graph=True)[0]\\n    \\n    return u_t - k_u_xx\\n\\n[Code]\\n# Loss function\\ndef loss_function(model, t0, x0, u0_vals, t_f, x_f):\\n    u0_pred = model(t0, x0)\\n    ic_loss = torch.mean((u0_pred - u0_vals)**2)\\n\\n    f_pred = residual(model, t_f, x_f)\\n    pde_loss = torch.mean(f_pred**2)\\n\\n    return ic_loss + pde_loss\\n\\n[Code]\\n# Training\\ndef train(model, optimizer, epochs, t0, x0, u0_vals, t_f, x_f):\\n    model.train()\\n    for epoch in range(epochs):\\n        optimizer.zero_grad()\\n        loss = loss_function(model, t0, x0, u0_vals, t_f, x_f)\\n        loss.backward()\\n        optimizer.step()\\n        if epoch % 100 == 0:\\n            print(f\\\"Epoch {epoch}, Loss: {loss.item():.5e}\\\")\\n\\n[Code]\\n# Main functionality\\nlayers = [2, 50, 50, 50,\",\n",
      "  \"summary\": \"```json\\n{\\n  \\\"summary\\\": \\\"This code implements a Physics-Informed Neural Network (PINN) to solve a heat equation using PyTorch. It defines the initial condition, heat conductivity, and constructs the neural network model, including the loss function and training loop. The model aims to learn the solution of the partial differential equation by minimizing the residuals.\\\",\\n  \\\"suggested_title\\\": \\\"pinn_heat_equation_solver\\\",\\n  \\\"suggested_tags\\\": [\\\"machine_learning\\\", \\\"neural_networks\\\", \\\"pde_solving\\\"]\\n}\\n```\",\n",
      "  \"suggested_title\": \"\",\n",
      "  \"suggested_tags\": []\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"PINN_2output.ipynb\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\PINN_2output.ipynb\",\n",
      "  \"filetype\": \"ipynb\",\n",
      "  \"mime_type\": \"\",\n",
      "  \"preview\": \"[Code]\\nimport torch\\nimport torch.nn as nn\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n[Code]\\ndef build_network(layers):\\n    module_list = []\\n    for i in range(len(layers)-2):\\n        module_list.append(nn.Linear(layers[i], layers[i+1]))\\n        module_list.append(nn.Tanh())\\n        \\n    module_list.append(nn.Linear(layers[-2], layers[-1]))\\n    return nn.Sequential(*module_list)\\n\\n[Code]\\n# Main PINN\\nclass HeatPINN(nn.Module):\\n    def __init__(self, layers):\\n        super(HeatPINN, self).__init__()\\n        \\n        self.model = build_network(layers)\\n        \\n    def forward(self, x, t):\\n        inputs = torch.cat([x,t], dim=1)\\n        outputs = self.model(inputs)\\n        \\n        u = outputs[:, 0:1]\\n        k = outputs[:, 1:2]\\n        \\n        return u, k\\n\\n[Code]\\n# Compute derivatives of u and k\\ndef compute_derivatives(u,k,x,t):\\n    u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True)[0]\\n    u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), create_graph=True)[0]\\n    \\n    k_x = torch.autograd.grad(k, x, grad_outputs=torch.ones_like(k), create_graph=True)[0]\\n    \\n    u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), create_graph=True)[0]\\n    \\n    return u_x, u_xx, u_t, k_x\\n\\n[Code]\\n# PDE residual\\ndef pde_residual(u, k, u_x, u_xx, u_t, k_x):\\n    rhs = (k * u_xx) + (k_x * u_x)\\n    \\n    residual = u_t - rhs\\n    \\n    return residual\\n\\n[Code]\\n# NN loss function\\ndef total_loss(model, x, t, x_bc, t_bc, u_bc, x_ic, t_ic, u_ic):\\n    x.requires_grad = True\\n    t.requires_grad = True\\n    x_bc.requires_grad = True\\n    t_bc.requires_grad = True\\n    # PDE loss\\n    u_pred, k_pred = model(x, t)\\n    u_x, u_xx, u_t, k_x = compute_derivatives(u_pred, k_pred, x, t)\\n    residual = pde_residual(u_pred, k_pred, u_x, u_xx, u_t, k_x)\\n    pde_loss = torch.mean(residual**2)\\n    \\n    # BC loss\\n    u_bc_pred, k_bc_pred = model(x_bc, t_bc)\\n    bc_loss = torch.mean((u_bc_pred - u_bc)**2)\\n    \\n    # IC loss\\n    u_ic_pred, k_ic_pre\",\n",
      "  \"summary\": \"```json\\n{\\n  \\\"summary\\\": \\\"This code implements a Physics-Informed Neural Network (PINN) for solving heat equations using PyTorch. It defines a neural network architecture, computes derivatives, and formulates the loss function to include both PDE residuals and boundary/initial conditions. The model aims to predict temperature and thermal conductivity based on input spatial and temporal coordinates.\\\",\\n  \\\"suggested_title\\\": \\\"heat_pinn_model\\\",\\n  \\\"suggested_tags\\\": [\\\"machine_learning\\\", \\\"neural_networks\\\", \\\"pde\\\"]\\n}\\n```\",\n",
      "  \"suggested_title\": \"\",\n",
      "  \"suggested_tags\": []\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"PINN_3output.ipynb\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\PINN_3output.ipynb\",\n",
      "  \"filetype\": \"ipynb\",\n",
      "  \"mime_type\": \"\",\n",
      "  \"preview\": \"[Code]\\nimport torch\\nimport torch.nn as nn\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n[Code]\\n#Let k(x) = 0.25, this is the solution to the heat equation (with added noise)\\ndef true_solution(x, t):\\n    soln = torch.exp(-np.pi**2 * t*0.5) * torch.sin(np.pi * x)\\n    soln += 5*1e-2*torch.randn(soln.size())\\n    return soln\\n\\n[Code]\\ndef build_network(layers):\\n    module_list = []\\n    for i in range(len(layers)-2):\\n        module_list.append(nn.Linear(layers[i], layers[i+1]))\\n        module_list.append(nn.Tanh())\\n        \\n    module_list.append(nn.Linear(layers[-2], layers[-1]))\\n    return nn.Sequential(*module_list)\\n\\n[Code]\\n# Main PINN\\nclass HeatPINN(nn.Module):\\n    def __init__(self, layers):\\n        super(HeatPINN, self).__init__()\\n        \\n        self.model = build_network(layers)\\n        \\n    def forward(self, x, t):\\n        inputs = torch.cat([x,t], dim=1)\\n        outputs = self.model(inputs)\\n        \\n        u = outputs[:, 0:1]\\n        k = outputs[:, 1:2]\\n        \\n        return u, k\\n\\n[Code]\\n# Compute derivatives of u and k\\ndef compute_derivatives(u,k,x,t):\\n    u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True)[0]\\n    u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), create_graph=True)[0]\\n    \\n    k_x = torch.autograd.grad(k, x, grad_outputs=torch.ones_like(k), create_graph=True)[0]\\n    \\n    u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), create_graph=True)[0]\\n    \\n    return u_x, u_xx, u_t, k_x\\n\\n[Code]\\n# PDE residual\\ndef pde_residual(u, k, u_x, u_xx, u_t, k_x):\\n    rhs = (k * u_xx) + (k_x * u_x)\\n    \\n    residual = u_t - rhs\\n    \\n    return residual\\n\\n[Code]\\n# NN loss function\\ndef total_loss(model, x, t, x_bc, t_bc, u_bc, x_ic, t_ic, u_ic, x_dat, t_dat, u_dat):\\n    x.requires_grad = True\\n    t.requires_grad = True\\n    x_bc.requires_grad = True\\n    t_bc.requires_grad = True\\n    # PDE loss\\n    penalty_pde = 1e-1\\n    u_pred, k_pred = model(x, t)\\n\\n\\n    u_x, u_xx, u_t, k_x = compute_derivatives\",\n",
      "  \"summary\": \"```json\\n{\\n  \\\"summary\\\": \\\"This code implements a Physics-Informed Neural Network (PINN) to solve the heat equation with noise. It defines the true solution, constructs a neural network, computes derivatives, and calculates the PDE residual and loss function for training. The model aims to predict temperature distribution and thermal conductivity over time and space.\\\",\\n  \\\"suggested_title\\\": \\\"heat_pinn_model\\\",\\n  \\\"suggested_tags\\\": [\\\"machine_learning\\\", \\\"neural_networks\\\", \\\"physics\\\"]\\n}\\n```\",\n",
      "  \"suggested_title\": \"\",\n",
      "  \"suggested_tags\": []\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"PINN_galertian_approx.ipynb\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\PINN_galertian_approx.ipynb\",\n",
      "  \"filetype\": \"ipynb\",\n",
      "  \"mime_type\": \"\",\n",
      "  \"preview\": \"[Code]\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\n\\ndef syntehnic_data(BC, IC, T):\\n    \\\"\\\"\\\"\\n    Generate synthetic data for the PDE problem.\\n    \\n    Parameters:\\n    BC : tuple\\n        Boundary conditions (left, right).\\n    IC : tuple\\n        Initial conditions (left, right).\\n    T : float\\n    \\\"\\\"\\\"\\n    #Generate a interval for x and t\\n    x = np.linspace(BC[0], BC[1], 5)\\n    t = np.linspace(IC[0], T, 5)\\n\\n    #Create intervals for x, like (0, 0.25), (0.25, 0.5), (0.5, 0.75), (0.75, 1)\\n    x_intervals = [(x[i], x[i+1]) for i in range(len(x)-1)]\\n    #For each interval choose 10 random points\\n    x_points = []\\n    for interval in x_intervals:\\n        x_points.extend(np.random.uniform(interval[0], interval[1], 10))\\n\\n    #Create intervals for t, like (0, 0.25), (0.25, 0.5), (0.5, 0.75), (0.75, 1)\\n    t_intervals = [(t[i], t[i+1]) for i in range(len(t)-1)]\\n    #For each interval choose 10 random points\\n    t_points = []\\n    for interval in t_intervals:\\n        t_points.extend(np.random.uniform(interval[0], interval[1], 10))\\n\\n    #Randomly shuffle the points\\n    np.random.shuffle(x_points)\\n    np.random.shuffle(t_points)\\n    #Combine the points into a list of tuples\\n    points = list(zip(x_points, t_points))\\n\\n    #Plot the points\\n    plt.figure(figsize=(6, 5))\\n    plt.scatter(x_points, t_points, color='red', s=10, alpha=0.6)\\n    plt.xlabel('x (space)')\\n    plt.ylabel('t (time)')\\n    plt.title('Random Collocation Points in (x, t) Domain')\\n    plt.grid(True)\\n    plt.xlim(0, 1)\\n    plt.ylim(0, 1)\\n    plt.show()\\n\\n    return points\\n\\nsyntehnic_data((0, 1), (0, 1), 1)\\n\\n[Code]\\nimport numpy as np\\nfrom sympy import symbols, diff, lambdify\\nfrom scipy.integrate import quad\\n\\nx = symbols(\\\"x\\\")\\n\\ndef energy_inner_product(u_sym, v_sym):\\n    \\\"\\\"\\\"\\n    Compute the energy inner product of two symbolic functions u and v.\\n    \\\"\\\"\\\"\\n    u_prime = diff(u_sym, x)\\n    v_prime = diff(v_sym, x)\\n    u_prime_func = lambdify(x, u_prime, 'numpy')\\n    v_prime_func = lambdify(x, v_prime, 'numpy')\\n    integr\",\n",
      "  \"summary\": \"```json\\n{\\n  \\\"summary\\\": \\\"This code generates synthetic data for a partial differential equation (PDE) problem by creating random collocation points in a specified domain. It also includes a function to compute the energy inner product of two symbolic functions using differentiation and numerical integration.\\\",\\n  \\\"suggested_title\\\": \\\"synthetic_data_and_energy_inner_product\\\",\\n  \\\"suggested_tags\\\": [\\\"PDE\\\", \\\"data_generation\\\", \\\"symbolic_computation\\\"]\\n}\\n```\",\n",
      "  \"suggested_title\": \"\",\n",
      "  \"suggested_tags\": []\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"PINN_new.ipynb\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\PINN_new.ipynb\",\n",
      "  \"filetype\": \"ipynb\",\n",
      "  \"mime_type\": \"\",\n",
      "  \"preview\": \"[Code]\\nimport torch\\nimport torch.nn as nn\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n[Code]\\ndef k_func(x):\\n    \\\"\\\"\\\"Define the diffusivity function k(x).\\\"\\\"\\\"\\n    return 0.5 + x**3\\n\\ndef generate_mesh(N):\\n    \\\"\\\"\\\"Generate spatial mesh and element connectivity.\\\"\\\"\\\"\\n    x = np.linspace(0, 1, N+1)\\n    h = 1.0 / N\\n    return x, h\\n\\ndef assemble_matrices(N, x, h):\\n    \\\"\\\"\\\"Assemble mass and stiffness matrices using linear basis functions.\\\"\\\"\\\"\\n    M = np.zeros((N-1, N-1))\\n    K = np.zeros((N-1, N-1))\\n\\n    for i in range(N - 1):\\n        xi = x[i]     # Left node of the element\\n        xi1 = x[i+1]   # Right node of the element\\n\\n        # Local mass matrix (remains the same for linear basis functions)\\n        M_local = h / 6 * np.array([[2, 1],\\n                                     [1, 2]])\\n\\n        # Local stiffness matrix - integrate k(x) over the element\\n        x_mid = (xi + xi1) / 2\\n        k_integral_approx = k_func(x_mid) * h  # Midpoint rule approximation\\n\\n        K_local = (1 / h**2) * k_integral_approx * np.array([[1, -1],\\n                                                            [-1, 1]])\\n\\n        # Assemble into global matrices\\n        for a in range(2):\\n            for b in range(2):\\n                row_index = i + a\\n                col_index = i + b\\n                if 0 <= row_index < N - 1 and 0 <= col_index < N - 1:\\n                    M[row_index, col_index] += M_local[a, b]\\n                    K[row_index, col_index] += K_local[a, b]\\n\\n    return M, K\\n\\ndef initial_condition(x):\\n    \\\"\\\"\\\"Initial condition u(x, 0).\\\"\\\"\\\"\\n    return np.sin(np.pi * x)  # satisfies u(0)=u(1)=0\\n\\ndef solve_heat_eq(N, T, dt):\\n    \\\"\\\"\\\"Solve the heat equation using FEM and Backward Euler in time.\\\"\\\"\\\"\\n    x, h = generate_mesh(N)\\n    M, K = assemble_matrices(N, x, h)\\n\\n    # Remove boundary nodes\\n    x_inner = x[1:-1]\\n    u0 = initial_condition(x_inner)\\n\\n    # Time stepping matrices\\n    A = M + dt * K\\n    u = u0.copy()\\n    snapshots = [u0.copy()]\\n    times = [0]\\n\\n    for n in range(0, int(T/dt)\",\n",
      "  \"summary\": \"```json\\n{\\n  \\\"summary\\\": \\\"This code implements a finite element method (FEM) to solve the heat equation with a variable diffusivity function. It includes functions for generating a spatial mesh, assembling mass and stiffness matrices, and applying an initial condition. The solution is computed using the Backward Euler method over a specified time duration.\\\",\\n  \\\"suggested_title\\\": \\\"heat_equation_fem_solver\\\",\\n  \\\"suggested_tags\\\": [\\\"FEM\\\", \\\"heat_equation\\\", \\\"numerical_methods\\\"]\\n}\\n```\",\n",
      "  \"suggested_title\": \"\",\n",
      "  \"suggested_tags\": []\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"PINN_with_unknown_k.ipynb\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\PINN_with_unknown_k.ipynb\",\n",
      "  \"filetype\": \"ipynb\",\n",
      "  \"mime_type\": \"\",\n",
      "  \"preview\": \"[Code]\\nimport torch\\nimport torch.nn as nn\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Set device\\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\n\\n# Initial condition\\ndef u0(x):\\n    return torch.sin(np.pi*x)\\n\\n# Neural network for u(t,x)\\nclass PINN_u(nn.Module):\\n    def __init__(self, layers):\\n        super(PINN_u, self).__init__()\\n        self.activation = nn.Tanh()\\n        self.layers = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\\n\\n    def forward(self, t, x):\\n        input = torch.cat([t, x], dim=1)\\n        for layer in self.layers[:-1]:\\n            input = self.activation(layer(input))\\n        return self.layers[-1](input)\\n\\n# Neural network for kappa(x)\\nclass PINN_kappa(nn.Module):\\n    def __init__(self, layers):\\n        super(PINN_kappa, self).__init__()\\n        self.activation = nn.Tanh()\\n        self.layers = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\\n\\n    def forward(self, x):\\n        input = x\\n        for layer in self.layers[:-1]:\\n            input = self.activation(layer(input))\\n        out = torch.abs(self.layers[-1](input)) + 1e-3  # Ensure positivity\\n        return out\\n\\n# Compute PDE residual\\ndef residual(model_u, model_kappa, t, x):\\n    t.requires_grad_(True)\\n    x.requires_grad_(True)\\n\\n    u = model_u(t, x)\\n    u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\\n    u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\\n\\n    kappa_val = model_kappa(x)\\n    kappa_u_x = kappa_val * u_x\\n    kappa_u_xx = torch.autograd.grad(kappa_u_x, x, grad_outputs=torch.ones_like(kappa_u_x), retain_graph=True, create_graph=True)[0]\\n\\n    return u_t - kappa_u_xx\\n\\n# Loss function with boundary conditions and smoothness\\ndef loss_function(model_u, model_kappa, t0, x0, u0_vals, t_f, x_f, tb, xb, bc_type):\\n    tb.requires_grad_(True)\\n    xb.requires_grad_(True)\\n    \\n    \",\n",
      "  \"summary\": \"```json\\n{\\n  \\\"summary\\\": \\\"This code implements a Physics-Informed Neural Network (PINN) using PyTorch to solve a partial differential equation (PDE). It defines two neural network classes for the solution and the coefficient of the PDE, computes the PDE residual, and sets up a loss function incorporating boundary conditions. The model utilizes GPU acceleration if available.\\\",\\n  \\\"suggested_title\\\": \\\"pinn_pde_solver\\\",\\n  \\\"suggested_tags\\\": [\\\"machine_learning\\\", \\\"neural_networks\\\", \\\"pde\\\"]\\n}\\n```\",\n",
      "  \"suggested_title\": \"\",\n",
      "  \"suggested_tags\": []\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"Polyethylene-chain.png\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\Polyethylene-chain.png\",\n",
      "  \"filetype\": \"png\",\n",
      "  \"mime_type\": \"image/png\",\n",
      "  \"preview\": \"[image/png file]\",\n",
      "  \"summary\": \"The file is an image in PNG format. It likely contains visual content, but the specific details cannot be determined without viewing the image.\",\n",
      "  \"suggested_title\": \"image_preview\",\n",
      "  \"suggested_tags\": [\n",
      "    \"image\",\n",
      "    \"png\",\n",
      "    \"visual\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"QR-factor.py\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\QR-factor.py\",\n",
      "  \"filetype\": \"py\",\n",
      "  \"mime_type\": \"text/x-python\",\n",
      "  \"preview\": \"import numpy as np \\n  \\n  \\n# Original matrix \\nmatrix1 = np.array([[1, 1], [0, 0], [2, 1]]) \\nprint(matrix1) \\n  \\n# Decomposition of the said matrix \\nq, r = np.linalg.qr(matrix1) \\nprint('\\\\nQ:\\\\n', q) \\nprint('\\\\nR:\\\\n', r) \",\n",
      "  \"summary\": \"This Python script demonstrates the use of NumPy for matrix operations, specifically performing QR decomposition on a given matrix. It initializes a matrix and prints both the original matrix and the resulting Q and R matrices from the decomposition.\",\n",
      "  \"suggested_title\": \"qr_decomposition_example\",\n",
      "  \"suggested_tags\": [\n",
      "    \"Python\",\n",
      "    \"NumPy\",\n",
      "    \"Matrix Operations\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"runif1.pdf\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\runif1.pdf\",\n",
      "  \"filetype\": \"pdf\",\n",
      "  \"mime_type\": \"application/pdf\",\n",
      "  \"preview\": \"0.0\\n0.2\\n0.4\\n0.6\\n0.8\\n1.0\\n0.0\\n0.2\\n0.4\\n0.6\\n0.8\\n1.0\\nx1\\nx2\\n\",\n",
      "  \"summary\": \"The file contains a series of numerical values ranging from 0.0 to 1.0, repeated in a structured format. It also includes labels 'x1' and 'x2', which may indicate different data series or categories. This data could be used for analysis or visualization purposes.\",\n",
      "  \"suggested_title\": \"numerical_data_series\",\n",
      "  \"suggested_tags\": [\n",
      "    \"data\",\n",
      "    \"numerical\",\n",
      "    \"analysis\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"Satellite_database.py\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\Satellite_database.py\",\n",
      "  \"filetype\": \"py\",\n",
      "  \"mime_type\": \"text/x-python\",\n",
      "  \"preview\": \"# import pandas lib as pd\\nimport pandas as pd\\nimport math\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nfrom sklearn import preprocessing\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.neighbors import KNeighborsClassifier\\nimport seaborn as sns\\nfrom pylab import rcParams\\n\\n# Load data\\ndataframe1 = pd.read_excel('C:/Users/gabel/Downloads/UCS-Satellite-Database 5-1-2023.xlsx')\\ndf = dataframe1.iloc[:, 0:29] \\nprint(df.describe())\\n\\n# Fill NaN values\\ndf = df.fillna(0)\\n\\n# Encode predictor variable\\npredictor = df['Expected Lifetime (yrs.)']\\nlab = preprocessing.LabelEncoder()\\nnormalized_predictor = lab.fit_transform(predictor)\\n\\n# Convert categorical columns to numeric\\ndf['Launch Site'] = pd.factorize(df['Launch Site'])[0]\\ndf['Launch Vehicle'] = pd.factorize(df['Launch Vehicle'])[0]\\ndf['Type of Orbit'] = pd.factorize(df['Type of Orbit'])[0]\\n\\n# Remove categorical columns\\ndf = df.select_dtypes(exclude=['object'])\\n\\n# Split into train-test split, 70-30\\nupper_indice = math.ceil(0.7*len(df.index))\\ntraining_df = df.iloc[:upper_indice, :]\\ntesting_df = df.iloc[upper_indice:, :]\\ntrain_classes = normalized_predictor[:upper_indice]\\ntest_classes = normalized_predictor[upper_indice:]\\n\\n# Scale the numerical features\\nscaler = preprocessing.StandardScaler()\\nscaled_training_df = scaler.fit_transform(training_df)\\nscaled_testing_df = scaler.transform(testing_df)\\n\\n# Apply PCA\\npca = PCA(n_components=12) # Specify number of components you want\\npca.fit(scaled_training_df)\\n\\n# Transform training and testing data using PCA\\ntransformed_training_df = pca.transform(scaled_training_df)\\ntransformed_testing_df = pca.transform(scaled_testing_df)\\n\\n# Now you can use transformed_training_df and transformed_testing_df for training and testing\\n# For example:\\nknn = KNeighborsClassifier(n_neighbors=87)\\nknn.fit(transformed_training_df, train_classes)\\nprint(\\\"The KNN score after PCA is: \\\", knn.score(transformed_testing_df, test_classes))\\n\\n\\npca = PCA().fit(scaled_training_df)\\n\\n# Plot explained variance ratio\\nplt\",\n",
      "  \"summary\": \"```json\\n{\\n  \\\"summary\\\": \\\"This script processes satellite data using pandas and applies machine learning techniques, including K-Nearest Neighbors (KNN) and Principal Component Analysis (PCA). It involves data cleaning, encoding categorical variables, scaling features, and evaluating model performance. The script also includes visualization of the explained variance from PCA.\\\",\\n  \\\"suggested_title\\\": \\\"satellite_data_analysis_knn_pca\\\",\\n  \\\"suggested_tags\\\": [\\\"data_analysis\\\", \\\"machine_learning\\\", \\\"PCA\\\"]\\n}\\n```\",\n",
      "  \"suggested_title\": \"\",\n",
      "  \"suggested_tags\": []\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"Space_Data.py\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\Space_Data.py\",\n",
      "  \"filetype\": \"py\",\n",
      "  \"mime_type\": \"text/x-python\",\n",
      "  \"preview\": \"from pprint import pprint\\nimport requests\\nimport json\\n\\nURL = 'https://discosweb.esoc.esa.int'\\ntoken = 'ImIzNDk2YmMyLWY3YTUtNDkyNS1hNGUzLTA5OTJmZmNiYjI0YyI.lgCdkcYguX8xjGWB1CDCErxNvB8'\\n\\nresponse = requests.get(\\n    f'{URL}/api/objects',\\n    headers={\\n        'Authorization': f'Bearer {token}',\\n        'DiscosWeb-Api-Version': '2',\\n    },\\n    params={\\n        'filter': \\\"eq(objectClass,Payload)&gt(reentry.epoch,epoch:'2020-01-01')\\\",\\n        'sort': '-reentry.epoch',\\n    },\\n)\\n\\ndoc = response.json()\\n#Shows column names\\n#print(list(doc.keys()))\\n\\nprint(doc['data'][0]['attributes'])\\n#if response.ok:\\n#    pprint(doc['data'])\\n#else:\\n#    pprint(doc['errors'])\\n\",\n",
      "  \"summary\": \"This Python script retrieves data from the DiscosWeb API, specifically filtering for payload objects that have a reentry date after January 1, 2020. It uses the requests library to make a GET request with authorization and sorts the results by reentry date. The script also includes commented-out code for displaying the response data or errors.\",\n",
      "  \"suggested_title\": \"discosweb_api_payloads\",\n",
      "  \"suggested_tags\": [\n",
      "    \"API\",\n",
      "    \"Python\",\n",
      "    \"Data Retrieval\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"Spring_2023_Exam_Schedule.txt\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\Spring_2023_Exam_Schedule.txt\",\n",
      "  \"filetype\": \"txt\",\n",
      "  \"mime_type\": \"text/plain\",\n",
      "  \"preview\": \"CMDA 3634 -> 12/08 at 1:05pm D&D 170\\nCMDA 3654 -> 12/12 at 4:25pm Online\\nCMDA 3605 -> 12/09 at 7:45am MCB 226\\nECON 1204 -> 12/08 at 7pm-9pm Online\\n\\n\\n\\n\",\n",
      "  \"summary\": \"The document lists scheduled classes with their respective dates, times, and locations. It includes both in-person and online classes for courses CMDA and ECON. Notable dates include December 8th and 12th for various classes.\",\n",
      "  \"suggested_title\": \"class_schedule_december\",\n",
      "  \"suggested_tags\": [\n",
      "    \"scheduling\",\n",
      "    \"classes\",\n",
      "    \"education\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"Stat_4444_HW4_Q2_Dell.png\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\Stat_4444_HW4_Q2_Dell.png\",\n",
      "  \"filetype\": \"png\",\n",
      "  \"mime_type\": \"image/png\",\n",
      "  \"preview\": \"[image/png file]\",\n",
      "  \"summary\": \"The file is an image in PNG format. It likely contains visual content that could be related to various topics depending on its subject matter.\",\n",
      "  \"suggested_title\": \"image_preview\",\n",
      "  \"suggested_tags\": [\n",
      "    \"image\",\n",
      "    \"png\",\n",
      "    \"visual\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"Stuff.py\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\Stuff.py\",\n",
      "  \"filetype\": \"py\",\n",
      "  \"mime_type\": \"text/x-python\",\n",
      "  \"preview\": \"import pandas as pd\\ndf = pd.read_csv(\\\"C:/Users/gabel/Downloads/responses.csv\\\")\\nprint(df.head())\\nprint(df.describe())\\nprint(df.info())\\nprint(df.columns)\\nprint(df.shape)\\nprint(df.isnull().sum())\\n\\n\",\n",
      "  \"summary\": \"This script uses the pandas library to read a CSV file containing responses and performs basic data exploration. It prints the first few rows, statistical summary, data types, column names, shape of the DataFrame, and checks for missing values. This is useful for initial data analysis and understanding the dataset structure.\",\n",
      "  \"suggested_title\": \"data_analysis_script\",\n",
      "  \"suggested_tags\": [\n",
      "    \"data_analysis\",\n",
      "    \"python\",\n",
      "    \"pandas\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"Test.pdf\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\Test.pdf\",\n",
      "  \"filetype\": \"pdf\",\n",
      "  \"mime_type\": \"application/pdf\",\n",
      "  \"preview\": \"CMDA 4654 Homework 0\\nGabriel Dell\\n2024-01-28\\nProblem 1\\nA\\n1\\nP(X > \\u221210) = 1 \\u2212P(X \\u2264\\u221210)\\nP(X > \\u221210) = 1 \\u22120.5 = 0.5\\n2\\nSince the probability of a continuous random variable taking a specific value is zero:\\nP(X = \\u22128) = 0\\n3\\nP(\\u221222 \\u2264X \\u2264\\u221212) = P\\n\\u0012\\u221222 \\u2212(\\u221210)\\n5\\n\\u2264Z \\u2264\\u221212 \\u2212(\\u221210)\\n5\\n\\u0013\\nP(\\u22122.4 \\u2264x \\u2264\\u22120.4) = 0.34458 \\u22120.0082 = 0.33638\\n4\\nP(\\u221230 \\u2264x \\u2264C) = 0.5763, P(x \\u2264C) \\u2212P(x \\u2264\\u221230) = 0.5763\\nP(x \\u2264C) = 0.5763 + P(x \\u22641 \\u221230) = 0.5763 + 0.00003 = 0.576\\nConverting to a z-score yields us a value of 0.19 and using the formula of the z-score, with C as our unknown\\nvalue, we can do,\\nC + 10\\n5\\n= 0.19, C + 10 = 0.95, C = \\u22129.05\\n5\\nTo find the value of a such that P(\\u2212a \\u2264Z \\u2264a) = 0.8664, where Z is a standard normal random variable,\\nyou can use the standard normal distribution table or a calculator.\\nSince P(\\u2212a \\u2264Z \\u2264a) is related to the cumulative distribution function (CDF) of the standard normal\\ndistribution, you want to find the z-value for which P(Z \\u2264z) \\u2212P(Z \\u2264\\u2212z) = 0.8664.\\nConsulting a standard normal distribution table or using a calculator, you would look for the z-value\\ncorresponding to a cumulative probability of 0.4332 (half of 0.8664).\\nLet z\\u2217be the z-value such that P(Z \\u2264z\\u2217) = 0.4332. Then, P(Z \\u2264\\u2212z\\u2217) = 1 \\u2212P(Z \\u2264z\\u2217).\\n1\\n\",\n",
      "  \"summary\": \"This document contains homework solutions for CMDA 4654, focusing on probability calculations involving continuous random variables and the standard normal distribution. Key problems include finding probabilities, z-scores, and specific values related to cumulative distribution functions.\",\n",
      "  \"suggested_title\": \"CMDA_4654_Homework_0\",\n",
      "  \"suggested_tags\": [\n",
      "    \"homework\",\n",
      "    \"probability\",\n",
      "    \"statistics\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"Unofficial Academic Transcipt.pdf\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\Unofficial Academic Transcipt.pdf\",\n",
      "  \"filetype\": \"pdf\",\n",
      "  \"mime_type\": \"application/pdf\",\n",
      "  \"preview\": \"Display Unofficial Transcript\\n\\u00a0\\n906426453 Gabriel Dell\\n02/02/25 04:27 PM\\nThis is NOT an official transcript. Courses which are in progress may also be included on this transcript.\\nTransfer Credit \\u00a0\\u00a0 Institution Credit \\u00a0\\u00a0 Transcript Totals \\u00a0\\u00a0 Courses in Progress\\nTranscript Data\\nSTUDENT INFORMATION\\nName : Gabriel Dell\\nStudent Type: Continuing\\nPrimary College: College of Science\\nPrimary Major: CMDA - Computational Modeling and Data Analytics\\n\\u00a0\\n***Transcript type:WEB is NOT Official ***\\n\\u00a0\\n\\u00a0\\n\\u00a0\\nTRANSFER CREDIT ACCEPTED BY INSTITUTION\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0-Top-\\nFS2021: Advanced Standing\\nSubject\\nCourse\\nTitle\\nGrade\\nCredit\\nHours\\nQuality Points\\nENGL\\n1105\\nFirst-Year Writing\\nT\\n3.000\\u00a0\\u00a0\\n0.00\\n\\u00a0\\nAttempt\\nHours\\nPassed\\nHours\\nEarned\\nHours\\nGPA\\nHours\\nQuality\\nPoints\\nGPA\\nCurrent Term:\\n0.000\\n0.000\\n3.000\\n0.000\\n0.00\\n0.00\\n\\u00a0\\nUnofficial Transcript\\nSU22-\\nFS22:\\nNorthern Va Cmty Coll-Annandal\\nSubject\\nCourse\\nTitle\\nGrade\\nCredit\\nHours\\nQuality Points\\nMATH\\n1226\\nCalculus of a Single Variable\\nT\\n4.000\\u00a0\\u00a0\\n0.00\\nMATH\\n2114\\nIntroduction to Linear\\nAlgebra\\nT\\n3.000\\u00a0\\u00a0\\n0.00\\n\\u00a0\\nAttempt\\nHours\\nPassed\\nHours\\nEarned\\nHours\\nGPA\\nHours\\nQuality\\nPoints\\nGPA\\nCurrent Term:\\n0.000\\n0.000\\n7.000\\n0.000\\n0.00\\n0.00\\n\\u00a0\\nUnofficial Transcript\\nINSTITUTION CREDIT\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0-Top-\\nTerm: Fall 2021\\nPrimary College: College of Science\\nPrimary Major: CMDA - Computational Modeling and Data Analytics\\n\",\n",
      "  \"summary\": \"This document is an unofficial transcript for Gabriel Dell, a continuing student majoring in Computational Modeling and Data Analytics at the College of Science. It includes details about transfer credits, courses in progress, and current term statistics, indicating that the transcript is not official and should not be used for formal purposes.\",\n",
      "  \"suggested_title\": \"gabriel_dell_unofficial_transcript\",\n",
      "  \"suggested_tags\": [\n",
      "    \"transcript\",\n",
      "    \"education\",\n",
      "    \"student_records\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"filename\": \"Untitled-1.ipynb\",\n",
      "  \"filepath\": \"C:\\\\Users\\\\gabel\\\\Documents\\\\Untitled-1.ipynb\",\n",
      "  \"filetype\": \"ipynb\",\n",
      "  \"mime_type\": \"\",\n",
      "  \"preview\": \"[Code]\\nimport pandas as pd\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\nfrom sklearn.cluster import KMeans\\nimport re\\ndf = pd.read_csv(\\\"C:/Users/gabel/Downloads/responses.csv\\\")\\nprint(df.columns)\\n\\n[Code]\\n#make chapter number a category\\ndf['chapter_number'] = df['chapter_number'].astype('category')\\n\\n#Create a displot of the chapter number and a hue of completes_pages\\nsns.histplot(data=df, x='chapter_number', hue='completes_page', multiple='fill')\\nplt.show()\\n\\n[Code]\\n#Want to look at time difference of lrn_dt_started and dt_submitted\\ndf['lrn_dt_started'] = pd.to_datetime(df['lrn_dt_started'])\\ndf['dt_submitted'] = pd.to_datetime(df['dt_submitted'])\\ndf['lrn_dt_saved'] = pd.to_datetime(df['lrn_dt_saved'])\\n#Give me a timedelta difference between dt_submitted and dt_started\\ndf['time_diff'] = (df['dt_submitted'] - df['lrn_dt_started']).dt.total_seconds() / 60\\n\\n[Code]\\n#Create a lineplot of the time difference with the chapter number as the x axis\\nsns.lineplot(data=df, x='chapter_number', y='time_diff')\\nplt.show()\\n\\n[Code]\\ntype = df[df['item_type'] == 'learnosity-activity']\\n#Create a lineplot of the time difference with the chapter number as the x axis\\nsns.lineplot(data=type, x='chapter_number', y='time_diff', hue='completes_page', ci=None)\\n\\n[Code]\\ntype['prompt'] = type['prompt'].fillna('').apply(lambda x: re.sub(r'<[^>]+>', '', x))\\n\\nvectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\\nX = vectorizer.fit_transform(type['prompt'])\\nk = 3\\n\\n# K-Means clustering\\nkmeans = KMeans(n_clusters=k, random_state=42)\\ntype['cluster'] = kmeans.fit_predict(X)\\n\\n#print(type[['prompt', 'cluster']])\\n\\n#Create a function that looks at the top words in each cluster\\n\\ndef get_top_words(cluster, n_words):\\n    X_cluster = X[type['cluster'] == cluster]\\n    words = vectorizer.get_feature_names_out()\\n    words = pd.DataFrame(X_cluster.toarray(), columns=words)\\n    return words.sum().sort_values(ascending=False).head(n_words)\\n\",\n",
      "  \"summary\": \"This code performs data analysis and visualization on a dataset containing chapter responses. It includes creating histograms and line plots to analyze chapter completion and time differences, as well as applying K-Means clustering to text prompts after preprocessing. The analysis aims to uncover patterns in learning activities based on chapter numbers and response times.\",\n",
      "  \"suggested_title\": \"chapter_analysis_clustering\",\n",
      "  \"suggested_tags\": [\n",
      "    \"data_analysis\",\n",
      "    \"visualization\",\n",
      "    \"machine_learning\"\n",
      "  ]\n",
      "}\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "âœ”ï¸Ž Saved structured data for 47 files â†’ C:\\Users\\gabel\\Documents\\phase2_file_info.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Phase 2 â€“ scan top-level files in ~/Documents, preview each, call GPT-4 to get\n",
    "  â€¢ 2-3-sentence summary\n",
    "  â€¢ 2-3 category tags\n",
    "  â€¢ concise suggested title (no extension)\n",
    "\n",
    "Outputs a list of dicts, one per file, e.g.\n",
    "\n",
    "{\n",
    "    \"filename\": \"Doc1.pdf\",\n",
    "    \"filepath\": \"/Users/you/Documents/Doc1.pdf\",\n",
    "    \"filetype\": \"pdf\",\n",
    "    \"mime_type\": \"application/pdf\",\n",
    "    \"preview\": \"First 500 chars â€¦\",\n",
    "    \"summary\": \"â€¦\",\n",
    "    \"suggested_title\": \"2023_Federal_Tax_Return\",\n",
    "    \"suggested_tags\": [\"Finance\", \"Taxes\"]\n",
    "}\n",
    "\"\"\"\n",
    "import os, json, mimetypes, shutil\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "#Set path to the .env file\n",
    "dotenv_path = \"C:\\\\Users\\\\gabel\\\\Documents\\\\File Organizer AI\\\\.env\"\n",
    "#Check if the .env file exists\n",
    "if not os.path.exists(dotenv_path):\n",
    "    raise FileNotFoundError(\"Please create a .env file with your OpenAI API key.\")\n",
    "load_dotenv(); \n",
    "#Check if the .env file is loaded\n",
    "if not os.path.exists(\".env\"):\n",
    "    raise FileNotFoundError(\"Please create a .env file with your OpenAI API key.\")\n",
    "# Load OpenAI API key from .env file\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"Please set the OPENAI_API_KEY environment variable in your .env file.\")\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "#DOCUMENTS_DIR = Path.home() / \"Documents\"\n",
    "\n",
    "def gpt_summarize_and_tag(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Ask GPT-4 to return JSON with keys 'summary', 'suggested_title', 'suggested_tags'.\n",
    "    The model response is parsed and returned as a Python dict.\n",
    "    \"\"\"\n",
    "    system = (\n",
    "        \"You are an assistant that summarizes files and suggests filenames & tags. \"\n",
    "        \"Always reply **only** with valid JSON having keys \"\n",
    "        \"'summary' (2-3 sentences), \"\n",
    "        \"'suggested_title' (concise filename, no extension, underscores OK), \"\n",
    "        \"'suggested_tags' (list of 2-3 short category strings).\"\n",
    "    )\n",
    "    user = f\"Here is the file content or preview:\\n{text}\"\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.3,\n",
    "        messages=[{\"role\": \"system\", \"content\": system},\n",
    "                  {\"role\": \"user\", \"content\": user}],\n",
    "    )\n",
    "    # The assistant's content should be JSON; parse it.\n",
    "    import json\n",
    "    try:\n",
    "        return json.loads(resp.choices[0].message.content.strip())\n",
    "    except json.JSONDecodeError:\n",
    "        # fallback: wrap whole text as 'summary' if parsing fails\n",
    "        return {\n",
    "            \"summary\": resp.choices[0].message.content.strip(),\n",
    "            \"suggested_title\": \"\",\n",
    "            \"suggested_tags\": [],\n",
    "        }\n",
    "\n",
    "def build_file_record(path: Path) -> dict:\n",
    "    \"\"\"Return the complete dict for one file, ready for Phase 3.\"\"\"\n",
    "    preview = preview_file(path)\n",
    "    ai = gpt_summarize_and_tag(preview)\n",
    "    mime_type, _ = mimetypes.guess_type(str(path))\n",
    "    return {\n",
    "        \"filename\": path.name,\n",
    "        \"filepath\": str(path),\n",
    "        \"filetype\": path.suffix.lstrip(\".\").lower(),\n",
    "        \"mime_type\": mime_type or \"\",\n",
    "        \"preview\": preview,\n",
    "        **ai,  # merges summary / suggested_title / suggested_tags\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_info_list = [build_file_record(p) for p in list_top_level_files(DOCUMENTS_DIR)]\n",
    "\n",
    "    # Pretty-print to console\n",
    "    for info in file_info_list:\n",
    "        print(json.dumps(info, indent=2))\n",
    "        print(\"-\" * 70)\n",
    "\n",
    "    # Optional: persist to JSON for Phase 3\n",
    "    out_path = DOCUMENTS_DIR / \"phase2_file_info.json\"\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(file_info_list, f, indent=2)\n",
    "    print(f\"\\nâœ”ï¸Ž Saved structured data for {len(file_info_list)} files â†’ {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f185a045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. .RData â€” The file content is unknown, and therefore no specific details can be provided. Further information is needed to summarize the content accurately. [Tags: unknown, file, content]\n",
      "2. .Rhistory â€” The file content is not available for review or summarization. Please provide a valid file or content for analysis. [Tags: unknown, file, content]\n",
      "3. 04.12.2023_22.06.45_REC.mp4 â€” The file is a video in MP4 format. It may contain visual and audio content suitable for various purposes such as entertainment, education, or documentation. [Tags: video, mp4, media]\n",
      "4. 6824.txt â€” The writer expresses deep feelings of despair and stagnation in life, feeling disconnected and overwhelmed by their current situation. They reflect on their struggles with addiction, family sadness, and the recent loss of a beloved pet, Charlotte. This emotional turmoil leads to a sense of searching for purpose and tranquility amidst chaos. [Tags: mental_health, personal_reflection, grief]\n",
      "5. best_model.pth â€” The file content is unknown and cannot be summarized. Further details are needed to provide an accurate summary. [Tags: unknown, file, content]\n",
      "6. big_bucks.csv â€” The file is an Excel spreadsheet, likely containing structured data such as tables, charts, or calculations. It may be used for data analysis, financial modeling, or record-keeping purposes. [Tags: spreadsheet, data, analysis]\n",
      "7. big_bucks_edited.csv â€” The file is an Excel spreadsheet, likely containing data organized in rows and columns. It may include calculations, charts, or tables relevant to a specific topic or analysis. [Tags: spreadsheet, data, analysis]\n",
      "8. biospy_results.pdf â€” The file contains a detailed analysis of market trends in the technology sector, highlighting key growth areas and potential challenges for businesses. It also provides insights into consumer behavior and forecasts for the upcoming year. [Tags: market_trends, technology, business_insights]\n",
      "9. bullshit.R â€” The file content is currently unknown or not provided. Please provide the content for a summary. [Tags: unknown, file, content]\n",
      "10. CMDA_4654_HW_0.tex â€” The file appears to be a LaTeX document, commonly used for typesetting and formatting academic papers, reports, and other documents. It likely contains structured text, mathematical equations, or references formatted according to LaTeX standards. [Tags: LaTeX, typesetting, academic]\n",
      "11. Correlation_plot.png â€” The file is an image in PNG format. It likely contains visual content, but specific details about the image cannot be determined without viewing it. [Tags: image, png, visual]\n",
      "12. desktop.ini â€” The file content is not accessible or recognizable. Please provide a valid file or content for summarization. [Tags: unknown, file, content]\n",
      "13. Epidemic.csv â€” The file is an Excel spreadsheet, likely containing data organized in rows and columns. It may include calculations, charts, or tables relevant to a specific topic or analysis. [Tags: Excel, Data, Spreadsheet]\n",
      "14. Explained_Var.png â€” The file is an image in PNG format. It likely contains visual content, but specific details cannot be determined without viewing the image. [Tags: image, png, visual]\n",
      "15. gptSerialCorrelationTest.cu.txt â€” ```json\n",
      "{\n",
      "  \"summary\": \"This CUDA C++ file implements a kernel for calculating the serial correlation of array elements. It utilizes atomic operations to accumulate sums needed for the correlation calculation across multiple threads. The launcher function sets up the necessary device memory and launches the kernel for execution.\",\n",
      "  \"suggested_title\": \"gpt_serial_correlation_test\",\n",
      "  \"suggested_tags\": [\"CUDA\", \"C++\", \"Parallel Computing\"]\n",
      "}\n",
      "``` [Tags: ]\n",
      "16. group_2.r â€” The file content is unknown and cannot be summarized. Further details are needed to provide an accurate summary. [Tags: unknown, file, content]\n",
      "17. Homework4.ipynb â€” ```json\n",
      "{\n",
      "  \"summary\": \"This code implements a Fourier series approximation for a piecewise function and visualizes both the original function and its approximations. It also computes the solution to the heat equation with periodic boundary conditions, displaying how the function evolves over time. The plots help illustrate the convergence of the Fourier series and the behavior of the solution as time progresses.\",\n",
      "  \"suggested_title\": \"fourier_series_heat_equation\",\n",
      "  \"suggested_tags\": [\"Fourier Series\", \"Heat Equation\", \"Matplotlib\"]\n",
      "}\n",
      "``` [Tags: ]\n",
      "18. HW3.ipynb â€” ```json\n",
      "{\n",
      "  \"summary\": \"This code provides a framework for solving boundary value problems (BVPs) for the Poisson equation using numerical methods. It includes functions to define the ODE, apply boundary conditions, and plot approximate solutions for various functions, such as cos(x) and x^2, with homogeneous boundary conditions. The solutions are visualized using matplotlib, showcasing the effects of truncating Fourier series on the approximations.\",\n",
      "  \"suggested_title\": \"poisson_bvp_solver\",\n",
      "  \"suggested_tags\": [\"numerical_methods\", \"boundary_value_problems\", \"matplotlib\"]\n",
      "}\n",
      "``` [Tags: ]\n",
      "19. HW5.ipynb â€” ```json\n",
      "{\n",
      "  \"summary\": \"This code implements numerical methods to solve differential equations using the Trapezoid Method and Backward Euler method. It computes the solution norms over time and compares the errors of both methods against the true solution. The results are visualized using semilog and loglog plots.\",\n",
      "  \"suggested_title\": \"numerical_methods_trapezoid_backward_euler\",\n",
      "  \"suggested_tags\": [\"numerical_methods\", \"differential_equations\", \"data_visualization\"]\n",
      "}\n",
      "``` [Tags: ]\n",
      "20. HW6.ipynb â€” ```json\n",
      "{\n",
      "  \"summary\": \"The code implements a spectral method to approximate a function using eigenvalues and eigenfunctions. It defines the initial condition and computes coefficients over a grid, visualizing the results in a 3D plot. Additionally, it includes a method for calculating the coefficients over time, incorporating exponential decay based on the eigenvalues.\",\n",
      "  \"suggested_title\": \"spectral_method_approximation\",\n",
      "  \"suggested_tags\": [\"numerical_methods\", \"eigenvalues\", \"visualization\"]\n",
      "}\n",
      "``` [Tags: ]\n",
      "21. HW_5.R â€” The content of the file is not accessible or recognizable, making it impossible to summarize. Further details or a different format may be needed for analysis. [Tags: unknown, file, preview]\n",
      "22. Indigenous Mental Health in Canada.mp4 â€” The file is a video in MP4 format. It likely contains visual and audio content, suitable for various multimedia applications. [Tags: video, mp4, media]\n",
      "23. Indigenous Mental Health in Canada.pptm â€” The file is a macro-enabled PowerPoint presentation, which typically includes interactive elements and automated tasks. It may contain slides with multimedia content, animations, and macros to enhance functionality. [Tags: PowerPoint, presentation, macro]\n",
      "24. knn_test.py â€” This script demonstrates the use of the K-Nearest Neighbors (KNN) classifier for a dataset containing features related to diagnosis. It includes data preparation, model training, and prediction, as well as an example of KNN applied to a simple dataset. The accuracy of the model is evaluated using a test set. [Tags: machine_learning, KNN, data_analysis]\n",
      "25. MDMAtxt.txt â€” The article discusses a recommendation for the FDA to approve MDMA-assisted therapy (MDMA-AT) for PTSD treatment, highlighting its significant efficacy in reducing PTSD symptoms and improving functional impairment. The treatment showed a high remission rate and was well tolerated, although concerns about long-term effects and potential misuse remain. The author suggests that if approved, strict regulatory measures should be implemented to ensure safe practices. [Tags: PTSD, MDMA, FDA]\n",
      "26. My Personal Code of Ethics.txt â€” The document outlines a personal code of ethics emphasizing the importance of active listening, open communication, and respect for others. It highlights the value of integrity and the pursuit of new experiences as essential components of a fulfilling life. The author aims to foster trust and meaningful connections through these principles. [Tags: ethics, personal_development, communication]\n",
      "27. NAE_Disproportionality_all_cases_2004-2024.pdf â€” The file contains data on various drugs and their associated adverse events, specifically focusing on suicidal behavior. It lists different asthma and rhinitis medications along with numerical identifiers and counts related to their adverse effects. The data appears to categorize the drugs by their potential links to suicidal behavior. [Tags: pharmaceuticals, adverse_events, mental_health]\n",
      "28. output.jpg â€” The file is an image in JPEG format. It likely contains visual content, but specific details cannot be determined without viewing the image. [Tags: image, jpeg, visual]\n",
      "29. PCA_plot.png â€” The file is an image in PNG format. It likely contains visual content, but specific details about the image cannot be determined from the file type alone. [Tags: image, png, visual]\n",
      "30. phase2_file_info.json â€” The file contains data in JSON format, which is commonly used for data interchange. It may include structured information such as objects, arrays, and key-value pairs, suitable for various applications and APIs. [Tags: data, json, api]\n",
      "31. PINN.ipynb â€” ```json\n",
      "{\n",
      "  \"summary\": \"This code implements a Physics-Informed Neural Network (PINN) to solve a heat equation using PyTorch. It defines the initial condition, heat conductivity, and constructs the neural network model, including the loss function and training loop. The model aims to learn the solution of the partial differential equation by minimizing the residuals.\",\n",
      "  \"suggested_title\": \"pinn_heat_equation_solver\",\n",
      "  \"suggested_tags\": [\"machine_learning\", \"neural_networks\", \"pde_solving\"]\n",
      "}\n",
      "``` [Tags: ]\n",
      "32. PINN_2output.ipynb â€” ```json\n",
      "{\n",
      "  \"summary\": \"This code implements a Physics-Informed Neural Network (PINN) for solving heat equations using PyTorch. It defines a neural network architecture, computes derivatives, and formulates the loss function to include both PDE residuals and boundary/initial conditions. The model aims to predict temperature and thermal conductivity based on input spatial and temporal coordinates.\",\n",
      "  \"suggested_title\": \"heat_pinn_model\",\n",
      "  \"suggested_tags\": [\"machine_learning\", \"neural_networks\", \"pde\"]\n",
      "}\n",
      "``` [Tags: ]\n",
      "33. PINN_3output.ipynb â€” ```json\n",
      "{\n",
      "  \"summary\": \"This code implements a Physics-Informed Neural Network (PINN) to solve the heat equation with noise. It defines the true solution, constructs a neural network, computes derivatives, and calculates the PDE residual and loss function for training. The model aims to predict temperature distribution and thermal conductivity over time and space.\",\n",
      "  \"suggested_title\": \"heat_pinn_model\",\n",
      "  \"suggested_tags\": [\"machine_learning\", \"neural_networks\", \"physics\"]\n",
      "}\n",
      "``` [Tags: ]\n",
      "34. PINN_galertian_approx.ipynb â€” ```json\n",
      "{\n",
      "  \"summary\": \"This code generates synthetic data for a partial differential equation (PDE) problem by creating random collocation points in a specified domain. It also includes a function to compute the energy inner product of two symbolic functions using differentiation and numerical integration.\",\n",
      "  \"suggested_title\": \"synthetic_data_and_energy_inner_product\",\n",
      "  \"suggested_tags\": [\"PDE\", \"data_generation\", \"symbolic_computation\"]\n",
      "}\n",
      "``` [Tags: ]\n",
      "35. PINN_new.ipynb â€” ```json\n",
      "{\n",
      "  \"summary\": \"This code implements a finite element method (FEM) to solve the heat equation with a variable diffusivity function. It includes functions for generating a spatial mesh, assembling mass and stiffness matrices, and applying an initial condition. The solution is computed using the Backward Euler method over a specified time duration.\",\n",
      "  \"suggested_title\": \"heat_equation_fem_solver\",\n",
      "  \"suggested_tags\": [\"FEM\", \"heat_equation\", \"numerical_methods\"]\n",
      "}\n",
      "``` [Tags: ]\n",
      "36. PINN_with_unknown_k.ipynb â€” ```json\n",
      "{\n",
      "  \"summary\": \"This code implements a Physics-Informed Neural Network (PINN) using PyTorch to solve a partial differential equation (PDE). It defines two neural network classes for the solution and the coefficient of the PDE, computes the PDE residual, and sets up a loss function incorporating boundary conditions. The model utilizes GPU acceleration if available.\",\n",
      "  \"suggested_title\": \"pinn_pde_solver\",\n",
      "  \"suggested_tags\": [\"machine_learning\", \"neural_networks\", \"pde\"]\n",
      "}\n",
      "``` [Tags: ]\n",
      "37. Polyethylene-chain.png â€” The file is an image in PNG format. It likely contains visual content, but the specific details cannot be determined without viewing the image. [Tags: image, png, visual]\n",
      "38. QR-factor.py â€” This Python script demonstrates the use of NumPy for matrix operations, specifically performing QR decomposition on a given matrix. It initializes a matrix and prints both the original matrix and the resulting Q and R matrices from the decomposition. [Tags: Python, NumPy, Matrix Operations]\n",
      "39. runif1.pdf â€” The file contains a series of numerical values ranging from 0.0 to 1.0, repeated in a structured format. It also includes labels 'x1' and 'x2', which may indicate different data series or categories. This data could be used for analysis or visualization purposes. [Tags: data, numerical, analysis]\n",
      "40. Satellite_database.py â€” ```json\n",
      "{\n",
      "  \"summary\": \"This script processes satellite data using pandas and applies machine learning techniques, including K-Nearest Neighbors (KNN) and Principal Component Analysis (PCA). It involves data cleaning, encoding categorical variables, scaling features, and evaluating model performance. The script also includes visualization of the explained variance from PCA.\",\n",
      "  \"suggested_title\": \"satellite_data_analysis_knn_pca\",\n",
      "  \"suggested_tags\": [\"data_analysis\", \"machine_learning\", \"PCA\"]\n",
      "}\n",
      "``` [Tags: ]\n",
      "41. Space_Data.py â€” This Python script retrieves data from the DiscosWeb API, specifically filtering for payload objects that have a reentry date after January 1, 2020. It uses the requests library to make a GET request with authorization and sorts the results by reentry date. The script also includes commented-out code for displaying the response data or errors. [Tags: API, Python, Data Retrieval]\n",
      "42. Spring_2023_Exam_Schedule.txt â€” The document lists scheduled classes with their respective dates, times, and locations. It includes both in-person and online classes for courses CMDA and ECON. Notable dates include December 8th and 12th for various classes. [Tags: scheduling, classes, education]\n",
      "43. Stat_4444_HW4_Q2_Dell.png â€” The file is an image in PNG format. It likely contains visual content that could be related to various topics depending on its subject matter. [Tags: image, png, visual]\n",
      "44. Stuff.py â€” This script uses the pandas library to read a CSV file containing responses and performs basic data exploration. It prints the first few rows, statistical summary, data types, column names, shape of the DataFrame, and checks for missing values. This is useful for initial data analysis and understanding the dataset structure. [Tags: data_analysis, python, pandas]\n",
      "45. Test.pdf â€” This document contains homework solutions for CMDA 4654, focusing on probability calculations involving continuous random variables and the standard normal distribution. Key problems include finding probabilities, z-scores, and specific values related to cumulative distribution functions. [Tags: homework, probability, statistics]\n",
      "46. Unofficial Academic Transcipt.pdf â€” This document is an unofficial transcript for Gabriel Dell, a continuing student majoring in Computational Modeling and Data Analytics at the College of Science. It includes details about transfer credits, courses in progress, and current term statistics, indicating that the transcript is not official and should not be used for formal purposes. [Tags: transcript, education, student_records]\n",
      "47. Untitled-1.ipynb â€” This code performs data analysis and visualization on a dataset containing chapter responses. It includes creating histograms and line plots to analyze chapter completion and time differences, as well as applying K-Means clustering to text prompts after preprocessing. The analysis aims to uncover patterns in learning activities based on chapter numbers and response times. [Tags: data_analysis, visualization, machine_learning]\n"
     ]
    }
   ],
   "source": [
    "#Phase 3 â€“ move files to new location\n",
    "import json\n",
    "with open(\"C:\\\\Users\\\\gabel\\\\Documents\\\\phase2_file_info.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    files_info = json.load(f)\n",
    "\n",
    "def suggest_file_groups(files_info):\n",
    "    file_descriptions = \"\\n\".join(\n",
    "        f\"{i+1}. {f['filename']} â€” {f['summary']} [Tags: {', '.join(f['suggested_tags'])}]\"\n",
    "        for i, f in enumerate(files_info)\n",
    "    )\n",
    "    prompt = (\n",
    "        \"Here are files and their summaries:\\n\\n\"\n",
    "        f\"{file_descriptions}\\n\\n\"\n",
    "        \"Please suggest 2â€“5 folder names to group these files by purpose or topic. \"\n",
    "        \"Then, assign each file number to a folder. Output format:\\n\\n\"\n",
    "        \"Groups:\\n- FolderName1: [1, 3, 5]\\n- FolderName2: [2, 4]\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "suggested_folders = suggest_file_groups(files_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ea36b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'Multimedia_Content': [2, 10, 13, 21, 27, 28, 36, 42], 'Data_Analysis_Scripts': [12, 5, 6, 23, 37, 39, 40, 43, 46], 'Machine_Learning_Models': [14, 30, 31, 32, 33, 34, 35], 'Textual_Document_Analysis': [3, 17, 18, 19, 24, 25, 26, 41, 44, 45], 'Unreadable_or_Unknown_Files': [0, 1, 4, 8, 11, 15, 20, 22, 29, 38]})\n",
      "[{'filename': '.RData', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\.RData', 'filetype': '', 'mime_type': '', 'preview': '[unknown file]', 'summary': 'The file content is unknown, and therefore no specific details can be provided. Further information is needed to summarize the content accurately.', 'suggested_title': 'unknown_file_content', 'suggested_tags': ['unknown', 'file', 'content']}, {'filename': '.Rhistory', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\.Rhistory', 'filetype': '', 'mime_type': '', 'preview': '[unknown file]', 'summary': 'The file content is not available for review or summarization. Please provide a valid file or content for analysis.', 'suggested_title': 'unknown_file', 'suggested_tags': ['unknown', 'file', 'content']}, {'filename': '04.12.2023_22.06.45_REC.mp4', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\04.12.2023_22.06.45_REC.mp4', 'filetype': 'mp4', 'mime_type': 'video/mp4', 'preview': '[video/mp4 file]', 'summary': 'The file is a video in MP4 format. It may contain visual and audio content suitable for various purposes such as entertainment, education, or documentation.', 'suggested_title': 'video_preview', 'suggested_tags': ['video', 'mp4', 'media']}, {'filename': '6824.txt', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\6824.txt', 'filetype': 'txt', 'mime_type': 'text/plain', 'preview': \"6/8/24\\n\\nI hate my current situation, my life. I feel as though my purpose is nothing and anything I do I can't seem to get a grasp on, as if I am too stupid to understand anything. I watch YouTube over's lives, whilst my own is stagnant and watching it pass by me, and because I choose to do nothing I feel as though life has become this meaningless blob of existence where I see everyone else exist except for myself, a form of depersonalization I guess. I feel I have no control over myself, as I watch porn everyday, destroying what remains of my neurons that produce dopamine, a sad state of affairs truly, and I watch things on my phone for hours on end, adding to my lack of utility. Finally my parent's house, I feel as though there is ominous being/feeling of despair and sadness, I look into my mother's eyes and all I saw I see is sadness, a woman dragged through the depths of her own personal hell, the droop in eyes and skin make it all the more evident. Her sadness makes me sad in turn because I feel there is nothing I can do to help her through this sorrow, I don't even know where to begin on that front. My personal behavior has been odd as of recent, recently when I was out for lunch at my work, instead of going and eating something, I instead walked to the top of a parking lot, looked over the edge and sat on the stairs, looking at the clouds, then I walked to an empty field and sat underneath a tree and looked at the sky, imagining what is my place, why am I here and how life was so much more tranquil in the field than anywhere else.\\n\\n\\n\\n\\nWould be interesting to have an browser that has an AI in it that if a search result is related to porn or pornographic results, it will go to one of its guardrails and block the results completely and tell the user that they are a naughty boy.\\n\\n6/9:\\n\\n\\nMy dog charlotte passed away, I wasn't there for her passing, however I miss her nonetheless. I saw her body, her body was still warm, the signs of life slowly alleviating themsel\", 'summary': 'The writer expresses deep feelings of despair and stagnation in life, feeling disconnected and overwhelmed by their current situation. They reflect on their struggles with addiction, family sadness, and the recent loss of a beloved pet, Charlotte. This emotional turmoil leads to a sense of searching for purpose and tranquility amidst chaos.', 'suggested_title': 'struggles_with_purpose_and_loss', 'suggested_tags': ['mental_health', 'personal_reflection', 'grief']}, {'filename': 'best_model.pth', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\best_model.pth', 'filetype': 'pth', 'mime_type': '', 'preview': '[unknown file]', 'summary': 'The file content is unknown and cannot be summarized. Further details are needed to provide an accurate summary.', 'suggested_title': 'unknown_file_content', 'suggested_tags': ['unknown', 'file', 'content']}, {'filename': 'big_bucks.csv', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\big_bucks.csv', 'filetype': 'csv', 'mime_type': 'application/vnd.ms-excel', 'preview': '[application/vnd.ms-excel file]', 'summary': 'The file is an Excel spreadsheet, likely containing structured data such as tables, charts, or calculations. It may be used for data analysis, financial modeling, or record-keeping purposes.', 'suggested_title': 'excel_data_analysis', 'suggested_tags': ['spreadsheet', 'data', 'analysis']}, {'filename': 'big_bucks_edited.csv', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\big_bucks_edited.csv', 'filetype': 'csv', 'mime_type': 'application/vnd.ms-excel', 'preview': '[application/vnd.ms-excel file]', 'summary': 'The file is an Excel spreadsheet, likely containing data organized in rows and columns. It may include calculations, charts, or tables relevant to a specific topic or analysis.', 'suggested_title': 'excel_data_analysis', 'suggested_tags': ['spreadsheet', 'data', 'analysis']}, {'filename': 'biospy_results.pdf', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\biospy_results.pdf', 'filetype': 'pdf', 'mime_type': 'application/pdf', 'preview': '', 'summary': 'The file contains a detailed analysis of market trends in the technology sector, highlighting key growth areas and potential challenges for businesses. It also provides insights into consumer behavior and forecasts for the upcoming year.', 'suggested_title': 'technology_market_analysis_2023', 'suggested_tags': ['market_trends', 'technology', 'business_insights']}, {'filename': 'bullshit.R', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\bullshit.R', 'filetype': 'r', 'mime_type': '', 'preview': '[unknown file]', 'summary': 'The file content is currently unknown or not provided. Please provide the content for a summary.', 'suggested_title': 'unknown_file_content', 'suggested_tags': ['unknown', 'file', 'content']}, {'filename': 'CMDA_4654_HW_0.tex', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\CMDA_4654_HW_0.tex', 'filetype': 'tex', 'mime_type': 'application/x-tex', 'preview': '[application/x-tex file]', 'summary': 'The file appears to be a LaTeX document, commonly used for typesetting and formatting academic papers, reports, and other documents. It likely contains structured text, mathematical equations, or references formatted according to LaTeX standards.', 'suggested_title': 'latex_document', 'suggested_tags': ['LaTeX', 'typesetting', 'academic']}, {'filename': 'Correlation_plot.png', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\Correlation_plot.png', 'filetype': 'png', 'mime_type': 'image/png', 'preview': '[image/png file]', 'summary': 'The file is an image in PNG format. It likely contains visual content, but specific details about the image cannot be determined without viewing it.', 'suggested_title': 'image_preview', 'suggested_tags': ['image', 'png', 'visual']}, {'filename': 'desktop.ini', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\desktop.ini', 'filetype': 'ini', 'mime_type': '', 'preview': '[unknown file]', 'summary': 'The file content is not accessible or recognizable. Please provide a valid file or content for summarization.', 'suggested_title': 'unknown_file_content', 'suggested_tags': ['unknown', 'file', 'content']}, {'filename': 'Epidemic.csv', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\Epidemic.csv', 'filetype': 'csv', 'mime_type': 'application/vnd.ms-excel', 'preview': '[application/vnd.ms-excel file]', 'summary': 'The file is an Excel spreadsheet, likely containing data organized in rows and columns. It may include calculations, charts, or tables relevant to a specific topic or analysis.', 'suggested_title': 'data_analysis_spreadsheet', 'suggested_tags': ['Excel', 'Data', 'Spreadsheet']}, {'filename': 'Explained_Var.png', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\Explained_Var.png', 'filetype': 'png', 'mime_type': 'image/png', 'preview': '[image/png file]', 'summary': 'The file is an image in PNG format. It likely contains visual content, but specific details cannot be determined without viewing the image.', 'suggested_title': 'image_preview', 'suggested_tags': ['image', 'png', 'visual']}, {'filename': 'gptSerialCorrelationTest.cu.txt', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\gptSerialCorrelationTest.cu.txt', 'filetype': 'txt', 'mime_type': 'text/plain', 'preview': '// gptSerialCorrelationTest.cu\\n\\n#include <iostream>\\n#include <cuda.h>\\n#include \"gptRandom.h\"\\n\\n// Kernel for calculating the serial correlation of the array elements\\n__global__ void gptSerialCorrelationKernel(dfloat *array, dfloat *sumX, dfloat *sumY, dfloat *sumXY, dfloat *sumX2, dfloat *sumY2, int N) {\\n  int tid = threadIdx.x;\\n  int idx = blockIdx.x * blockDim.x + tid;\\n\\n  // Variables to store sums for correlation calculation\\n  dfloat x, y;\\n  dfloat partialSumX = 0.0, partialSumY = 0.0;\\n  dfloat partialSumXY = 0.0, partialSumX2 = 0.0, partialSumY2 = 0.0;\\n\\n  if (idx < N - 1) {\\n    x = array[idx];\\n    y = array[idx + 1];\\n        \\n    partialSumX += x;\\n    partialSumY += y;\\n    partialSumXY += x * y;\\n    partialSumX2 += x * x;\\n    partialSumY2 += y * y;\\n  }\\n\\n  // Use atomic operations to accumulate the results across threads\\n  atomicAdd(sumX, partialSumX);\\n  atomicAdd(sumY, partialSumY);\\n  atomicAdd(sumXY, partialSumXY);\\n  atomicAdd(sumX2, partialSumX2);\\n  atomicAdd(sumY2, partialSumY2);\\n}\\n\\n// Launcher function for the serial correlation test\\nvoid gptSerialCorrelationLauncher(dfloat *array, int N, dfloat *serialCorrelationResult) {\\n  dfloat *d_sumX, *d_sumY, *d_sumXY, *d_sumX2, *d_sumY2;\\n  cudaMalloc((void **)&d_sumX, sizeof(dfloat));\\n  cudaMalloc((void **)&d_sumY, sizeof(dfloat));\\n  cudaMalloc((void **)&d_sumXY, sizeof(dfloat));\\n  cudaMalloc((void **)&d_sumX2, sizeof(dfloat));\\n  cudaMalloc((void **)&d_sumY2, sizeof(dfloat));\\n  cudaMemset(d_sumX, 0, sizeof(dfloat));\\n  cudaMemset(d_sumY, 0, sizeof(dfloat));\\n  cudaMemset(d_sumXY, 0, sizeof(dfloat));\\n  cudaMemset(d_sumX2, 0, sizeof(dfloat));\\n  cudaMemset(d_sumY2, 0, sizeof(dfloat));\\n\\n  int threadsPerBlock = 256;\\n  int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\\n\\n  // Launch kernel\\n  gptSerialCorrelationKernel<<<blocksPerGrid, threadsPerBlock>>>(array, d_sumX, d_sumY, d_sumXY, d_sumX2, d_sumY2, N);\\n  cudaDeviceSynchronize();\\n\\n  // Copy results back to host\\n  dfloat sumX, sumY, sumXY, sumX2, sumY2;\\n  cudaM', 'summary': '```json\\n{\\n  \"summary\": \"This CUDA C++ file implements a kernel for calculating the serial correlation of array elements. It utilizes atomic operations to accumulate sums needed for the correlation calculation across multiple threads. The launcher function sets up the necessary device memory and launches the kernel for execution.\",\\n  \"suggested_title\": \"gpt_serial_correlation_test\",\\n  \"suggested_tags\": [\"CUDA\", \"C++\", \"Parallel Computing\"]\\n}\\n```', 'suggested_title': '', 'suggested_tags': []}, {'filename': 'group_2.r', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\group_2.r', 'filetype': 'r', 'mime_type': '', 'preview': '[unknown file]', 'summary': 'The file content is unknown and cannot be summarized. Further details are needed to provide an accurate summary.', 'suggested_title': 'unknown_file_content', 'suggested_tags': ['unknown', 'file', 'content']}, {'filename': 'Homework4.ipynb', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\Homework4.ipynb', 'filetype': 'ipynb', 'mime_type': '', 'preview': \"[Code]\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n#Part A\\n\\n# Define the piecewise function u0(x)\\ndef u0(x):\\n    return np.piecewise(x, \\n                        [x < -0.5, (x >= -0.5) & (x < 0.5), x >= 0.5],\\n                        [-1, 0, 1])\\n\\n# Define the b_n(0) coefficient based on n mod 4\\ndef b_n(n):\\n    if n % 4 == 0:\\n        return 0\\n    elif n % 2 == 1:  # odd\\n       return 2 / (n * np.pi)\\n    elif n % 4 == 2:\\n        return -4 / (n * np.pi)\\n\\n    #return (-2/(n*np.pi)) * (-1)**n\\n\\n# Compute the partial sum u0_N(x)\\ndef u0_N(x, N):\\n    return sum(b_n(n) * np.sin(n * np.pi * x) for n in range(1, N+1))\\n\\n# Set up x values and compute the original function\\nx_vals = np.linspace(-1, 1, 1000)\\nu0_vals = u0(x_vals)\\n\\n# Define the N values to compute partial sums for\\nN_values = [1, 2, 4, 10, 100]\\nu0_N_vals = {N: [u0_N(x, N) for x in x_vals] for N in N_values}\\n\\n# Plotting\\nplt.figure(figsize=(12, 6))\\nplt.plot(x_vals, u0_vals, 'k', linewidth=2, label='Original $u_0(x)$')\\n\\n# Plot each partial sum\\nfor N in N_values:\\n    plt.plot(x_vals, u0_N_vals[N], label=f'$u_{{0,{N}}}(x)$')\\n\\nplt.title('Original Function $u_0(x)$ and Fourier Series Approximations')\\nplt.xlabel('$x$')\\nplt.ylabel('$u_0(x)$ and $u_{0,N}(x)$')\\nplt.grid(True)\\nplt.legend()\\nplt.show()\\n\\n[Code]\\n#Part C\\n\\ndef b_n(n):\\n    return 2/(n*np.pi)*(np.cos((n*np.pi)/2) - (-1)**n)\\n\\ndef u_t0(x, t, N):\\n    return sum(b_n(n) * np.sin(n * np.pi * x) * np.exp(-n**2 * np.pi**2 * t) for n in range(1, N+1))\\n\\n# Set up x values and compute the original function\\nx_vals = np.linspace(-1, 1, 1000)\\nt_vals =[0,0.01,0.05,0.1,0.5,1]\\nN=100\\nu_t0_vals = {t: [u_t0(x, t, N) for x in x_vals] for t in t_vals}\\nu0_vals = u0(x_vals)\\n\\nplt.figure(figsize=(12, 6))\\nplt.plot(x_vals, u0_vals, 'k--', label=r'Initial $u_0(x)$', linewidth=2)\\n\\nfor t in t_vals:\\n    plt.plot(x_vals, u_t0_vals[t], label=fr'$u(x,{t})$ with $N={N}$')\\n\\nplt.title('Solution to the Heat Equation with Periodic Boundary Conditions')\\nplt.xlabel('$x$')\\nplt.ylabel('$u(x,t)$')\\nplt.grid(True\", 'summary': '```json\\n{\\n  \"summary\": \"This code implements a Fourier series approximation for a piecewise function and visualizes both the original function and its approximations. It also computes the solution to the heat equation with periodic boundary conditions, displaying how the function evolves over time. The plots help illustrate the convergence of the Fourier series and the behavior of the solution as time progresses.\",\\n  \"suggested_title\": \"fourier_series_heat_equation\",\\n  \"suggested_tags\": [\"Fourier Series\", \"Heat Equation\", \"Matplotlib\"]\\n}\\n```', 'suggested_title': '', 'suggested_tags': []}, {'filename': 'HW3.ipynb', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\HW3.ipynb', 'filetype': 'ipynb', 'mime_type': '', 'preview': '[Code]\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom scipy.linalg import solve\\nfrom scipy.integrate import solve_bvp\\n\\n# Define the domain\\nx_vals = np.linspace(0, 1, 100)\\n\\n# Function to solve -u\\'\\'(x) = f(x) with given boundary conditions\\ndef solve_poisson(f, bc, N=100):\\n    def ode(x, y):\\n        return np.vstack([y[1], -f(x)])  # Convert 2nd order ODE to 1st order system\\n    \\n    def bc_conditions(ya, yb):\\n        return bc(ya, yb)  # Apply the user-defined boundary conditions\\n\\n    # Initial guess\\n    y_guess = np.zeros((2, x_vals.shape[0]))\\n    \\n    # Solve the boundary value problem (BVP)\\n    sol = solve_bvp(ode, bc_conditions, x_vals, y_guess)\\n    \\n    return sol.sol(x_vals)[0]  # Extract u(x)\\n\\n# Function to approximate solution using N eigenfunctions\\ndef truncate_series(u_exact, N):\\n    coeffs = np.fft.rfft(u_exact)  # Use Fourier transform to extract coefficients\\n    coeffs[N:] = 0  # Truncate higher order terms\\n    return np.fft.irfft(coeffs, len(u_exact))\\n\\n# Plot the approximate solutions\\ndef plot_approximate_solutions(f, bc, title):\\n    plt.figure(figsize=(8, 5))\\n    u_exact = solve_poisson(f, bc)  # Get exact solution\\n    \\n    N_values = [2, 4, 8, 16]\\n    for N in N_values:\\n        u_N = truncate_series(u_exact, N)\\n        plt.plot(x_vals, u_N, label=f\"N = {N}\")\\n\\n    plt.plot(x_vals, u_exact, \\'k--\\', label=\"Exact Solution\", linewidth=2)\\n    plt.title(title)\\n    plt.xlabel(\"x\")\\n    plt.ylabel(\"u_N(x)\")\\n    plt.legend()\\n    plt.grid()\\n    plt.show()\\n\\n# Subproblem (e): -u\\'\\'(x) = cos(x), Homogeneous BCs u\\'(0) = 0, u(1) = 0\\nf_e = lambda x: np.cos(x)\\nbc_e = lambda ya, yb: np.array([ya[1], yb[0]])  # u\\'(0) = 0, u(1) = 0\\nplot_approximate_solutions(f_e, bc_e, \"(e) -u\\'\\'(x) = cos(x) with homogeneous BCs\")\\n\\n[Code]\\nf_c = lambda x: x**2\\nbc_c = lambda ya, yb: np.array([ya[1], yb[0]])  # u\\'(0) = 0, u(1) = 0\\nplot_approximate_solutions(f_c, bc_c, \"(c) -u\\'\\'(x) = x^2 with homogeneous BCs\")\\n\\n[Code]\\nf_d = lambda x: x**2\\nbc_d = lambda ya, yb: np.array([ya[1], yb[0] - 1])', 'summary': '```json\\n{\\n  \"summary\": \"This code provides a framework for solving boundary value problems (BVPs) for the Poisson equation using numerical methods. It includes functions to define the ODE, apply boundary conditions, and plot approximate solutions for various functions, such as cos(x) and x^2, with homogeneous boundary conditions. The solutions are visualized using matplotlib, showcasing the effects of truncating Fourier series on the approximations.\",\\n  \"suggested_title\": \"poisson_bvp_solver\",\\n  \"suggested_tags\": [\"numerical_methods\", \"boundary_value_problems\", \"matplotlib\"]\\n}\\n```', 'suggested_title': '', 'suggested_tags': []}, {'filename': 'HW5.ipynb', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\HW5.ipynb', 'filetype': 'ipynb', 'mime_type': '', 'preview': '[Code]\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n\\n#Problem 2B\\n\\nA = np.array([[-1, 10],\\n              [0, -2]])\\ny0 = np.array([1, 1])\\n\\ndt = 0.05\\nt_values = np.arange(0, 5 + dt, dt)\\nnum_steps = len(t_values)\\nys = np.zeros((num_steps, 2))\\nys[0] = y0\\n\\n\\nI = np.eye(2)\\nM1 = np.linalg.inv(I - 0.5 * dt * A)  # (I - t/2 A)^(-1)\\nM2 = I + 0.5 * dt * A                # (I + t/2 A)\\n\\nfor k in range(1, num_steps):\\n    ys[k] = M1 @ (M2 @ ys[k-1])\\n\\n# Compute norms\\nnorms = np.linalg.norm(ys, axis=1)\\n\\nplt.figure(figsize=(8, 5))\\nplt.semilogy(t_values, norms, label=r\"$\\\\|y_k\\\\|$ (Trapezoid Method)\")\\nplt.xlabel(\"Time $t_k$\")\\nplt.ylabel(r\"$\\\\|y_k\\\\|$\")\\nplt.title(\"Semilogy plot of solution norm over time\")\\nplt.grid(True, which=\\'both\\', linestyle=\\'--\\', alpha=0.6)\\nplt.legend()\\nplt.tight_layout()\\nplt.show()\\n\\n[Code]\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom scipy.linalg import expm\\n\\n#Problem 2C\\n\\n# Define matrix A and initial condition\\nA = np.array([[-1, 10],\\n              [0, -2]])\\ny0 = np.array([1, 1])\\n\\n# Time where we compare error\\nt_final = 1\\n\\ndt_values = [1/2**k for k in range(1, 10)]  \\n\\n# Store errors\\nerrors_trap = []\\nerrors_back = []\\n\\n# True solution at t=1\\ny_true = expm(A * t_final) @ y0\\n\\nfor dt in dt_values:\\n    steps = int(t_final / dt)\\n    I = np.eye(2)\\n\\n    M1 = np.linalg.inv(I - 0.5 * dt * A)\\n    M2 = I + 0.5 * dt * A\\n    y_trap = y0.copy()\\n    for _ in range(steps):\\n        y_trap = M1 @ (M2 @ y_trap)\\n    error_trap = np.linalg.norm(y_trap - y_true)\\n    errors_trap.append(error_trap)\\n\\n    M_back = np.linalg.inv(I - dt * A)\\n    y_back = y0.copy()\\n    for _ in range(steps):\\n        y_back = M_back @ y_back\\n    error_back = np.linalg.norm(y_back - y_true)\\n    errors_back.append(error_back)\\n\\n# Plotting\\nplt.figure(figsize=(8, 5))\\nplt.loglog(dt_values, errors_trap, \\'o-\\', label=\\'Trapezoid Method\\')\\nplt.loglog(dt_values, errors_back, \\'s-\\', label=\\'Backward Euler\\')\\nplt.xlabel(\\'Î”t\\')\\nplt.ylabel(\\'Error at t=1 (norm)\\')\\nplt.title(\\'Error vs Î”t for Trapezoid and Backward Euler Met', 'summary': '```json\\n{\\n  \"summary\": \"This code implements numerical methods to solve differential equations using the Trapezoid Method and Backward Euler method. It computes the solution norms over time and compares the errors of both methods against the true solution. The results are visualized using semilog and loglog plots.\",\\n  \"suggested_title\": \"numerical_methods_trapezoid_backward_euler\",\\n  \"suggested_tags\": [\"numerical_methods\", \"differential_equations\", \"data_visualization\"]\\n}\\n```', 'suggested_title': '', 'suggested_tags': []}, {'filename': 'HW6.ipynb', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\HW6.ipynb', 'filetype': 'ipynb', 'mime_type': '', 'preview': \"[Code]\\nimport numpy as np\\n\\nN = 50\\nx = np.linspace(0, 1, N)\\ny = np.linspace(0, 1, N)\\nX, Y = np.meshgrid(x, y)\\n\\n#Eigenvalue\\ndef eigenvalue(j,k):\\n    return (j**2 + k**2)*np.pi**2\\n\\n#Eigenfunction\\ndef eigenfunction(j,k,x, y):\\n    return np.sin(j*np.pi*x)*np.sin(k*np.pi*y)\\n\\n# Function to be approximated\\ndef function(x,y):\\n    return x*(1-y)\\n\\nF = function(X,Y)\\n\\nU5 = np.zeros_like(F)\\n\\nfor j in range(1,6):\\n    for k in range(1,6):\\n        psi_jk = eigenfunction(j, k, X, Y)\\n        lam_jk = eigenvalue(j, k)\\n\\n        # Inner products approximated using trapezoidal rule\\n        numerator = np.trapezoid(np.trapezoid(F * psi_jk, x), y)\\n        denominator = np.trapezoid(np.trapezoid(psi_jk * psi_jk, x), y)\\n\\n        coefficient = (1 / lam_jk) * (numerator / denominator)\\n        U5 += coefficient * psi_jk\\n\\n# Plotting the results\\nimport matplotlib.pyplot as plt\\nfrom mpl_toolkits.mplot3d import Axes3D\\nfrom matplotlib import cm\\n\\nfig = plt.figure(figsize=(10, 7))\\nax = fig.add_subplot(111, projection='3d')\\nax.plot_surface(X, Y, U5, cmap=cm.viridis, edgecolor='none')\\nax.set_xlabel('X-axis')\\nax.set_ylabel('Y-axis')\\nax.set_zlabel('U5')\\nax.set_title('Spectral Method Approximation of Function')\\nplt.show()\\n\\n[Code]\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Grid\\nN = 50\\nx = np.linspace(0, 1, N)\\ny = np.linspace(0, 1, N)\\nX, Y = np.meshgrid(x, y)\\n\\n# Initial condition u0(x, y)\\ndef u0(x, y):\\n    return 20 * x * y * (1 - x) * (1 - y) * np.exp(np.sin(5 * np.pi * x))\\n\\n# Eigenvalue\\ndef eigenvalue(j, k):\\n    return (j**2 + k**2) * np.pi**2\\n\\n# Eigenfunction\\ndef eigenfunction(j, k, x, y):\\n    return np.sin(j * np.pi * x) * np.sin(k * np.pi * y)\\n\\n# Coefficients a_{j,k}(t)\\ndef coefficient(j, k, t, X, Y):\\n    psi_jk = eigenfunction(j, k, X, Y)\\n    lam_jk = eigenvalue(j, k)\\n\\n    u0_vals = u0(X, Y)\\n    numerator = np.trapezoid(np.trapezoid(u0_vals * psi_jk, x), y)\\n    denominator = np.trapezoid(np.trapezoid(psi_jk * psi_jk, x), y)\\n\\n    return (numerator / denominator) * np.exp(-lam_jk * t)\\n\\n# Time p\", 'summary': '```json\\n{\\n  \"summary\": \"The code implements a spectral method to approximate a function using eigenvalues and eigenfunctions. It defines the initial condition and computes coefficients over a grid, visualizing the results in a 3D plot. Additionally, it includes a method for calculating the coefficients over time, incorporating exponential decay based on the eigenvalues.\",\\n  \"suggested_title\": \"spectral_method_approximation\",\\n  \"suggested_tags\": [\"numerical_methods\", \"eigenvalues\", \"visualization\"]\\n}\\n```', 'suggested_title': '', 'suggested_tags': []}, {'filename': 'HW_5.R', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\HW_5.R', 'filetype': 'r', 'mime_type': '', 'preview': '[unknown file]', 'summary': 'The content of the file is not accessible or recognizable, making it impossible to summarize. Further details or a different format may be needed for analysis.', 'suggested_title': 'unknown_file_preview', 'suggested_tags': ['unknown', 'file', 'preview']}, {'filename': 'Indigenous Mental Health in Canada.mp4', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\Indigenous Mental Health in Canada.mp4', 'filetype': 'mp4', 'mime_type': 'video/mp4', 'preview': '[video/mp4 file]', 'summary': 'The file is a video in MP4 format. It likely contains visual and audio content, suitable for various multimedia applications.', 'suggested_title': 'video_preview', 'suggested_tags': ['video', 'mp4', 'media']}, {'filename': 'Indigenous Mental Health in Canada.pptm', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\Indigenous Mental Health in Canada.pptm', 'filetype': 'pptm', 'mime_type': 'application/vnd.ms-powerpoint.presentation.macroEnabled.12', 'preview': '[application/vnd.ms-powerpoint.presentation.macroEnabled.12 file]', 'summary': 'The file is a macro-enabled PowerPoint presentation, which typically includes interactive elements and automated tasks. It may contain slides with multimedia content, animations, and macros to enhance functionality.', 'suggested_title': 'macro_enabled_presentation', 'suggested_tags': ['PowerPoint', 'presentation', 'macro']}, {'filename': 'knn_test.py', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\knn_test.py', 'filetype': 'py', 'mime_type': 'text/x-python', 'preview': '# import pandas as pd\\n# data = pd.read_csv(\"C:/Users/gabel/Downloads/data.csv\")\\n# data = data[[\\'radius_mean\\', \\'texture_mean\\', \\'diagnosis\\']]\\n# # Defining X and y\\n# X = data.drop(\\'diagnosis\\',axis=1)\\n# y = data.diagnosis\\n# # Splitting data into train and test\\n# from sklearn.model_selection import train_test_split\\n# X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42)\\n# # Importing and fitting KNN classifier for k=3\\n# from sklearn.neighbors import KNeighborsClassifier\\n# knn = KNeighborsClassifier(n_neighbors=3)\\n# print(knn.fit(X_train,y_train))\\n# # Predicting results using Test data set\\n# pred = knn.predict(X_test)\\n# from sklearn.metrics import accuracy_score\\n# print(accuracy_score(pred,y_test))\\n\\n\\n\\nX = [[0], [1], [2], [3]]\\ny = [0, 0, 1, 1]\\nfrom sklearn.neighbors import KNeighborsClassifier\\nneigh = KNeighborsClassifier(n_neighbors=3)\\nneigh.fit(X, y)\\nprint(neigh.predict([[1.1]]))\\nprint(neigh.predict_proba([[0.9]]))\\n', 'summary': 'This script demonstrates the use of the K-Nearest Neighbors (KNN) classifier for a dataset containing features related to diagnosis. It includes data preparation, model training, and prediction, as well as an example of KNN applied to a simple dataset. The accuracy of the model is evaluated using a test set.', 'suggested_title': 'knn_classifier_example', 'suggested_tags': ['machine_learning', 'KNN', 'data_analysis']}, {'filename': 'MDMAtxt.txt', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\MDMAtxt.txt', 'filetype': 'txt', 'mime_type': 'text/plain', 'preview': 'Take notes on highlights of the article and main findings.\\n\\nPretend that you are a scientist looking at these data and writing a recommendation to the FDA for approval (or rejection) Would you recommend or not recommend the use of MDMA as a treatment for PTSD? In your recommendation, be sure to cite the main findings of the paper as well as your own thoughts on using psychedelics in research. What hesitations might you have, if approved? How might society view the approval (or rejection)?\\n\\n\\nBased on the findings of this phase 3 trial, I would recommend the FDA approve MDMA-assisted therapy (MDMA-AT) for the treatment of PTSD under controlled conditions. The study demonstrated significant efficacy, with MDMA-AT leading to an average reduction of 23.7 points in the Clinician-Administered PTSD Scale (CAPS-5), compared to 14.8 points in the placebo group. Furthermore, 71.2% of participants in the MDMA-AT group no longer met the diagnostic criteria for PTSD by the studyâ€™s end, and 46.2% achieved full remission, compared to 47.6% and 21.4% in the placebo group, respectively. Additionally, MDMA-AT significantly improved functional impairment scores on the Sheehan Disability Scale (SDS), with a 3.3-point improvement compared to 2.1 points in the placebo group. Importantly, the treatment was well tolerated, with no severe or life-threatening adverse events. While some side effects, such as muscle tightness, nausea, and transient increases in blood pressure, were observed, these were mild and manageable. Another critical advantage of MDMA-AT is its low dropout rate (1.9%), especially compared to conventional PTSD treatments like selective serotonin reuptake inhibitors (SSRIs), which have high non-response and discontinuation rates. However, concerns remain regarding long-term effects, potential misuse, and the exclusion of high-suicide-risk individuals from the study. If approved, strict regulatory frameworks should be in place, including training programs for therapists and ', 'summary': 'The article discusses a recommendation for the FDA to approve MDMA-assisted therapy (MDMA-AT) for PTSD treatment, highlighting its significant efficacy in reducing PTSD symptoms and improving functional impairment. The treatment showed a high remission rate and was well tolerated, although concerns about long-term effects and potential misuse remain. The author suggests that if approved, strict regulatory measures should be implemented to ensure safe practices.', 'suggested_title': 'mdma_ptsd_fda_recommendation', 'suggested_tags': ['PTSD', 'MDMA', 'FDA']}, {'filename': 'My Personal Code of Ethics.txt', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\My Personal Code of Ethics.txt', 'filetype': 'txt', 'mime_type': 'text/plain', 'preview': 'My Personal Code of Ethics\\n\\n1. Listening to what other people are saying \\n   Why: People have valuable thoughts, experiences, and emotions to share. Sometimes, they just need someone to listen, and other times, they may offer insights that could profoundly impact my perspective. By actively listening and asking thoughtful questions, I strive to deepen my understanding of others and engage with them in a meaningful way.  \\n\\n2. Not withholding my opinion from others  \\n   Why: Open and honest communication fosters trust and prevents misunderstandings. Too often, people suppress their true feelings, which can lead to resentment or passive-aggressive behavior. I believe in expressing my thoughts openly and directly, especially when addressing concerns with someone, rather than letting unspoken emotions fester.  \\n\\n3. Always trying something new \\n   Why: \"Carpe Diem\"â€”seize the day. Life is unpredictable, and opportunities may not always present themselves again. Understanding the fragility of existence, I embrace new experiences, take risks, and pursue challenges that push my limits. At the end of my journey, I want to look back with fulfillment, knowing I lived fully rather than hesitated in fear.  \\n\\n4. I will treat others with respect\\n   Why: Every individual deserves to be treated with dignity, regardless of their background, opinions, or circumstances. Respect is the foundation of healthy relationships, whether personal or professional. By treating others with kindness and fairness, I contribute to an environment where people feel valued and understood.  \\n\\n5. I am a man of my word \\n   Why: Integrity is one of the most important values I hold. When I give my wordâ€”whether in friendships, professional endeavors, or personal goalsâ€”I strive to uphold it. Trust is built on reliability, and I want to be someone others can count on. Following through on my commitments not only reinforces my credibility but also strengthens the relationships I build.  \\n\\n', 'summary': 'The document outlines a personal code of ethics emphasizing the importance of active listening, open communication, and respect for others. It highlights the value of integrity and the pursuit of new experiences as essential components of a fulfilling life. The author aims to foster trust and meaningful connections through these principles.', 'suggested_title': 'personal_code_of_ethics', 'suggested_tags': ['ethics', 'personal_development', 'communication']}, {'filename': 'NAE_Disproportionality_all_cases_2004-2024.pdf', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\NAE_Disproportionality_all_cases_2004-2024.pdf', 'filetype': 'pdf', 'mime_type': 'application/pdf', 'preview': 'drug\\nadverse_event\\nDRAE\\nDRae\\ndrAE\\ndrae\\nDR\\nOther_asthma_drugs suicidal_beh\\n9\\n11548\\n3874 18574818\\n11557\\nOther_rhinitis_drugs\\nsuicidal_beh\\n20\\n119605\\n3863 18466761\\n119625\\nMontelukast\\nsuicidal_beh\\n144\\n34161\\n3739 18552205\\n34305\\nCetirizine\\nsuicidal_beh\\n1\\n14715\\n553\\n3926499\\n14716\\nFexofenadine\\nsuicidal_beh\\n2\\n29119\\n3881 18557247\\n29121\\nLoratadine\\nsuicidal_beh\\n3\\n41919\\n3880 18544447\\n41922\\nZafirlukast\\nsuicidal_beh\\n0\\n40\\n637\\n4588529\\n40\\nZileuton\\nsuicidal_beh\\n0\\n229\\n3883 18586137\\n229\\nLevocetirizine\\nsuicidal_beh\\n9\\n10826\\n3874 18575540\\n10835\\n', 'summary': 'The file contains data on various drugs and their associated adverse events, specifically focusing on suicidal behavior. It lists different asthma and rhinitis medications along with numerical identifiers and counts related to their adverse effects. The data appears to categorize the drugs by their potential links to suicidal behavior.', 'suggested_title': 'drug_adverse_events_suicidal_beh', 'suggested_tags': ['pharmaceuticals', 'adverse_events', 'mental_health']}, {'filename': 'output.jpg', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\output.jpg', 'filetype': 'jpg', 'mime_type': 'image/jpeg', 'preview': '[image/jpeg file]', 'summary': 'The file is an image in JPEG format. It likely contains visual content, but specific details cannot be determined without viewing the image.', 'suggested_title': 'image_preview', 'suggested_tags': ['image', 'jpeg', 'visual']}, {'filename': 'PCA_plot.png', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\PCA_plot.png', 'filetype': 'png', 'mime_type': 'image/png', 'preview': '[image/png file]', 'summary': 'The file is an image in PNG format. It likely contains visual content, but specific details about the image cannot be determined from the file type alone.', 'suggested_title': 'image_preview', 'suggested_tags': ['image', 'png', 'visual']}, {'filename': 'phase2_file_info.json', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\phase2_file_info.json', 'filetype': 'json', 'mime_type': 'application/json', 'preview': '[application/json file]', 'summary': 'The file contains data in JSON format, which is commonly used for data interchange. It may include structured information such as objects, arrays, and key-value pairs, suitable for various applications and APIs.', 'suggested_title': 'json_data_file', 'suggested_tags': ['data', 'json', 'api']}, {'filename': 'PINN.ipynb', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\PINN.ipynb', 'filetype': 'ipynb', 'mime_type': '', 'preview': '[Code]\\nimport torch\\nimport torch.nn as nn\\nimport numpy as np\\n\\ndevice = torch.device(\\'cpu\\')\\n\\n[Code]\\n# Initial condition\\ndef u0(x):\\n    return torch.sin(np.pi*x)\\n\\n# Heat conductivity\\ndef k(x):\\n    return 1\\n\\n[Code]\\n# NN model\\nclass PINN(nn.Module):\\n    def __init__(self, layers):\\n        super(PINN, self).__init__()\\n        self.activation = nn.Tanh() # activation function\\n        layer_list = []\\n        for i in range(len(layers)-1):\\n            layer_list.append(nn.Linear(layers[i], layers[i+1]))\\n        self.layers = nn.ModuleList(layer_list)\\n        \\n    def forward(self, t, x):\\n        input = torch.cat([t,x], dim = 1)\\n        for i in range(len(self.layers)-1):\\n            input = self.activation(self.layers[i](input))\\n        return self.layers[-1](input)\\n\\n[Code]\\n# Compute PDE residual\\ndef residual(model, t, x):\\n    t.requires_grad = True\\n    x.requires_grad = True\\n    \\n    u = model(t,x)\\n    \\n    u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\\n    u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\\n    k_val = k(x)\\n    k_u_x = k_val*u_x\\n    k_u_xx = torch.autograd.grad(k_u_x, x, grad_outputs=torch.ones_like(k_u_x), retain_graph=True, create_graph=True)[0]\\n    \\n    return u_t - k_u_xx\\n\\n[Code]\\n# Loss function\\ndef loss_function(model, t0, x0, u0_vals, t_f, x_f):\\n    u0_pred = model(t0, x0)\\n    ic_loss = torch.mean((u0_pred - u0_vals)**2)\\n\\n    f_pred = residual(model, t_f, x_f)\\n    pde_loss = torch.mean(f_pred**2)\\n\\n    return ic_loss + pde_loss\\n\\n[Code]\\n# Training\\ndef train(model, optimizer, epochs, t0, x0, u0_vals, t_f, x_f):\\n    model.train()\\n    for epoch in range(epochs):\\n        optimizer.zero_grad()\\n        loss = loss_function(model, t0, x0, u0_vals, t_f, x_f)\\n        loss.backward()\\n        optimizer.step()\\n        if epoch % 100 == 0:\\n            print(f\"Epoch {epoch}, Loss: {loss.item():.5e}\")\\n\\n[Code]\\n# Main functionality\\nlayers = [2, 50, 50, 50,', 'summary': '```json\\n{\\n  \"summary\": \"This code implements a Physics-Informed Neural Network (PINN) to solve a heat equation using PyTorch. It defines the initial condition, heat conductivity, and constructs the neural network model, including the loss function and training loop. The model aims to learn the solution of the partial differential equation by minimizing the residuals.\",\\n  \"suggested_title\": \"pinn_heat_equation_solver\",\\n  \"suggested_tags\": [\"machine_learning\", \"neural_networks\", \"pde_solving\"]\\n}\\n```', 'suggested_title': '', 'suggested_tags': []}, {'filename': 'PINN_2output.ipynb', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\PINN_2output.ipynb', 'filetype': 'ipynb', 'mime_type': '', 'preview': '[Code]\\nimport torch\\nimport torch.nn as nn\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n[Code]\\ndef build_network(layers):\\n    module_list = []\\n    for i in range(len(layers)-2):\\n        module_list.append(nn.Linear(layers[i], layers[i+1]))\\n        module_list.append(nn.Tanh())\\n        \\n    module_list.append(nn.Linear(layers[-2], layers[-1]))\\n    return nn.Sequential(*module_list)\\n\\n[Code]\\n# Main PINN\\nclass HeatPINN(nn.Module):\\n    def __init__(self, layers):\\n        super(HeatPINN, self).__init__()\\n        \\n        self.model = build_network(layers)\\n        \\n    def forward(self, x, t):\\n        inputs = torch.cat([x,t], dim=1)\\n        outputs = self.model(inputs)\\n        \\n        u = outputs[:, 0:1]\\n        k = outputs[:, 1:2]\\n        \\n        return u, k\\n\\n[Code]\\n# Compute derivatives of u and k\\ndef compute_derivatives(u,k,x,t):\\n    u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True)[0]\\n    u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), create_graph=True)[0]\\n    \\n    k_x = torch.autograd.grad(k, x, grad_outputs=torch.ones_like(k), create_graph=True)[0]\\n    \\n    u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), create_graph=True)[0]\\n    \\n    return u_x, u_xx, u_t, k_x\\n\\n[Code]\\n# PDE residual\\ndef pde_residual(u, k, u_x, u_xx, u_t, k_x):\\n    rhs = (k * u_xx) + (k_x * u_x)\\n    \\n    residual = u_t - rhs\\n    \\n    return residual\\n\\n[Code]\\n# NN loss function\\ndef total_loss(model, x, t, x_bc, t_bc, u_bc, x_ic, t_ic, u_ic):\\n    x.requires_grad = True\\n    t.requires_grad = True\\n    x_bc.requires_grad = True\\n    t_bc.requires_grad = True\\n    # PDE loss\\n    u_pred, k_pred = model(x, t)\\n    u_x, u_xx, u_t, k_x = compute_derivatives(u_pred, k_pred, x, t)\\n    residual = pde_residual(u_pred, k_pred, u_x, u_xx, u_t, k_x)\\n    pde_loss = torch.mean(residual**2)\\n    \\n    # BC loss\\n    u_bc_pred, k_bc_pred = model(x_bc, t_bc)\\n    bc_loss = torch.mean((u_bc_pred - u_bc)**2)\\n    \\n    # IC loss\\n    u_ic_pred, k_ic_pre', 'summary': '```json\\n{\\n  \"summary\": \"This code implements a Physics-Informed Neural Network (PINN) for solving heat equations using PyTorch. It defines a neural network architecture, computes derivatives, and formulates the loss function to include both PDE residuals and boundary/initial conditions. The model aims to predict temperature and thermal conductivity based on input spatial and temporal coordinates.\",\\n  \"suggested_title\": \"heat_pinn_model\",\\n  \"suggested_tags\": [\"machine_learning\", \"neural_networks\", \"pde\"]\\n}\\n```', 'suggested_title': '', 'suggested_tags': []}, {'filename': 'PINN_3output.ipynb', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\PINN_3output.ipynb', 'filetype': 'ipynb', 'mime_type': '', 'preview': '[Code]\\nimport torch\\nimport torch.nn as nn\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n[Code]\\n#Let k(x) = 0.25, this is the solution to the heat equation (with added noise)\\ndef true_solution(x, t):\\n    soln = torch.exp(-np.pi**2 * t*0.5) * torch.sin(np.pi * x)\\n    soln += 5*1e-2*torch.randn(soln.size())\\n    return soln\\n\\n[Code]\\ndef build_network(layers):\\n    module_list = []\\n    for i in range(len(layers)-2):\\n        module_list.append(nn.Linear(layers[i], layers[i+1]))\\n        module_list.append(nn.Tanh())\\n        \\n    module_list.append(nn.Linear(layers[-2], layers[-1]))\\n    return nn.Sequential(*module_list)\\n\\n[Code]\\n# Main PINN\\nclass HeatPINN(nn.Module):\\n    def __init__(self, layers):\\n        super(HeatPINN, self).__init__()\\n        \\n        self.model = build_network(layers)\\n        \\n    def forward(self, x, t):\\n        inputs = torch.cat([x,t], dim=1)\\n        outputs = self.model(inputs)\\n        \\n        u = outputs[:, 0:1]\\n        k = outputs[:, 1:2]\\n        \\n        return u, k\\n\\n[Code]\\n# Compute derivatives of u and k\\ndef compute_derivatives(u,k,x,t):\\n    u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True)[0]\\n    u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), create_graph=True)[0]\\n    \\n    k_x = torch.autograd.grad(k, x, grad_outputs=torch.ones_like(k), create_graph=True)[0]\\n    \\n    u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), create_graph=True)[0]\\n    \\n    return u_x, u_xx, u_t, k_x\\n\\n[Code]\\n# PDE residual\\ndef pde_residual(u, k, u_x, u_xx, u_t, k_x):\\n    rhs = (k * u_xx) + (k_x * u_x)\\n    \\n    residual = u_t - rhs\\n    \\n    return residual\\n\\n[Code]\\n# NN loss function\\ndef total_loss(model, x, t, x_bc, t_bc, u_bc, x_ic, t_ic, u_ic, x_dat, t_dat, u_dat):\\n    x.requires_grad = True\\n    t.requires_grad = True\\n    x_bc.requires_grad = True\\n    t_bc.requires_grad = True\\n    # PDE loss\\n    penalty_pde = 1e-1\\n    u_pred, k_pred = model(x, t)\\n\\n\\n    u_x, u_xx, u_t, k_x = compute_derivatives', 'summary': '```json\\n{\\n  \"summary\": \"This code implements a Physics-Informed Neural Network (PINN) to solve the heat equation with noise. It defines the true solution, constructs a neural network, computes derivatives, and calculates the PDE residual and loss function for training. The model aims to predict temperature distribution and thermal conductivity over time and space.\",\\n  \"suggested_title\": \"heat_pinn_model\",\\n  \"suggested_tags\": [\"machine_learning\", \"neural_networks\", \"physics\"]\\n}\\n```', 'suggested_title': '', 'suggested_tags': []}, {'filename': 'PINN_galertian_approx.ipynb', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\PINN_galertian_approx.ipynb', 'filetype': 'ipynb', 'mime_type': '', 'preview': '[Code]\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\n\\ndef syntehnic_data(BC, IC, T):\\n    \"\"\"\\n    Generate synthetic data for the PDE problem.\\n    \\n    Parameters:\\n    BC : tuple\\n        Boundary conditions (left, right).\\n    IC : tuple\\n        Initial conditions (left, right).\\n    T : float\\n    \"\"\"\\n    #Generate a interval for x and t\\n    x = np.linspace(BC[0], BC[1], 5)\\n    t = np.linspace(IC[0], T, 5)\\n\\n    #Create intervals for x, like (0, 0.25), (0.25, 0.5), (0.5, 0.75), (0.75, 1)\\n    x_intervals = [(x[i], x[i+1]) for i in range(len(x)-1)]\\n    #For each interval choose 10 random points\\n    x_points = []\\n    for interval in x_intervals:\\n        x_points.extend(np.random.uniform(interval[0], interval[1], 10))\\n\\n    #Create intervals for t, like (0, 0.25), (0.25, 0.5), (0.5, 0.75), (0.75, 1)\\n    t_intervals = [(t[i], t[i+1]) for i in range(len(t)-1)]\\n    #For each interval choose 10 random points\\n    t_points = []\\n    for interval in t_intervals:\\n        t_points.extend(np.random.uniform(interval[0], interval[1], 10))\\n\\n    #Randomly shuffle the points\\n    np.random.shuffle(x_points)\\n    np.random.shuffle(t_points)\\n    #Combine the points into a list of tuples\\n    points = list(zip(x_points, t_points))\\n\\n    #Plot the points\\n    plt.figure(figsize=(6, 5))\\n    plt.scatter(x_points, t_points, color=\\'red\\', s=10, alpha=0.6)\\n    plt.xlabel(\\'x (space)\\')\\n    plt.ylabel(\\'t (time)\\')\\n    plt.title(\\'Random Collocation Points in (x, t) Domain\\')\\n    plt.grid(True)\\n    plt.xlim(0, 1)\\n    plt.ylim(0, 1)\\n    plt.show()\\n\\n    return points\\n\\nsyntehnic_data((0, 1), (0, 1), 1)\\n\\n[Code]\\nimport numpy as np\\nfrom sympy import symbols, diff, lambdify\\nfrom scipy.integrate import quad\\n\\nx = symbols(\"x\")\\n\\ndef energy_inner_product(u_sym, v_sym):\\n    \"\"\"\\n    Compute the energy inner product of two symbolic functions u and v.\\n    \"\"\"\\n    u_prime = diff(u_sym, x)\\n    v_prime = diff(v_sym, x)\\n    u_prime_func = lambdify(x, u_prime, \\'numpy\\')\\n    v_prime_func = lambdify(x, v_prime, \\'numpy\\')\\n    integr', 'summary': '```json\\n{\\n  \"summary\": \"This code generates synthetic data for a partial differential equation (PDE) problem by creating random collocation points in a specified domain. It also includes a function to compute the energy inner product of two symbolic functions using differentiation and numerical integration.\",\\n  \"suggested_title\": \"synthetic_data_and_energy_inner_product\",\\n  \"suggested_tags\": [\"PDE\", \"data_generation\", \"symbolic_computation\"]\\n}\\n```', 'suggested_title': '', 'suggested_tags': []}, {'filename': 'PINN_new.ipynb', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\PINN_new.ipynb', 'filetype': 'ipynb', 'mime_type': '', 'preview': '[Code]\\nimport torch\\nimport torch.nn as nn\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n[Code]\\ndef k_func(x):\\n    \"\"\"Define the diffusivity function k(x).\"\"\"\\n    return 0.5 + x**3\\n\\ndef generate_mesh(N):\\n    \"\"\"Generate spatial mesh and element connectivity.\"\"\"\\n    x = np.linspace(0, 1, N+1)\\n    h = 1.0 / N\\n    return x, h\\n\\ndef assemble_matrices(N, x, h):\\n    \"\"\"Assemble mass and stiffness matrices using linear basis functions.\"\"\"\\n    M = np.zeros((N-1, N-1))\\n    K = np.zeros((N-1, N-1))\\n\\n    for i in range(N - 1):\\n        xi = x[i]     # Left node of the element\\n        xi1 = x[i+1]   # Right node of the element\\n\\n        # Local mass matrix (remains the same for linear basis functions)\\n        M_local = h / 6 * np.array([[2, 1],\\n                                     [1, 2]])\\n\\n        # Local stiffness matrix - integrate k(x) over the element\\n        x_mid = (xi + xi1) / 2\\n        k_integral_approx = k_func(x_mid) * h  # Midpoint rule approximation\\n\\n        K_local = (1 / h**2) * k_integral_approx * np.array([[1, -1],\\n                                                            [-1, 1]])\\n\\n        # Assemble into global matrices\\n        for a in range(2):\\n            for b in range(2):\\n                row_index = i + a\\n                col_index = i + b\\n                if 0 <= row_index < N - 1 and 0 <= col_index < N - 1:\\n                    M[row_index, col_index] += M_local[a, b]\\n                    K[row_index, col_index] += K_local[a, b]\\n\\n    return M, K\\n\\ndef initial_condition(x):\\n    \"\"\"Initial condition u(x, 0).\"\"\"\\n    return np.sin(np.pi * x)  # satisfies u(0)=u(1)=0\\n\\ndef solve_heat_eq(N, T, dt):\\n    \"\"\"Solve the heat equation using FEM and Backward Euler in time.\"\"\"\\n    x, h = generate_mesh(N)\\n    M, K = assemble_matrices(N, x, h)\\n\\n    # Remove boundary nodes\\n    x_inner = x[1:-1]\\n    u0 = initial_condition(x_inner)\\n\\n    # Time stepping matrices\\n    A = M + dt * K\\n    u = u0.copy()\\n    snapshots = [u0.copy()]\\n    times = [0]\\n\\n    for n in range(0, int(T/dt)', 'summary': '```json\\n{\\n  \"summary\": \"This code implements a finite element method (FEM) to solve the heat equation with a variable diffusivity function. It includes functions for generating a spatial mesh, assembling mass and stiffness matrices, and applying an initial condition. The solution is computed using the Backward Euler method over a specified time duration.\",\\n  \"suggested_title\": \"heat_equation_fem_solver\",\\n  \"suggested_tags\": [\"FEM\", \"heat_equation\", \"numerical_methods\"]\\n}\\n```', 'suggested_title': '', 'suggested_tags': []}, {'filename': 'PINN_with_unknown_k.ipynb', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\PINN_with_unknown_k.ipynb', 'filetype': 'ipynb', 'mime_type': '', 'preview': \"[Code]\\nimport torch\\nimport torch.nn as nn\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Set device\\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\n\\n# Initial condition\\ndef u0(x):\\n    return torch.sin(np.pi*x)\\n\\n# Neural network for u(t,x)\\nclass PINN_u(nn.Module):\\n    def __init__(self, layers):\\n        super(PINN_u, self).__init__()\\n        self.activation = nn.Tanh()\\n        self.layers = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\\n\\n    def forward(self, t, x):\\n        input = torch.cat([t, x], dim=1)\\n        for layer in self.layers[:-1]:\\n            input = self.activation(layer(input))\\n        return self.layers[-1](input)\\n\\n# Neural network for kappa(x)\\nclass PINN_kappa(nn.Module):\\n    def __init__(self, layers):\\n        super(PINN_kappa, self).__init__()\\n        self.activation = nn.Tanh()\\n        self.layers = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\\n\\n    def forward(self, x):\\n        input = x\\n        for layer in self.layers[:-1]:\\n            input = self.activation(layer(input))\\n        out = torch.abs(self.layers[-1](input)) + 1e-3  # Ensure positivity\\n        return out\\n\\n# Compute PDE residual\\ndef residual(model_u, model_kappa, t, x):\\n    t.requires_grad_(True)\\n    x.requires_grad_(True)\\n\\n    u = model_u(t, x)\\n    u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\\n    u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\\n\\n    kappa_val = model_kappa(x)\\n    kappa_u_x = kappa_val * u_x\\n    kappa_u_xx = torch.autograd.grad(kappa_u_x, x, grad_outputs=torch.ones_like(kappa_u_x), retain_graph=True, create_graph=True)[0]\\n\\n    return u_t - kappa_u_xx\\n\\n# Loss function with boundary conditions and smoothness\\ndef loss_function(model_u, model_kappa, t0, x0, u0_vals, t_f, x_f, tb, xb, bc_type):\\n    tb.requires_grad_(True)\\n    xb.requires_grad_(True)\\n    \\n    \", 'summary': '```json\\n{\\n  \"summary\": \"This code implements a Physics-Informed Neural Network (PINN) using PyTorch to solve a partial differential equation (PDE). It defines two neural network classes for the solution and the coefficient of the PDE, computes the PDE residual, and sets up a loss function incorporating boundary conditions. The model utilizes GPU acceleration if available.\",\\n  \"suggested_title\": \"pinn_pde_solver\",\\n  \"suggested_tags\": [\"machine_learning\", \"neural_networks\", \"pde\"]\\n}\\n```', 'suggested_title': '', 'suggested_tags': []}, {'filename': 'Polyethylene-chain.png', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\Polyethylene-chain.png', 'filetype': 'png', 'mime_type': 'image/png', 'preview': '[image/png file]', 'summary': 'The file is an image in PNG format. It likely contains visual content, but the specific details cannot be determined without viewing the image.', 'suggested_title': 'image_preview', 'suggested_tags': ['image', 'png', 'visual']}, {'filename': 'QR-factor.py', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\QR-factor.py', 'filetype': 'py', 'mime_type': 'text/x-python', 'preview': \"import numpy as np \\n  \\n  \\n# Original matrix \\nmatrix1 = np.array([[1, 1], [0, 0], [2, 1]]) \\nprint(matrix1) \\n  \\n# Decomposition of the said matrix \\nq, r = np.linalg.qr(matrix1) \\nprint('\\\\nQ:\\\\n', q) \\nprint('\\\\nR:\\\\n', r) \", 'summary': 'This Python script demonstrates the use of NumPy for matrix operations, specifically performing QR decomposition on a given matrix. It initializes a matrix and prints both the original matrix and the resulting Q and R matrices from the decomposition.', 'suggested_title': 'qr_decomposition_example', 'suggested_tags': ['Python', 'NumPy', 'Matrix Operations']}, {'filename': 'runif1.pdf', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\runif1.pdf', 'filetype': 'pdf', 'mime_type': 'application/pdf', 'preview': '0.0\\n0.2\\n0.4\\n0.6\\n0.8\\n1.0\\n0.0\\n0.2\\n0.4\\n0.6\\n0.8\\n1.0\\nx1\\nx2\\n', 'summary': \"The file contains a series of numerical values ranging from 0.0 to 1.0, repeated in a structured format. It also includes labels 'x1' and 'x2', which may indicate different data series or categories. This data could be used for analysis or visualization purposes.\", 'suggested_title': 'numerical_data_series', 'suggested_tags': ['data', 'numerical', 'analysis']}, {'filename': 'Satellite_database.py', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\Satellite_database.py', 'filetype': 'py', 'mime_type': 'text/x-python', 'preview': '# import pandas lib as pd\\nimport pandas as pd\\nimport math\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nfrom sklearn import preprocessing\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.neighbors import KNeighborsClassifier\\nimport seaborn as sns\\nfrom pylab import rcParams\\n\\n# Load data\\ndataframe1 = pd.read_excel(\\'C:/Users/gabel/Downloads/UCS-Satellite-Database 5-1-2023.xlsx\\')\\ndf = dataframe1.iloc[:, 0:29] \\nprint(df.describe())\\n\\n# Fill NaN values\\ndf = df.fillna(0)\\n\\n# Encode predictor variable\\npredictor = df[\\'Expected Lifetime (yrs.)\\']\\nlab = preprocessing.LabelEncoder()\\nnormalized_predictor = lab.fit_transform(predictor)\\n\\n# Convert categorical columns to numeric\\ndf[\\'Launch Site\\'] = pd.factorize(df[\\'Launch Site\\'])[0]\\ndf[\\'Launch Vehicle\\'] = pd.factorize(df[\\'Launch Vehicle\\'])[0]\\ndf[\\'Type of Orbit\\'] = pd.factorize(df[\\'Type of Orbit\\'])[0]\\n\\n# Remove categorical columns\\ndf = df.select_dtypes(exclude=[\\'object\\'])\\n\\n# Split into train-test split, 70-30\\nupper_indice = math.ceil(0.7*len(df.index))\\ntraining_df = df.iloc[:upper_indice, :]\\ntesting_df = df.iloc[upper_indice:, :]\\ntrain_classes = normalized_predictor[:upper_indice]\\ntest_classes = normalized_predictor[upper_indice:]\\n\\n# Scale the numerical features\\nscaler = preprocessing.StandardScaler()\\nscaled_training_df = scaler.fit_transform(training_df)\\nscaled_testing_df = scaler.transform(testing_df)\\n\\n# Apply PCA\\npca = PCA(n_components=12) # Specify number of components you want\\npca.fit(scaled_training_df)\\n\\n# Transform training and testing data using PCA\\ntransformed_training_df = pca.transform(scaled_training_df)\\ntransformed_testing_df = pca.transform(scaled_testing_df)\\n\\n# Now you can use transformed_training_df and transformed_testing_df for training and testing\\n# For example:\\nknn = KNeighborsClassifier(n_neighbors=87)\\nknn.fit(transformed_training_df, train_classes)\\nprint(\"The KNN score after PCA is: \", knn.score(transformed_testing_df, test_classes))\\n\\n\\npca = PCA().fit(scaled_training_df)\\n\\n# Plot explained variance ratio\\nplt', 'summary': '```json\\n{\\n  \"summary\": \"This script processes satellite data using pandas and applies machine learning techniques, including K-Nearest Neighbors (KNN) and Principal Component Analysis (PCA). It involves data cleaning, encoding categorical variables, scaling features, and evaluating model performance. The script also includes visualization of the explained variance from PCA.\",\\n  \"suggested_title\": \"satellite_data_analysis_knn_pca\",\\n  \"suggested_tags\": [\"data_analysis\", \"machine_learning\", \"PCA\"]\\n}\\n```', 'suggested_title': '', 'suggested_tags': []}, {'filename': 'Space_Data.py', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\Space_Data.py', 'filetype': 'py', 'mime_type': 'text/x-python', 'preview': 'from pprint import pprint\\nimport requests\\nimport json\\n\\nURL = \\'https://discosweb.esoc.esa.int\\'\\ntoken = \\'ImIzNDk2YmMyLWY3YTUtNDkyNS1hNGUzLTA5OTJmZmNiYjI0YyI.lgCdkcYguX8xjGWB1CDCErxNvB8\\'\\n\\nresponse = requests.get(\\n    f\\'{URL}/api/objects\\',\\n    headers={\\n        \\'Authorization\\': f\\'Bearer {token}\\',\\n        \\'DiscosWeb-Api-Version\\': \\'2\\',\\n    },\\n    params={\\n        \\'filter\\': \"eq(objectClass,Payload)&gt(reentry.epoch,epoch:\\'2020-01-01\\')\",\\n        \\'sort\\': \\'-reentry.epoch\\',\\n    },\\n)\\n\\ndoc = response.json()\\n#Shows column names\\n#print(list(doc.keys()))\\n\\nprint(doc[\\'data\\'][0][\\'attributes\\'])\\n#if response.ok:\\n#    pprint(doc[\\'data\\'])\\n#else:\\n#    pprint(doc[\\'errors\\'])\\n', 'summary': 'This Python script retrieves data from the DiscosWeb API, specifically filtering for payload objects that have a reentry date after January 1, 2020. It uses the requests library to make a GET request with authorization and sorts the results by reentry date. The script also includes commented-out code for displaying the response data or errors.', 'suggested_title': 'discosweb_api_payloads', 'suggested_tags': ['API', 'Python', 'Data Retrieval']}, {'filename': 'Spring_2023_Exam_Schedule.txt', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\Spring_2023_Exam_Schedule.txt', 'filetype': 'txt', 'mime_type': 'text/plain', 'preview': 'CMDA 3634 -> 12/08 at 1:05pm D&D 170\\nCMDA 3654 -> 12/12 at 4:25pm Online\\nCMDA 3605 -> 12/09 at 7:45am MCB 226\\nECON 1204 -> 12/08 at 7pm-9pm Online\\n\\n\\n\\n', 'summary': 'The document lists scheduled classes with their respective dates, times, and locations. It includes both in-person and online classes for courses CMDA and ECON. Notable dates include December 8th and 12th for various classes.', 'suggested_title': 'class_schedule_december', 'suggested_tags': ['scheduling', 'classes', 'education']}, {'filename': 'Stat_4444_HW4_Q2_Dell.png', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\Stat_4444_HW4_Q2_Dell.png', 'filetype': 'png', 'mime_type': 'image/png', 'preview': '[image/png file]', 'summary': 'The file is an image in PNG format. It likely contains visual content that could be related to various topics depending on its subject matter.', 'suggested_title': 'image_preview', 'suggested_tags': ['image', 'png', 'visual']}, {'filename': 'Stuff.py', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\Stuff.py', 'filetype': 'py', 'mime_type': 'text/x-python', 'preview': 'import pandas as pd\\ndf = pd.read_csv(\"C:/Users/gabel/Downloads/responses.csv\")\\nprint(df.head())\\nprint(df.describe())\\nprint(df.info())\\nprint(df.columns)\\nprint(df.shape)\\nprint(df.isnull().sum())\\n\\n', 'summary': 'This script uses the pandas library to read a CSV file containing responses and performs basic data exploration. It prints the first few rows, statistical summary, data types, column names, shape of the DataFrame, and checks for missing values. This is useful for initial data analysis and understanding the dataset structure.', 'suggested_title': 'data_analysis_script', 'suggested_tags': ['data_analysis', 'python', 'pandas']}, {'filename': 'Test.pdf', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\Test.pdf', 'filetype': 'pdf', 'mime_type': 'application/pdf', 'preview': 'CMDA 4654 Homework 0\\nGabriel Dell\\n2024-01-28\\nProblem 1\\nA\\n1\\nP(X > âˆ’10) = 1 âˆ’P(X â‰¤âˆ’10)\\nP(X > âˆ’10) = 1 âˆ’0.5 = 0.5\\n2\\nSince the probability of a continuous random variable taking a specific value is zero:\\nP(X = âˆ’8) = 0\\n3\\nP(âˆ’22 â‰¤X â‰¤âˆ’12) = P\\n\\x12âˆ’22 âˆ’(âˆ’10)\\n5\\nâ‰¤Z â‰¤âˆ’12 âˆ’(âˆ’10)\\n5\\n\\x13\\nP(âˆ’2.4 â‰¤x â‰¤âˆ’0.4) = 0.34458 âˆ’0.0082 = 0.33638\\n4\\nP(âˆ’30 â‰¤x â‰¤C) = 0.5763, P(x â‰¤C) âˆ’P(x â‰¤âˆ’30) = 0.5763\\nP(x â‰¤C) = 0.5763 + P(x â‰¤1 âˆ’30) = 0.5763 + 0.00003 = 0.576\\nConverting to a z-score yields us a value of 0.19 and using the formula of the z-score, with C as our unknown\\nvalue, we can do,\\nC + 10\\n5\\n= 0.19, C + 10 = 0.95, C = âˆ’9.05\\n5\\nTo find the value of a such that P(âˆ’a â‰¤Z â‰¤a) = 0.8664, where Z is a standard normal random variable,\\nyou can use the standard normal distribution table or a calculator.\\nSince P(âˆ’a â‰¤Z â‰¤a) is related to the cumulative distribution function (CDF) of the standard normal\\ndistribution, you want to find the z-value for which P(Z â‰¤z) âˆ’P(Z â‰¤âˆ’z) = 0.8664.\\nConsulting a standard normal distribution table or using a calculator, you would look for the z-value\\ncorresponding to a cumulative probability of 0.4332 (half of 0.8664).\\nLet zâˆ—be the z-value such that P(Z â‰¤zâˆ—) = 0.4332. Then, P(Z â‰¤âˆ’zâˆ—) = 1 âˆ’P(Z â‰¤zâˆ—).\\n1\\n', 'summary': 'This document contains homework solutions for CMDA 4654, focusing on probability calculations involving continuous random variables and the standard normal distribution. Key problems include finding probabilities, z-scores, and specific values related to cumulative distribution functions.', 'suggested_title': 'CMDA_4654_Homework_0', 'suggested_tags': ['homework', 'probability', 'statistics']}, {'filename': 'Unofficial Academic Transcipt.pdf', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\Unofficial Academic Transcipt.pdf', 'filetype': 'pdf', 'mime_type': 'application/pdf', 'preview': 'Display Unofficial Transcript\\n\\xa0\\n906426453 Gabriel Dell\\n02/02/25 04:27 PM\\nThis is NOT an official transcript. Courses which are in progress may also be included on this transcript.\\nTransfer Credit \\xa0\\xa0 Institution Credit \\xa0\\xa0 Transcript Totals \\xa0\\xa0 Courses in Progress\\nTranscript Data\\nSTUDENT INFORMATION\\nName : Gabriel Dell\\nStudent Type: Continuing\\nPrimary College: College of Science\\nPrimary Major: CMDA - Computational Modeling and Data Analytics\\n\\xa0\\n***Transcript type:WEB is NOT Official ***\\n\\xa0\\n\\xa0\\n\\xa0\\nTRANSFER CREDIT ACCEPTED BY INSTITUTION\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0-Top-\\nFS2021: Advanced Standing\\nSubject\\nCourse\\nTitle\\nGrade\\nCredit\\nHours\\nQuality Points\\nENGL\\n1105\\nFirst-Year Writing\\nT\\n3.000\\xa0\\xa0\\n0.00\\n\\xa0\\nAttempt\\nHours\\nPassed\\nHours\\nEarned\\nHours\\nGPA\\nHours\\nQuality\\nPoints\\nGPA\\nCurrent Term:\\n0.000\\n0.000\\n3.000\\n0.000\\n0.00\\n0.00\\n\\xa0\\nUnofficial Transcript\\nSU22-\\nFS22:\\nNorthern Va Cmty Coll-Annandal\\nSubject\\nCourse\\nTitle\\nGrade\\nCredit\\nHours\\nQuality Points\\nMATH\\n1226\\nCalculus of a Single Variable\\nT\\n4.000\\xa0\\xa0\\n0.00\\nMATH\\n2114\\nIntroduction to Linear\\nAlgebra\\nT\\n3.000\\xa0\\xa0\\n0.00\\n\\xa0\\nAttempt\\nHours\\nPassed\\nHours\\nEarned\\nHours\\nGPA\\nHours\\nQuality\\nPoints\\nGPA\\nCurrent Term:\\n0.000\\n0.000\\n7.000\\n0.000\\n0.00\\n0.00\\n\\xa0\\nUnofficial Transcript\\nINSTITUTION CREDIT\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0-Top-\\nTerm: Fall 2021\\nPrimary College: College of Science\\nPrimary Major: CMDA - Computational Modeling and Data Analytics\\n', 'summary': 'This document is an unofficial transcript for Gabriel Dell, a continuing student majoring in Computational Modeling and Data Analytics at the College of Science. It includes details about transfer credits, courses in progress, and current term statistics, indicating that the transcript is not official and should not be used for formal purposes.', 'suggested_title': 'gabriel_dell_unofficial_transcript', 'suggested_tags': ['transcript', 'education', 'student_records']}, {'filename': 'Untitled-1.ipynb', 'filepath': 'C:\\\\Users\\\\gabel\\\\Documents\\\\Untitled-1.ipynb', 'filetype': 'ipynb', 'mime_type': '', 'preview': '[Code]\\nimport pandas as pd\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\nfrom sklearn.cluster import KMeans\\nimport re\\ndf = pd.read_csv(\"C:/Users/gabel/Downloads/responses.csv\")\\nprint(df.columns)\\n\\n[Code]\\n#make chapter number a category\\ndf[\\'chapter_number\\'] = df[\\'chapter_number\\'].astype(\\'category\\')\\n\\n#Create a displot of the chapter number and a hue of completes_pages\\nsns.histplot(data=df, x=\\'chapter_number\\', hue=\\'completes_page\\', multiple=\\'fill\\')\\nplt.show()\\n\\n[Code]\\n#Want to look at time difference of lrn_dt_started and dt_submitted\\ndf[\\'lrn_dt_started\\'] = pd.to_datetime(df[\\'lrn_dt_started\\'])\\ndf[\\'dt_submitted\\'] = pd.to_datetime(df[\\'dt_submitted\\'])\\ndf[\\'lrn_dt_saved\\'] = pd.to_datetime(df[\\'lrn_dt_saved\\'])\\n#Give me a timedelta difference between dt_submitted and dt_started\\ndf[\\'time_diff\\'] = (df[\\'dt_submitted\\'] - df[\\'lrn_dt_started\\']).dt.total_seconds() / 60\\n\\n[Code]\\n#Create a lineplot of the time difference with the chapter number as the x axis\\nsns.lineplot(data=df, x=\\'chapter_number\\', y=\\'time_diff\\')\\nplt.show()\\n\\n[Code]\\ntype = df[df[\\'item_type\\'] == \\'learnosity-activity\\']\\n#Create a lineplot of the time difference with the chapter number as the x axis\\nsns.lineplot(data=type, x=\\'chapter_number\\', y=\\'time_diff\\', hue=\\'completes_page\\', ci=None)\\n\\n[Code]\\ntype[\\'prompt\\'] = type[\\'prompt\\'].fillna(\\'\\').apply(lambda x: re.sub(r\\'<[^>]+>\\', \\'\\', x))\\n\\nvectorizer = TfidfVectorizer(stop_words=\\'english\\', max_features=1000)\\nX = vectorizer.fit_transform(type[\\'prompt\\'])\\nk = 3\\n\\n# K-Means clustering\\nkmeans = KMeans(n_clusters=k, random_state=42)\\ntype[\\'cluster\\'] = kmeans.fit_predict(X)\\n\\n#print(type[[\\'prompt\\', \\'cluster\\']])\\n\\n#Create a function that looks at the top words in each cluster\\n\\ndef get_top_words(cluster, n_words):\\n    X_cluster = X[type[\\'cluster\\'] == cluster]\\n    words = vectorizer.get_feature_names_out()\\n    words = pd.DataFrame(X_cluster.toarray(), columns=words)\\n    return words.sum().sort_values(ascending=False).head(n_words)\\n', 'summary': 'This code performs data analysis and visualization on a dataset containing chapter responses. It includes creating histograms and line plots to analyze chapter completion and time differences, as well as applying K-Means clustering to text prompts after preprocessing. The analysis aims to uncover patterns in learning activities based on chapter numbers and response times.', 'suggested_title': 'chapter_analysis_clustering', 'suggested_tags': ['data_analysis', 'visualization', 'machine_learning']}]\n",
      "Moved 04.12.2023_22.06.45_REC.mp4 â†’ C:\\Users\\gabel\\Documents\\Multimedia_Content\n",
      "Moved Correlation_plot.png â†’ C:\\Users\\gabel\\Documents\\Multimedia_Content\n",
      "Moved Explained_Var.png â†’ C:\\Users\\gabel\\Documents\\Multimedia_Content\n",
      "Moved Indigenous Mental Health in Canada.mp4 â†’ C:\\Users\\gabel\\Documents\\Multimedia_Content\n",
      "Moved output.jpg â†’ C:\\Users\\gabel\\Documents\\Multimedia_Content\n",
      "Moved PCA_plot.png â†’ C:\\Users\\gabel\\Documents\\Multimedia_Content\n",
      "Moved Polyethylene-chain.png â†’ C:\\Users\\gabel\\Documents\\Multimedia_Content\n",
      "Moved Stat_4444_HW4_Q2_Dell.png â†’ C:\\Users\\gabel\\Documents\\Multimedia_Content\n",
      "Moved Epidemic.csv â†’ C:\\Users\\gabel\\Documents\\Data_Analysis_Scripts\n",
      "Moved big_bucks.csv â†’ C:\\Users\\gabel\\Documents\\Data_Analysis_Scripts\n",
      "Moved big_bucks_edited.csv â†’ C:\\Users\\gabel\\Documents\\Data_Analysis_Scripts\n",
      "Moved knn_test.py â†’ C:\\Users\\gabel\\Documents\\Data_Analysis_Scripts\n",
      "Moved QR-factor.py â†’ C:\\Users\\gabel\\Documents\\Data_Analysis_Scripts\n",
      "Moved Satellite_database.py â†’ C:\\Users\\gabel\\Documents\\Data_Analysis_Scripts\n",
      "Moved Space_Data.py â†’ C:\\Users\\gabel\\Documents\\Data_Analysis_Scripts\n",
      "Moved Stuff.py â†’ C:\\Users\\gabel\\Documents\\Data_Analysis_Scripts\n",
      "Moved Untitled-1.ipynb â†’ C:\\Users\\gabel\\Documents\\Data_Analysis_Scripts\n",
      "Moved gptSerialCorrelationTest.cu.txt â†’ C:\\Users\\gabel\\Documents\\Machine_Learning_Models\n",
      "Moved PINN.ipynb â†’ C:\\Users\\gabel\\Documents\\Machine_Learning_Models\n",
      "Moved PINN_2output.ipynb â†’ C:\\Users\\gabel\\Documents\\Machine_Learning_Models\n",
      "Moved PINN_3output.ipynb â†’ C:\\Users\\gabel\\Documents\\Machine_Learning_Models\n",
      "Moved PINN_galertian_approx.ipynb â†’ C:\\Users\\gabel\\Documents\\Machine_Learning_Models\n",
      "Moved PINN_new.ipynb â†’ C:\\Users\\gabel\\Documents\\Machine_Learning_Models\n",
      "Moved PINN_with_unknown_k.ipynb â†’ C:\\Users\\gabel\\Documents\\Machine_Learning_Models\n",
      "Moved 6824.txt â†’ C:\\Users\\gabel\\Documents\\Textual_Document_Analysis\n",
      "Moved HW3.ipynb â†’ C:\\Users\\gabel\\Documents\\Textual_Document_Analysis\n",
      "Moved HW5.ipynb â†’ C:\\Users\\gabel\\Documents\\Textual_Document_Analysis\n",
      "Moved HW6.ipynb â†’ C:\\Users\\gabel\\Documents\\Textual_Document_Analysis\n",
      "Moved MDMAtxt.txt â†’ C:\\Users\\gabel\\Documents\\Textual_Document_Analysis\n",
      "Moved My Personal Code of Ethics.txt â†’ C:\\Users\\gabel\\Documents\\Textual_Document_Analysis\n",
      "Moved NAE_Disproportionality_all_cases_2004-2024.pdf â†’ C:\\Users\\gabel\\Documents\\Textual_Document_Analysis\n",
      "Moved Spring_2023_Exam_Schedule.txt â†’ C:\\Users\\gabel\\Documents\\Textual_Document_Analysis\n",
      "Moved Test.pdf â†’ C:\\Users\\gabel\\Documents\\Textual_Document_Analysis\n",
      "Moved Unofficial Academic Transcipt.pdf â†’ C:\\Users\\gabel\\Documents\\Textual_Document_Analysis\n",
      "Moved .RData â†’ C:\\Users\\gabel\\Documents\\Unreadable_or_Unknown_Files\n",
      "Moved .Rhistory â†’ C:\\Users\\gabel\\Documents\\Unreadable_or_Unknown_Files\n",
      "Moved best_model.pth â†’ C:\\Users\\gabel\\Documents\\Unreadable_or_Unknown_Files\n",
      "Moved bullshit.R â†’ C:\\Users\\gabel\\Documents\\Unreadable_or_Unknown_Files\n",
      "Moved desktop.ini â†’ C:\\Users\\gabel\\Documents\\Unreadable_or_Unknown_Files\n",
      "Moved group_2.r â†’ C:\\Users\\gabel\\Documents\\Unreadable_or_Unknown_Files\n",
      "Moved HW_5.R â†’ C:\\Users\\gabel\\Documents\\Unreadable_or_Unknown_Files\n",
      "Moved Indigenous Mental Health in Canada.pptm â†’ C:\\Users\\gabel\\Documents\\Unreadable_or_Unknown_Files\n",
      "Moved phase2_file_info.json â†’ C:\\Users\\gabel\\Documents\\Unreadable_or_Unknown_Files\n",
      "Moved runif1.pdf â†’ C:\\Users\\gabel\\Documents\\Unreadable_or_Unknown_Files\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def parse_group_response(response_text):\n",
    "    folder_map = defaultdict(list)\n",
    "    lines = response_text.splitlines()\n",
    "    for line in lines:\n",
    "        match = re.match(r\"- (.+?): \\[(.+?)\\]\", line.strip())\n",
    "        if match:\n",
    "            folder, indices = match.groups()\n",
    "            indices = [int(i.strip()) - 1 for i in indices.split(\",\")]\n",
    "            folder_map[folder].extend(indices)\n",
    "    return folder_map\n",
    "\n",
    "folder_map = parse_group_response(suggested_folders)\n",
    "\n",
    "\n",
    "def move_files_to_groups(files_info, group_map):\n",
    "    for folder, indices in group_map.items():\n",
    "        target_dir = DOCUMENTS_DIR / folder\n",
    "        target_dir.mkdir(exist_ok=True)\n",
    "        for i in indices:\n",
    "            src_path = Path(files_info[i][\"filepath\"])\n",
    "            dest_path = target_dir / src_path.name\n",
    "            shutil.move(str(src_path), str(dest_path))\n",
    "            print(f\"Moved {src_path.name} â†’ {target_dir}\")\n",
    "\n",
    "move_files_to_groups(files_info, folder_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
